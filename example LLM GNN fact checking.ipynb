{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMW7X49Y7lOMIJat1BmKlHH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAUforPython/BioMedAI/blob/main/example%20LLM%20GNN%20fact%20checking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BioMedAI Fact Checking with RoBERTa + PubMed + Graph Neural Networks\n",
        "======================================================================\n",
        "\n",
        "This script demonstrates a comprehensive medical fact-checking system using:\n",
        "1. RoBERTa transformer models for claim-evidence analysis\n",
        "2. PubMed literature search for scientific evidence\n",
        "3. Graph Neural Networks for knowledge graph reasoning\n",
        "\n",
        "The system evaluates medical claims by analyzing evidence, searching relevant literature,\n",
        "constructing knowledge graphs, and providing structured verdicts through advanced ML.\n",
        "\n",
        "Fact Checking Process:\n",
        "1. Data Preparation: Medical claims with evidence pairs\n",
        "2. PubMed Literature Search: Scientific paper retrieval\n",
        "3. Knowledge Graph Construction: Claims, evidence, and papers as nodes\n",
        "4. Graph Neural Network Reasoning: Multi-hop reasoning over relationships\n",
        "5. Model Training: Combined RoBERTa + GNN approach\n",
        "6. Verdict Generation: Enhanced classification with confidence scores\n"
      ],
      "metadata": {
        "id": "QtTs27zYWtwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install torch_geometric --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R43H1S63XK_Y",
        "outputId": "ebdceac1-7e3e-48db-c819-537c424abd6a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "from torch_geometric.utils import to_networkx\n",
        "import networkx as nx\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import logging\n",
        "from collections import Counter, defaultdict\n",
        "import warnings\n",
        "import requests\n",
        "import time\n",
        "from urllib.parse import quote_plus\n",
        "import xml.etree.ElementTree as ET\n",
        "from torch.optim import AdamW"
      ],
      "metadata": {
        "id": "2MxkpuY9W0Dt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get Hugging Face token from environment\n",
        "HF_TOKEN = userdata.get(\"HF_token_example\")\n",
        "\n",
        "PUBMED_TOKEN = userdata.get('PubMed_token')"
      ],
      "metadata": {
        "id": "zpXyxcQEW7j7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if PUBMED_TOKEN:\n",
        "  print(f\"✅ PubMed API token detected\")\n",
        "else:\n",
        "  print(\"⚠️  No PubMed API token found. Set PUBMED_TOKEN environment variable to avoid rate limits.\")\n",
        "\n",
        "if HF_TOKEN:\n",
        "  print(\"✅ Hugging Face token detected\")\n",
        "else:\n",
        "  print(\"⚠️  No Hugging Face\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr5Gtc6Xc-4x",
        "outputId": "5464bc9f-41c5-4c23-d87a-7a7bb8bd3119"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PubMed API token detected\n",
            "✅ Hugging Face token detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1UNmqYNrWkKS"
      },
      "outputs": [],
      "source": [
        "class MedicalFactCheckingDataset(Dataset):\n",
        "    \"\"\"Dataset class for medical fact-checking data\"\"\"\n",
        "\n",
        "    def __init__(self, claims, evidences, labels, tokenizer, max_length=512):\n",
        "        self.claims = claims\n",
        "        self.evidences = evidences\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.claims)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        claim = str(self.claims[idx])\n",
        "        evidence = str(self.evidences[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Combine claim and evidence as input\n",
        "        text = f\"Claim: {claim} Evidence: {evidence}\"\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "class MedicalKnowledgeGraph:\n",
        "    \"\"\"\n",
        "    Knowledge Graph for Medical Fact Checking\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.nodes = []\n",
        "        self.edges = []\n",
        "        self.node_features = []\n",
        "        self.node_types = []\n",
        "        self.node_id_map = {}\n",
        "        self.node_labels = {}  # For visualization\n",
        "        self.node_metadata = {}  # Store detailed metadata for each node\n",
        "\n",
        "    def add_claim_node(self, claim_text, claim_id):\n",
        "        \"\"\"Add a claim node to the graph\"\"\"\n",
        "        node_id = len(self.nodes)\n",
        "        node_name = f\"claim_{claim_id}\"\n",
        "        self.nodes.append(node_name)\n",
        "        self.node_types.append('claim')\n",
        "        # Handle None case\n",
        "        claim_text = claim_text if claim_text else \"Unknown Claim\"\n",
        "        self.node_labels[node_name] = claim_text[:50] + \"...\" if len(claim_text) > 50 else claim_text\n",
        "        self.node_metadata[node_name] = {\n",
        "            'full_text': claim_text,\n",
        "            'type': 'claim',\n",
        "            'id': claim_id\n",
        "        }\n",
        "        # Simple feature: text embedding placeholder\n",
        "        self.node_features.append(self._text_to_features(claim_text))\n",
        "        self.node_id_map[node_name] = node_id\n",
        "        return node_id\n",
        "\n",
        "    def add_evidence_node(self, evidence_text, evidence_id):\n",
        "        \"\"\"Add an evidence node to the graph\"\"\"\n",
        "        node_id = len(self.nodes)\n",
        "        node_name = f\"evidence_{evidence_id}\"\n",
        "        self.nodes.append(node_name)\n",
        "        self.node_types.append('evidence')\n",
        "        # Handle None case\n",
        "        evidence_text = evidence_text if evidence_text else \"Unknown Evidence\"\n",
        "        self.node_labels[node_name] = evidence_text[:50] + \"...\" if len(evidence_text) > 50 else evidence_text\n",
        "        self.node_metadata[node_name] = {\n",
        "            'full_text': evidence_text,\n",
        "            'type': 'evidence',\n",
        "            'id': evidence_id\n",
        "        }\n",
        "        self.node_features.append(self._text_to_features(evidence_text))\n",
        "        self.node_id_map[node_name] = node_id\n",
        "        return node_id\n",
        "\n",
        "    def add_paper_node(self, paper_info, paper_id):\n",
        "        \"\"\"Add a paper node to the graph\"\"\"\n",
        "        node_id = len(self.nodes)\n",
        "        node_name = f\"paper_{paper_id}\"\n",
        "        self.nodes.append(node_name)\n",
        "        self.node_types.append('paper')\n",
        "        # Handle None case for title\n",
        "        title = paper_info.get('title', 'Unknown Paper') if paper_info else 'Unknown Paper'\n",
        "        title = title if title else 'Unknown Paper'\n",
        "        self.node_labels[node_name] = title[:50] + \"...\" if len(title) > 50 else title\n",
        "        self.node_metadata[node_name] = {\n",
        "            'title': title,\n",
        "            'authors': paper_info.get('authors', []) if paper_info else [],\n",
        "            'journal': paper_info.get('journal', '') if paper_info else '',\n",
        "            'year': paper_info.get('year', '') if paper_info else '',\n",
        "            'pmid': paper_info.get('pmid', '') if paper_info else '',\n",
        "            'type': 'paper',\n",
        "            'id': paper_id,\n",
        "            'relevance_score': paper_info.get('relevance_score', 0.5) if paper_info else 0.5\n",
        "        }\n",
        "        # Feature based on paper metadata\n",
        "        features = self._paper_to_features(paper_info)\n",
        "        self.node_features.append(features)\n",
        "        self.node_id_map[node_name] = node_id\n",
        "        return node_id\n",
        "\n",
        "    def add_entity_node(self, entity_name, entity_type):\n",
        "        \"\"\"Add a medical entity node to the graph\"\"\"\n",
        "        node_key = f\"entity_{entity_name}_{entity_type}\"\n",
        "        if node_key in self.node_id_map:\n",
        "            return self.node_id_map[node_key]\n",
        "\n",
        "        node_id = len(self.nodes)\n",
        "        self.nodes.append(node_key)\n",
        "        self.node_types.append('entity')\n",
        "        entity_display = f\"{entity_name} ({entity_type})\" if entity_name and entity_type else \"Unknown Entity\"\n",
        "        self.node_labels[node_key] = entity_display[:50] + \"...\" if len(entity_display) > 50 else entity_display\n",
        "        self.node_metadata[node_key] = {\n",
        "            'name': entity_name if entity_name else \"Unknown\",\n",
        "            'entity_type': entity_type if entity_type else \"Unknown\",\n",
        "            'type': 'entity'\n",
        "        }\n",
        "        self.node_features.append(self._entity_to_features(entity_name, entity_type))\n",
        "        self.node_id_map[node_key] = node_id\n",
        "        return node_id\n",
        "\n",
        "    def add_edge(self, source_node_id, target_node_id, relation_type, weight=1.0):\n",
        "        \"\"\"Add an edge between nodes\"\"\"\n",
        "        self.edges.append((source_node_id, target_node_id, relation_type, weight))\n",
        "\n",
        "    def _text_to_features(self, text):\n",
        "        \"\"\"Convert text to feature vector (simplified)\"\"\"\n",
        "        if not text:\n",
        "            return [0, 0, 0]\n",
        "        words = str(text).lower().split()\n",
        "        return [len(words), len(set(words)), sum(len(w) for w in words)/len(words) if words else 0]\n",
        "\n",
        "    def _paper_to_features(self, paper_info):\n",
        "        \"\"\"Convert paper info to feature vector\"\"\"\n",
        "        if not paper_info:\n",
        "            return [0, 0, 0]\n",
        "        return [1, paper_info.get('relevance_score', 0.5), len(paper_info.get('authors', []))]\n",
        "\n",
        "    def _entity_to_features(self, entity_name, entity_type):\n",
        "        \"\"\"Convert entity to feature vector\"\"\"\n",
        "        if not entity_name or not entity_type:\n",
        "            return [0, 0, 0]\n",
        "        type_map = {'disease': 1, 'drug': 2, 'symptom': 3, 'treatment': 4, 'cancer': 5, 'sugar': 6, 'sweetener': 7}\n",
        "        return [type_map.get(entity_type, 0), len(entity_name), 1]\n",
        "\n",
        "    def build_torch_geometric_data(self):\n",
        "        \"\"\"Convert to PyTorch Geometric format\"\"\"\n",
        "        # Node features\n",
        "        x = torch.tensor(self.node_features, dtype=torch.float)\n",
        "\n",
        "        # Edge indices and attributes\n",
        "        edge_index = []\n",
        "        edge_attr = []\n",
        "\n",
        "        for source, target, relation, weight in self.edges:\n",
        "            edge_index.append([source, target])\n",
        "            # Encode relation type\n",
        "            relation_map = {'supports': 1, 'refutes': 2, 'cites': 3, 'mentions': 4, 'related': 5}\n",
        "            edge_attr.append([relation_map.get(relation, 0), weight])\n",
        "\n",
        "        if edge_index:\n",
        "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "            edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
        "        else:\n",
        "            edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "            edge_attr = torch.empty((0, 2), dtype=torch.float)\n",
        "\n",
        "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "    def visualize_graph(self, claim_id=None, max_nodes=100, save_path=None, show_all=False):\n",
        "        \"\"\"\n",
        "        Visualize the knowledge graph with enhanced styling and filtering options.\n",
        "        \"\"\"\n",
        "\n",
        "        # Create NetworkX graph from edges\n",
        "        G = nx.DiGraph()\n",
        "\n",
        "        # Add all nodes with attributes\n",
        "        node_colors = []\n",
        "        node_sizes = []\n",
        "        node_shapes = []\n",
        "        node_color_map = {\n",
        "            'claim': '#FF6B6B',      # Red for claims\n",
        "            'evidence': '#4ECDC4',   # Teal for evidence\n",
        "            'paper': '#45B7D1',      # Blue for papers\n",
        "            'entity': '#96CEB4'      # Green for entities\n",
        "        }\n",
        "\n",
        "        node_shape_map = {\n",
        "            'claim': 'o',      # Circle\n",
        "            'evidence': 's',   # Square\n",
        "            'paper': 'd',      # Diamond\n",
        "            'entity': '^'      # Triangle\n",
        "        }\n",
        "\n",
        "        # Add all nodes to graph (or filter if claim_id is specified)\n",
        "        if show_all or claim_id is None:\n",
        "            # Show all nodes\n",
        "            nodes_to_show = range(len(self.nodes))\n",
        "        else:\n",
        "            # Filter nodes if claim_id is specified\n",
        "            claim_node_name = f\"claim_{claim_id}\"\n",
        "            if claim_node_name in self.node_id_map:\n",
        "                claim_node_id = self.node_id_map[claim_node_name]\n",
        "                # Get connected nodes\n",
        "                connected_nodes = {claim_node_id}\n",
        "                for source, target, _, _ in self.edges:\n",
        "                    if source == claim_node_id or target == claim_node_id:\n",
        "                        connected_nodes.add(source)\n",
        "                        connected_nodes.add(target)\n",
        "\n",
        "                # Limit to max_nodes for visualization clarity\n",
        "                nodes_to_show = list(connected_nodes)[:max_nodes]\n",
        "            else:\n",
        "                nodes_to_show = list(range(min(len(self.nodes), max_nodes)))\n",
        "\n",
        "        # Add filtered nodes to graph\n",
        "        for node_id in nodes_to_show:\n",
        "            if node_id < len(self.nodes):\n",
        "                node_name = self.nodes[node_id]\n",
        "                node_type = self.node_types[node_id]\n",
        "                G.add_node(node_name,\n",
        "                          type=node_type,\n",
        "                          label=self.node_labels.get(node_name, node_name),\n",
        "                          metadata=self.node_metadata.get(node_name, {}))\n",
        "                node_colors.append(node_color_map.get(node_type, '#CCCCCC'))\n",
        "                node_sizes.append(300 if node_type == 'claim' else 150)\n",
        "                node_shapes.append(node_shape_map.get(node_type, 'o'))\n",
        "\n",
        "        # Add all edges between nodes in the graph\n",
        "        edge_colors = []\n",
        "        edge_styles = []\n",
        "        edge_widths = []\n",
        "        edge_labels = []\n",
        "        edge_style_map = {\n",
        "            'supports': 'solid',\n",
        "            'refutes': 'dashed',\n",
        "            'cites': 'dotted',\n",
        "            'mentions': 'dashdot',\n",
        "            'related': 'solid'\n",
        "        }\n",
        "        edge_color_map = {\n",
        "            'supports': '#2E8B57',   # Green\n",
        "            'refutes': '#DC143C',    # Crimson\n",
        "            'cites': '#4169E1',      # Royal Blue\n",
        "            'mentions': '#FF8C00',   # Dark Orange\n",
        "            'related': '#808080'     # Gray\n",
        "        }\n",
        "\n",
        "        for source, target, relation, weight in self.edges:\n",
        "            if source in nodes_to_show and target in nodes_to_show:\n",
        "                G.add_edge(self.nodes[source], self.nodes[target],\n",
        "                          relation=relation, weight=weight)\n",
        "                edge_colors.append(edge_color_map.get(relation, '#000000'))\n",
        "                edge_styles.append(edge_style_map.get(relation, 'solid'))\n",
        "                edge_widths.append(max(0.5, weight * 2))  # Scale width by weight\n",
        "                edge_labels.append(relation[:10])  # Short label for edges\n",
        "\n",
        "        # Create visualization\n",
        "        plt.figure(figsize=(20, 15))\n",
        "\n",
        "        # Use spring layout with adjustments for better visualization\n",
        "        pos = nx.spring_layout(G, k=3, iterations=50, seed=42)\n",
        "\n",
        "        # Draw nodes by type (to get different shapes)\n",
        "        for shape in set(node_shapes):\n",
        "            nodes_of_shape = [n for n, ns in zip(G.nodes(), node_shapes)\n",
        "                             if ns == shape and n in G.nodes()]\n",
        "            if nodes_of_shape:\n",
        "                nx.draw_networkx_nodes(G, pos,\n",
        "                                     nodelist=nodes_of_shape,\n",
        "                                     node_color=[node_colors[i] for i, ns in enumerate(node_shapes) if ns == shape and self.nodes[i] in G.nodes()],\n",
        "                                     node_size=[node_sizes[i] for i, ns in enumerate(node_shapes) if ns == shape and self.nodes[i] in G.nodes()],\n",
        "                                     node_shape=shape,\n",
        "                                     alpha=0.8)\n",
        "\n",
        "        # Draw edges\n",
        "        nx.draw_networkx_edges(G, pos,\n",
        "                              edge_color=edge_colors,\n",
        "                              style=edge_styles,\n",
        "                              width=edge_widths,\n",
        "                              alpha=0.6,\n",
        "                              arrows=True,\n",
        "                              arrowsize=15)\n",
        "\n",
        "        # Draw labels with better positioning\n",
        "        labels = nx.get_node_attributes(G, 'label')\n",
        "        nx.draw_networkx_labels(G, pos, labels, font_size=8, font_weight='bold')\n",
        "\n",
        "        # Create legend\n",
        "        legend_elements = []\n",
        "        for node_type, color in node_color_map.items():\n",
        "            legend_elements.append(plt.Line2D([0], [0], marker='o', color='w',\n",
        "                                            markerfacecolor=color, markersize=10,\n",
        "                                            label=f'{node_type.capitalize()}'))\n",
        "\n",
        "        for relation, color in edge_color_map.items():\n",
        "            legend_elements.append(plt.Line2D([0], [0], color=color, linestyle=edge_style_map.get(relation, 'solid'),\n",
        "                                            linewidth=2, label=f'{relation.capitalize()}'))\n",
        "\n",
        "        plt.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.05, 1))\n",
        "\n",
        "        plt.title('Medical Knowledge Graph Visualization', fontsize=16, fontweight='bold')\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save or show\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Graph visualization saved to {save_path}\")\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "        # Print graph statistics\n",
        "        print(f\"\\n📊 Graph Statistics:\")\n",
        "        print(f\"  Nodes: {G.number_of_nodes()}\")\n",
        "        print(f\"  Edges: {G.number_of_edges()}\")\n",
        "        node_types = nx.get_node_attributes(G, 'type')\n",
        "        if node_types:\n",
        "            print(f\"  Node Types: {dict(Counter(node_types.values()))}\")\n",
        "        edge_relations = nx.get_edge_attributes(G, 'relation')\n",
        "        if edge_relations:\n",
        "            print(f\"  Relationship Types: {dict(Counter(edge_relations.values()))}\")\n",
        "\n",
        "        return G\n",
        "\n",
        "class GNNFactChecker(nn.Module):\n",
        "    \"\"\"\n",
        "    Graph Neural Network for Medical Fact Checking\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_node_features, hidden_dim=64, num_classes=2):\n",
        "        super(GNNFactChecker, self).__init__()\n",
        "\n",
        "        # GCN layers for local neighborhood aggregation\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "\n",
        "        # GAT layer for attention-based reasoning\n",
        "        self.gat1 = GATConv(hidden_dim, hidden_dim, heads=4, dropout=0.1)\n",
        "        self.gat2 = GATConv(hidden_dim * 4, hidden_dim, heads=1, dropout=0.1)\n",
        "\n",
        "        # Classification layers\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_dim // 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # GCN layers\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # GAT layers\n",
        "        x = self.gat1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.gat2(x, edge_index)\n",
        "\n",
        "        # Global pooling (mean pooling)\n",
        "        graph_embedding = torch.mean(x, dim=0, keepdim=True)\n",
        "\n",
        "        # Classification\n",
        "        output = self.classifier(graph_embedding)\n",
        "\n",
        "        return output.squeeze(0)\n",
        "\n",
        "class HybridFactChecker(nn.Module):\n",
        "    \"\"\"\n",
        "    Hybrid Fact Checker combining RoBERTa and GNN\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, roberta_model, gnn_model, hidden_dim=64):\n",
        "        super(HybridFactChecker, self).__init__()\n",
        "        self.roberta = roberta_model\n",
        "        self.gnn = gnn_model\n",
        "\n",
        "        # Fusion layer\n",
        "        self.fusion = nn.Linear(hidden_dim + 768, hidden_dim)  # 768 = RoBERTa hidden size\n",
        "        self.classifier = nn.Linear(hidden_dim, 2)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, graph_data):\n",
        "        # RoBERTa encoding\n",
        "        roberta_outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        roberta_embedding = roberta_outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "\n",
        "        # GNN encoding\n",
        "        gnn_output = self.gnn(graph_data).unsqueeze(0)\n",
        "\n",
        "        # Fusion\n",
        "        combined = torch.cat([roberta_embedding, gnn_output], dim=1)\n",
        "        fused = F.relu(self.fusion(combined))\n",
        "        fused = self.dropout(fused)\n",
        "\n",
        "        # Final classification\n",
        "        logits = self.classifier(fused)\n",
        "\n",
        "        return logits\n",
        "\n",
        "def parse_pubmed_xml(xml_content):\n",
        "    \"\"\"\n",
        "    Parse PubMed XML content to extract paper information and citations.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not xml_content:\n",
        "            return []\n",
        "        root = ET.fromstring(xml_content)\n",
        "        papers = []\n",
        "\n",
        "        for article in root.findall('.//PubmedArticle'):\n",
        "            # Extract PMID\n",
        "            pmid_elem = article.find('.//PMID')\n",
        "            pmid = pmid_elem.text if pmid_elem is not None and pmid_elem.text else 'Unknown'\n",
        "\n",
        "            # Extract title\n",
        "            title_elem = article.find('.//ArticleTitle')\n",
        "            title = title_elem.text if title_elem is not None and title_elem.text else 'Unknown Title'\n",
        "\n",
        "            # Extract authors\n",
        "            authors = []\n",
        "            for author in article.findall('.//Author'):\n",
        "                lastname_elem = author.find('LastName')\n",
        "                firstname_elem = author.find('ForeName')\n",
        "                if lastname_elem is not None and firstname_elem is not None and lastname_elem.text and firstname_elem.text:\n",
        "                    authors.append(f\"{firstname_elem.text} {lastname_elem.text}\")\n",
        "\n",
        "            # Extract journal\n",
        "            journal_elem = article.find('.//Journal/Title')\n",
        "            journal = journal_elem.text if journal_elem is not None and journal_elem.text else 'Unknown Journal'\n",
        "\n",
        "            # Extract year\n",
        "            year_elem = article.find('.//PubDate/Year')\n",
        "            year = year_elem.text if year_elem is not None and year_elem.text else 'Unknown Year'\n",
        "\n",
        "            papers.append({\n",
        "                'pmid': pmid,\n",
        "                'title': title,\n",
        "                'authors': authors,\n",
        "                'journal': journal,\n",
        "                'year': year\n",
        "            })\n",
        "\n",
        "        return papers\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Failed to parse PubMed XML: {e}\")\n",
        "        return []\n",
        "\n",
        "def search_pubmed(query, max_results=5, api_key=None):\n",
        "    \"\"\"\n",
        "    Search PubMed for relevant medical literature with proper API key usage and rate limiting.\n",
        "    \"\"\"\n",
        "\n",
        "    # Construct PubMed API URLs\n",
        "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
        "    fetch_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
        "\n",
        "    # Prepare search parameters with API key\n",
        "    params = {\n",
        "        'db': 'pubmed',\n",
        "        'term': query,\n",
        "        'retmax': max_results,\n",
        "        'retmode': 'json',\n",
        "        'sort': 'relevance'\n",
        "    }\n",
        "\n",
        "    # Add API key if provided\n",
        "    if api_key:\n",
        "        params['api_key'] = api_key\n",
        "\n",
        "    try:\n",
        "        # Search for papers\n",
        "        search_response = requests.get(base_url, params=params, timeout=10)\n",
        "        search_response.raise_for_status()\n",
        "        search_data = search_response.json()\n",
        "\n",
        "        # Extract PMIDs\n",
        "        pmids = search_data.get('esearchresult', {}).get('idlist', [])\n",
        "\n",
        "        if not pmids:\n",
        "            return {\n",
        "                'papers': [],\n",
        "                'abstracts': [],\n",
        "                'total_papers': 0,\n",
        "                'confidence_boost': 0,\n",
        "                'literature_evidence': 'No relevant literature found'\n",
        "            }\n",
        "\n",
        "        # Fetch paper details with rate limiting\n",
        "        fetch_params = {\n",
        "            'db': 'pubmed',\n",
        "            'id': ','.join(pmids),\n",
        "            'retmode': 'xml',\n",
        "            'rettype': 'abstract'\n",
        "        }\n",
        "\n",
        "        # Add API key to fetch request as well\n",
        "        if api_key:\n",
        "            fetch_params['api_key'] = api_key\n",
        "\n",
        "        # Rate limiting - add delay to respect API limits\n",
        "        time.sleep(0.2)  # 200ms delay between requests\n",
        "\n",
        "        fetch_response = requests.get(fetch_url, params=fetch_params, timeout=10)\n",
        "        fetch_response.raise_for_status()\n",
        "\n",
        "        # Parse XML response\n",
        "        papers = parse_pubmed_xml(fetch_response.text)\n",
        "\n",
        "        # Add relevance scores and abstracts\n",
        "        abstracts = []\n",
        "        for i, paper in enumerate(papers):\n",
        "            if 'relevance_score' not in paper:\n",
        "                paper['relevance_score'] = max(0.7, 1.0 - i * 0.1)  # Decreasing relevance\n",
        "            abstracts.append(f\"Abstract of study examining {query}. Findings support current medical understanding.\")\n",
        "\n",
        "        # Calculate confidence boost based on literature quality\n",
        "        confidence_boost = min(0.3, len(papers) * 0.1)  # Max 30% confidence boost\n",
        "\n",
        "        literature_evidence = f\"Found {len(papers)} relevant studies. \"\n",
        "        if len(papers) >= 2:\n",
        "            literature_evidence += \"Strong literature support.\"\n",
        "        elif len(papers) == 1:\n",
        "            literature_evidence += \"Moderate literature support.\"\n",
        "        else:\n",
        "            literature_evidence += \"Limited literature support.\"\n",
        "\n",
        "        return {\n",
        "            'papers': papers,\n",
        "            'abstracts': abstracts,\n",
        "            'total_papers': len(papers),\n",
        "            'confidence_boost': confidence_boost,\n",
        "            'literature_evidence': literature_evidence\n",
        "        }\n",
        "\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        if e.response.status_code == 429:\n",
        "            logger.warning(f\"PubMed API rate limit exceeded for query '{query}'. Consider using an API key.\")\n",
        "            # Return empty results instead of failing\n",
        "            return {\n",
        "                'papers': [],\n",
        "                'abstracts': [],\n",
        "                'total_papers': 0,\n",
        "                'confidence_boost': 0,\n",
        "                'literature_evidence': 'API rate limit exceeded. Try again later.'\n",
        "            }\n",
        "        else:\n",
        "            logger.warning(f\"PubMed search failed for query '{query}': {e}\")\n",
        "            return {\n",
        "                'papers': [],\n",
        "                'abstracts': [],\n",
        "                'total_papers': 0,\n",
        "                'confidence_boost': 0,\n",
        "                'literature_evidence': f'Literature search error: {str(e)}'\n",
        "            }\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"PubMed search failed for query '{query}': {e}\")\n",
        "        return {\n",
        "            'papers': [],\n",
        "            'abstracts': [],\n",
        "            'total_papers': 0,\n",
        "            'confidence_boost': 0,\n",
        "            'literature_evidence': f'Literature search error: {str(e)}'\n",
        "        }\n",
        "\n",
        "def enhance_claim_with_literature(claim, verdict):\n",
        "    \"\"\"\n",
        "    Enhance claim evaluation with PubMed literature search.\n",
        "    \"\"\"\n",
        "\n",
        "    # Construct search query based on claim and verdict\n",
        "    if verdict == 'Supported by Evidence':\n",
        "        # Look for supporting evidence\n",
        "        search_query = f\"{claim} AND (clinical trial OR meta-analysis OR systematic review)\"\n",
        "    else:\n",
        "        # Look for contradicting evidence or studies showing no effect\n",
        "        search_query = f\"{claim} AND (no effect OR contradicts OR systematic review)\"\n",
        "\n",
        "    # Perform PubMed search\n",
        "    pubmed_results = search_pubmed(search_query, max_results=5, api_key=PUBMED_TOKEN)\n",
        "\n",
        "    # Generate enhanced evidence text\n",
        "    if pubmed_results['total_papers'] > 0:\n",
        "        literature_summary = f\"PubMed literature review found {pubmed_results['total_papers']} relevant papers. \"\n",
        "        literature_summary += pubmed_results['literature_evidence']\n",
        "        enhanced_evidence = f\"{pubmed_results['literature_evidence']} {pubmed_results['abstracts'][0][:200]}...\"\n",
        "    else:\n",
        "        literature_summary = \"No relevant PubMed literature found for this claim.\"\n",
        "        enhanced_evidence = f\"No PubMed literature available. {pubmed_results['literature_evidence']}\"\n",
        "\n",
        "    return {\n",
        "        'enhanced_evidence': enhanced_evidence,\n",
        "        'literature_summary': literature_summary,\n",
        "        'confidence_boost': pubmed_results['confidence_boost'],\n",
        "        'papers_found': pubmed_results['total_papers'],\n",
        "        'papers': pubmed_results['papers']\n",
        "    }\n",
        "\n",
        "def build_knowledge_graph_for_claim(claim, evidence, papers, claim_id):\n",
        "    \"\"\"\n",
        "    Build knowledge graph for a single claim-evidence pair with paper citations.\n",
        "    \"\"\"\n",
        "\n",
        "    kg = MedicalKnowledgeGraph()\n",
        "\n",
        "    # Add nodes\n",
        "    claim_node_id = kg.add_claim_node(claim, claim_id)\n",
        "    evidence_node_id = kg.add_evidence_node(evidence, claim_id)\n",
        "\n",
        "    # Add paper nodes\n",
        "    paper_node_ids = []\n",
        "    paper_metadata = {}\n",
        "    for i, paper in enumerate(papers):\n",
        "        paper_node_id = kg.add_paper_node(paper, f\"{claim_id}_{i}\")\n",
        "        paper_node_ids.append(paper_node_id)\n",
        "        paper_metadata[paper_node_id] = paper\n",
        "\n",
        "    # Add entity nodes (simplified extraction)\n",
        "    entities = extract_medical_entities(claim)\n",
        "    entity_node_ids = []\n",
        "    for entity, entity_type in entities:\n",
        "        entity_node_id = kg.add_entity_node(entity, entity_type)\n",
        "        entity_node_ids.append(entity_node_id)\n",
        "\n",
        "    # Add edges\n",
        "    # Claim-Evidence relationship\n",
        "    kg.add_edge(claim_node_id, evidence_node_id, 'related', weight=1.0)\n",
        "    kg.add_edge(evidence_node_id, claim_node_id, 'related', weight=1.0)\n",
        "\n",
        "    # Evidence-Paper relationships\n",
        "    for paper_node_id in paper_node_ids:\n",
        "        kg.add_edge(evidence_node_id, paper_node_id, 'supports', weight=0.8)\n",
        "        kg.add_edge(paper_node_id, evidence_node_id, 'related', weight=0.6)\n",
        "\n",
        "    # Claim-Entity relationships\n",
        "    for entity_node_id in entity_node_ids:\n",
        "        kg.add_edge(claim_node_id, entity_node_id, 'mentions', weight=0.7)\n",
        "        kg.add_edge(entity_node_id, claim_node_id, 'mentioned_in', weight=0.7)\n",
        "\n",
        "    # Paper-Paper citations (simplified - in practice, extract from references)\n",
        "    # For demonstration, create citation network based on relevance scores\n",
        "    if len(paper_node_ids) > 1:\n",
        "        # Sort papers by relevance score\n",
        "        paper_scores = [(pid, paper_metadata[pid].get('relevance_score', 0.5)) for pid in paper_node_ids]\n",
        "        paper_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Create citation links from higher relevance to lower relevance papers\n",
        "        for i in range(len(paper_scores) - 1):\n",
        "            source_pid = paper_scores[i][0]\n",
        "            target_pid = paper_scores[i + 1][0]\n",
        "            citation_weight = 0.5 + (paper_scores[i][1] - paper_scores[i + 1][1]) * 2\n",
        "            kg.add_edge(source_pid, target_pid, 'cites', weight=min(1.0, citation_weight))\n",
        "\n",
        "    return kg\n",
        "\n",
        "def extract_medical_entities(text):\n",
        "    \"\"\"\n",
        "    Simple medical entity extraction (in practice, use medical NER models).\n",
        "    Returns list of (entity, type) tuples.\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return []\n",
        "    # Simplified entity extraction\n",
        "    entities = []\n",
        "\n",
        "    # Disease keywords\n",
        "    diseases = ['disease', 'disorder', 'syndrome', 'condition', 'infection', 'cancer', 'diabetes', 'hypertension', 'obesity']\n",
        "    for disease in diseases:\n",
        "        if disease in text.lower():\n",
        "            entities.append((disease, 'disease'))\n",
        "\n",
        "    # Treatment keywords\n",
        "    treatments = ['treatment', 'therapy', 'medication', 'drug', 'vaccine', 'sweetener', 'sugar', 'additive']\n",
        "    for treatment in treatments:\n",
        "        if treatment in text.lower():\n",
        "            entities.append((treatment, 'treatment'))\n",
        "\n",
        "    # Symptom keywords\n",
        "    symptoms = ['symptom', 'sign', 'effect', 'impact', 'risk', 'mortality', 'weight', 'cancer']\n",
        "    for symptom in symptoms:\n",
        "        if symptom in text.lower():\n",
        "            entities.append((symptom, 'symptom'))\n",
        "\n",
        "    return entities\n",
        "\n",
        "def load_and_preprocess_medical_data(visualize=True, use_pubmed=True, use_gnn=True):\n",
        "    \"\"\"\n",
        "    Load and preprocess sample medical fact-checking data with imbalanced distribution\n",
        "    and optional PubMed literature + GNN integration.\n",
        "    \"\"\"\n",
        "    logger.info(\"Loading and preprocessing medical data...\")\n",
        "\n",
        "    # Base medical claims - realistic examples\n",
        "    base_claims_supported = [\n",
        "        \"Regular exercise reduces cardiovascular disease risk.\",\n",
        "        \"Mediterranean diet promotes longevity.\",\n",
        "        \"Chronic stress weakens immune function.\",\n",
        "        \"Sleep deprivation impairs cognitive performance.\",\n",
        "        \"Breastfeeding boosts infant immunity.\",\n",
        "        \"Omega-3 fatty acids benefit heart health.\",\n",
        "        \"High fiber diet reduces colon cancer risk.\",\n",
        "        \"Sun exposure in moderation provides vitamin D benefits.\",\n",
        "        \"Probiotics support digestive health.\",\n",
        "        \"Mindfulness meditation reduces anxiety.\",\n",
        "        \"Vaccination prevents infectious diseases.\",\n",
        "        \"Hand washing prevents disease transmission.\",\n",
        "        \"Adequate hydration supports kidney function.\",\n",
        "        \"Strength training maintains muscle mass with aging.\",\n",
        "        \"Fruits and vegetables provide essential antioxidants.\"\n",
        "    ]\n",
        "\n",
        "    base_claims_refuted = [\n",
        "        \"Vitamin C can cure the common cold.\",\n",
        "        \"Antibiotics treat viral infections.\",\n",
        "        \"Probiotics cure serious bacterial infections.\",\n",
        "        \"Eating carrots significantly improves night vision.\",\n",
        "        \"Vaccines cause autism.\",\n",
        "        \"Drinking exactly 8 glasses of water daily is required.\",\n",
        "        \"MSG causes headaches in everyone.\",\n",
        "        \"Microwave cooking destroys all nutrients.\",\n",
        "        \"Red wine consumption is always heart-healthy.\",\n",
        "        \"Artificial sweeteners cause cancer.\",\n",
        "        \"Detox diets are necessary for body cleansing.\",\n",
        "        \"Protein intake damages healthy kidneys.\",\n",
        "        \"Crash diets are effective for long-term weight loss.\",\n",
        "        \"Supplements replace a balanced diet.\",\n",
        "        \"All fats are bad for health.\",\n",
        "        \"Organic food always prevents disease.\",\n",
        "        \"Homeopathy cures serious illnesses.\",\n",
        "        \"Essential oils cure chronic conditions.\",\n",
        "        \"Fasting cleanses toxins from organs.\",\n",
        "        \"Alkaline water prevents cancer.\"\n",
        "    ]\n",
        "\n",
        "    # Simulate a larger, imbalanced dataset (~90% Refuted)\n",
        "    num_supported = 10  # Reduced for testing\n",
        "    num_refuted = int(0.9 * (len(base_claims_supported) + len(base_claims_refuted)) * 2)\n",
        "\n",
        "    supported_claims = np.random.choice(base_claims_supported, size=num_supported, replace=True).tolist()\n",
        "    refuted_claims = np.random.choice(base_claims_refuted, size=num_refuted, replace=True).tolist()\n",
        "\n",
        "    all_claims = supported_claims + refuted_claims\n",
        "    all_verdicts = ['Supported by Evidence'] * len(supported_claims) + ['Refuted by Evidence'] * len(refuted_claims)\n",
        "\n",
        "    combined = list(zip(all_claims, all_verdicts))\n",
        "    np.random.shuffle(combined)\n",
        "    claims_shuffled, verdicts_shuffled = zip(*combined)\n",
        "    claims_shuffled, verdicts_shuffled = list(claims_shuffled), list(verdicts_shuffled)\n",
        "\n",
        "    # Generate corresponding evidence texts with optional PubMed integration\n",
        "    evidence_texts = []\n",
        "    labels = []\n",
        "    literature_info = []\n",
        "    knowledge_graphs = []\n",
        "\n",
        "    print(\"🔍 Integrating PubMed literature search and GNN knowledge graphs...\")\n",
        "\n",
        "    for i, (claim, verdict) in enumerate(zip(claims_shuffled, verdicts_shuffled)):\n",
        "        if i % 5 == 0:  # Progress indicator\n",
        "            print(f\"  Processing claim {i+1}/{len(claims_shuffled)}: {claim[:50] if claim else 'Unknown Claim'}...\")\n",
        "\n",
        "        if verdict == 'Supported by Evidence':\n",
        "            # Generate supporting evidence\n",
        "            base_evidence = f\"Clinical studies and meta-analyses consistently demonstrate that {claim.lower()[:-1] if claim else 'unknown claim'} is supported by robust scientific evidence.\"\n",
        "            label = 1  # Supported\n",
        "        else:\n",
        "            # Generate refuting evidence\n",
        "            base_evidence = f\"Epidemiological research and systematic reviews show that {claim.lower()[:-1] if claim else 'unknown claim'} is contradicted by current medical understanding.\"\n",
        "            label = 0  # Refuted\n",
        "\n",
        "        # Integrate PubMed literature if enabled\n",
        "        if use_pubmed:\n",
        "            literature_results = enhance_claim_with_literature(claim, verdict)\n",
        "            enhanced_evidence = f\"{base_evidence} {literature_results['enhanced_evidence']}\"\n",
        "            literature_summary = literature_results['literature_summary']\n",
        "            papers = literature_results['papers']\n",
        "        else:\n",
        "            enhanced_evidence = base_evidence\n",
        "            literature_summary = \"PubMed integration disabled\"\n",
        "            papers = []\n",
        "\n",
        "        # Build knowledge graph if GNN is enabled\n",
        "        if use_gnn:\n",
        "            kg = build_knowledge_graph_for_claim(claim, enhanced_evidence, papers, i)\n",
        "            knowledge_graphs.append(kg)\n",
        "        else:\n",
        "            # Create empty knowledge graph\n",
        "            kg = MedicalKnowledgeGraph()\n",
        "            knowledge_graphs.append(kg)\n",
        "\n",
        "        evidence_texts.append(enhanced_evidence)\n",
        "        labels.append(label)\n",
        "        literature_info.append(literature_summary)\n",
        "\n",
        "        # Rate limiting for PubMed API - only when actually making requests\n",
        "        if use_pubmed and literature_results['papers_found'] > 0:\n",
        "            time.sleep(0.1)  # Brief delay to respect API limits\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'medical_claim': claims_shuffled,\n",
        "        'evidence_text': evidence_texts,\n",
        "        'label': labels,\n",
        "        'verdict_text': verdicts_shuffled,\n",
        "        'literature_info': literature_info\n",
        "    })\n",
        "\n",
        "    logger.info(f\"Loaded {len(df)} medical claim-evidence pairs\")\n",
        "    logger.info(f\"Class distribution - Supported: {sum(labels)}, Refuted: {len(labels) - sum(labels)}\")\n",
        "\n",
        "    return df, knowledge_graphs\n",
        "\n",
        "def visualize_all_graphs(knowledge_graphs, save_path='complete_knowledge_graph.png'):\n",
        "    \"\"\"\n",
        "    Visualize all knowledge graphs combined into one comprehensive graph.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n🎨 Creating comprehensive visualization of all knowledge graphs...\")\n",
        "\n",
        "    # Create a unified graph combining all individual graphs\n",
        "    unified_kg = MedicalKnowledgeGraph()\n",
        "    node_mapping = {}  # Map old node IDs to new unified IDs\n",
        "    paper_citations = []  # Store citation relationships\n",
        "\n",
        "    # Process each knowledge graph\n",
        "    for kg_idx, kg in enumerate(knowledge_graphs):\n",
        "        # Add all nodes from this graph\n",
        "        for i, (node_name, node_type) in enumerate(zip(kg.nodes, kg.node_types)):\n",
        "            if node_name not in node_mapping:\n",
        "                # Add node to unified graph\n",
        "                metadata = kg.node_metadata.get(node_name, {})\n",
        "                if node_type == 'claim':\n",
        "                    unified_kg.add_claim_node(metadata.get('full_text', ''),\n",
        "                                            metadata.get('id', kg_idx))\n",
        "                elif node_type == 'evidence':\n",
        "                    unified_kg.add_evidence_node(metadata.get('full_text', ''),\n",
        "                                               metadata.get('id', kg_idx))\n",
        "                elif node_type == 'paper':\n",
        "                    unified_kg.add_paper_node(metadata,\n",
        "                                            metadata.get('id', kg_idx))\n",
        "                elif node_type == 'entity':\n",
        "                    unified_kg.add_entity_node(metadata.get('name', ''),\n",
        "                                             metadata.get('entity_type', ''))\n",
        "\n",
        "                node_mapping[node_name] = len(unified_kg.nodes) - 1\n",
        "\n",
        "        # Add all edges from this graph\n",
        "        for source_id, target_id, relation, weight in kg.edges:\n",
        "            source_name = kg.nodes[source_id]\n",
        "            target_name = kg.nodes[target_id]\n",
        "\n",
        "            if source_name in node_mapping and target_name in node_mapping:\n",
        "                unified_kg.add_edge(node_mapping[source_name],\n",
        "                                  node_mapping[target_name],\n",
        "                                  relation, weight)\n",
        "\n",
        "    # Visualize the unified graph\n",
        "    try:\n",
        "        print(\"  Creating comprehensive graph visualization...\")\n",
        "        graph_nx = unified_kg.visualize_graph(show_all=True, save_path=save_path)\n",
        "        print(f\"  ✅ Complete knowledge graph visualization saved to {save_path}\")\n",
        "\n",
        "        return unified_kg\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Failed to create comprehensive visualization: {e}\")\n",
        "        return None\n",
        "\n",
        "def train_and_evaluate_medical_baseline(model_name='roberta-base', epochs=2, batch_size=4, learning_rate=2e-5, visualize=True, use_pubmed=True, use_gnn=True):\n",
        "    \"\"\"\n",
        "    Main function to load medical data, prepare model, train, and evaluate the hybrid system,\n",
        "    including visualizations of the process and results.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting Hybrid Medical Fact Checking (RoBERTa + PubMed + GNN)...\")\n",
        "\n",
        "    # 1. Load and preprocess medical data\n",
        "    df, knowledge_graphs = load_and_preprocess_medical_data(visualize=visualize, use_pubmed=use_pubmed, use_gnn=use_gnn)\n",
        "    if df.empty:\n",
        "        logger.error(\"No medical data available after preprocessing. Exiting.\")\n",
        "        return None, None, 0, \"No data\"\n",
        "\n",
        "    # 2. Visualize all knowledge graphs combined\n",
        "    if visualize and use_gnn and knowledge_graphs:\n",
        "        unified_graph = visualize_all_graphs(knowledge_graphs, save_path='complete_knowledge_graph.png')\n",
        "\n",
        "    # 3. Prepare data for training\n",
        "    claims = df['medical_claim'].tolist()\n",
        "    evidences = df['evidence_text'].tolist()\n",
        "    labels = df['label'].tolist()\n",
        "\n",
        "    train_claims, val_claims, train_evidences, val_evidences, train_labels, val_labels = train_test_split(\n",
        "        claims, evidences, labels, test_size=0.2, random_state=42, stratify=labels\n",
        "    )\n",
        "\n",
        "    # Split knowledge graphs accordingly\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        range(len(claims)), test_size=0.2, random_state=42, stratify=labels\n",
        "    )\n",
        "    train_knowledge_graphs = [knowledge_graphs[i] for i in train_indices] if knowledge_graphs else []\n",
        "    val_knowledge_graphs = [knowledge_graphs[i] for i in val_indices] if knowledge_graphs else []\n",
        "\n",
        "    # Convert knowledge graphs to PyTorch Geometric data\n",
        "    train_graph_data = [kg.build_torch_geometric_data() for kg in train_knowledge_graphs] if train_knowledge_graphs else []\n",
        "    val_graph_data = [kg.build_torch_geometric_data() for kg in val_knowledge_graphs] if val_knowledge_graphs else []\n",
        "\n",
        "    if visualize:\n",
        "        split_data = pd.DataFrame({\n",
        "            'Split': ['Train'] * len(train_labels) + ['Validation'] * len(val_labels),\n",
        "            'Label': train_labels + val_labels\n",
        "        })\n",
        "        label_names = {0: 'Refuted', 1: 'Supported'}\n",
        "        split_data['Label_Name'] = split_data['Label'].map(label_names)\n",
        "\n",
        "        plt.figure(figsize=(12, 5))\n",
        "        ax1 = plt.subplot(1, 2, 1)\n",
        "        split_counts = split_data['Split'].value_counts()\n",
        "        sns.barplot(x=split_counts.index, y=split_counts.values, palette='Set2', ax=ax1)\n",
        "        ax1.set_title('Data Split Sizes')\n",
        "        ax1.set_ylabel('Number of Samples')\n",
        "\n",
        "        ax2 = plt.subplot(1, 2, 2)\n",
        "        crosstab_df = pd.crosstab(split_data['Split'], split_data['Label_Name'])\n",
        "        crosstab_df.plot(kind='bar', ax=ax2, color=['salmon', 'skyblue'])\n",
        "        ax2.set_title('Label Distribution in Splits')\n",
        "        ax2.set_xlabel('Data Split')\n",
        "        ax2.set_ylabel('Count')\n",
        "        ax2.legend(title='Verdict')\n",
        "        plt.xticks(rotation=0)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        logger.info(\"Displayed data split visualization.\")\n",
        "\n",
        "    # 4. Load tokenizer and RoBERTa model using HF_TOKEN\n",
        "    logger.info(f\"Loading tokenizer and model '{model_name}' from Hugging Face...\")\n",
        "    try:\n",
        "        # Pass the token when loading from_pretrained\n",
        "        tokenizer_kwargs = {\"use_auth_token\": HF_TOKEN} if HF_TOKEN else {}\n",
        "        model_kwargs = {\"use_auth_token\": HF_TOKEN} if HF_TOKEN else {}\n",
        "\n",
        "        tokenizer = RobertaTokenizer.from_pretrained(model_name, **tokenizer_kwargs)\n",
        "        roberta_model = RobertaModel.from_pretrained(model_name, **model_kwargs)\n",
        "        logger.info(\"Tokenizer and RoBERTa model loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to load tokenizer or model '{model_name}': {e}\")\n",
        "        return None, None, 0, f\"Load Error: {e}\"\n",
        "\n",
        "    # 5. Initialize GNN model\n",
        "    if use_gnn:\n",
        "        gnn_model = GNNFactChecker(num_node_features=3, hidden_dim=64, num_classes=2)\n",
        "        hybrid_model = HybridFactChecker(roberta_model, gnn_model)\n",
        "        logger.info(\"GNN and Hybrid model initialized successfully.\")\n",
        "    else:\n",
        "        # Fallback to RoBERTa-only model\n",
        "        hybrid_model = roberta_model\n",
        "        logger.info(\"Using RoBERTa-only model (GNN disabled).\")\n",
        "\n",
        "    # 6. Create datasets and dataloaders\n",
        "    train_dataset = MedicalFactCheckingDataset(train_claims, train_evidences, train_labels, tokenizer)\n",
        "    val_dataset = MedicalFactCheckingDataset(val_claims, val_evidences, val_labels, tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # 7. Setup training\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    hybrid_model.to(device)\n",
        "    optimizer = AdamW(hybrid_model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Store metrics for each epoch\n",
        "    epoch_metrics = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'val_accuracy': [],\n",
        "        'val_precision': [],\n",
        "        'val_recall': [],\n",
        "        'val_f1': []\n",
        "    }\n",
        "\n",
        "    # 8. Training loop with epoch-by-epoch results\n",
        "    logger.info(\"Starting training loop...\")\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Training phase\n",
        "        hybrid_model.train()\n",
        "        total_train_loss = 0\n",
        "        train_steps = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels_batch = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass (simplified - in practice, handle graph data properly)\n",
        "            if use_gnn:\n",
        "                # This is a simplified approach - in practice, you'd batch graph data properly\n",
        "                roberta_outputs = hybrid_model.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                outputs = roberta_outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "                # Add simple classification head\n",
        "                classifier = nn.Linear(outputs.size(-1), 2).to(device)\n",
        "                outputs = classifier(outputs)\n",
        "            else:\n",
        "                # RoBERTa-only forward pass\n",
        "                roberta_outputs = hybrid_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                outputs = roberta_outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "                # Add simple classification head for RoBERTa-only\n",
        "                classifier = nn.Linear(outputs.size(-1), 2).to(device)\n",
        "                outputs = classifier(outputs)\n",
        "\n",
        "            # Compute loss\n",
        "            if len(outputs.shape) == 1:\n",
        "                outputs = outputs.unsqueeze(0)\n",
        "            loss = F.cross_entropy(outputs, labels_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "            train_steps += 1\n",
        "\n",
        "            if batch_idx % 2 == 0:  # Print every 2 batches\n",
        "                print(f\"  Batch {batch_idx}: Train Loss = {loss.item():.4f}\")\n",
        "\n",
        "        avg_train_loss = total_train_loss / train_steps if train_steps > 0 else 0\n",
        "        epoch_metrics['train_loss'].append(avg_train_loss)\n",
        "\n",
        "        # Validation phase\n",
        "        hybrid_model.eval()\n",
        "        total_val_loss = 0\n",
        "        val_predictions = []\n",
        "        val_true_labels = []\n",
        "        val_steps = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels_batch = batch['labels'].to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                if use_gnn:\n",
        "                    roberta_outputs = hybrid_model.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                    outputs = roberta_outputs.last_hidden_state[:, 0, :]\n",
        "                    classifier = nn.Linear(outputs.size(-1), 2).to(device)\n",
        "                    outputs = classifier(outputs)\n",
        "                else:\n",
        "                    roberta_outputs = hybrid_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                    outputs = roberta_outputs.last_hidden_state[:, 0, :]\n",
        "                    classifier = nn.Linear(outputs.size(-1), 2).to(device)\n",
        "                    outputs = classifier(outputs)\n",
        "\n",
        "                if len(outputs.shape) == 1:\n",
        "                    outputs = outputs.unsqueeze(0)\n",
        "\n",
        "                loss = F.cross_entropy(outputs, labels_batch)\n",
        "                logits = outputs\n",
        "\n",
        "                total_val_loss += loss.item()\n",
        "                val_steps += 1\n",
        "\n",
        "                predictions = torch.argmax(logits, dim=-1)\n",
        "                val_predictions.extend(predictions.cpu().numpy())\n",
        "                val_true_labels.extend(labels_batch.cpu().numpy())\n",
        "\n",
        "        avg_val_loss = total_val_loss / val_steps if val_steps > 0 else 0\n",
        "        accuracy = accuracy_score(val_true_labels, val_predictions) if val_true_labels and val_predictions else 0\n",
        "        if val_true_labels and val_predictions:\n",
        "            precision, recall, f1, _ = precision_recall_fscore_support(val_true_labels, val_predictions, average='weighted')\n",
        "        else:\n",
        "            precision = recall = f1 = 0\n",
        "\n",
        "        # Store metrics\n",
        "        epoch_metrics['val_loss'].append(avg_val_loss)\n",
        "        epoch_metrics['val_accuracy'].append(accuracy)\n",
        "        epoch_metrics['val_precision'].append(precision)\n",
        "        epoch_metrics['val_recall'].append(recall)\n",
        "        epoch_metrics['val_f1'].append(f1)\n",
        "\n",
        "        # Print epoch results\n",
        "        print(f\"\\nEpoch {epoch + 1} Results:\")\n",
        "        print(f\"  Average Train Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"  Average Val Loss: {avg_val_loss:.4f}\")\n",
        "        print(f\"  Validation Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"  Validation Precision: {precision:.4f}\")\n",
        "        print(f\"  Validation Recall: {recall:.4f}\")\n",
        "        print(f\"  Validation F1-Score: {f1:.4f}\")\n",
        "\n",
        "        # Confusion matrix for current epoch\n",
        "        if val_true_labels and val_predictions:\n",
        "            cm = confusion_matrix(val_true_labels, val_predictions)\n",
        "            print(f\"  Confusion Matrix: {cm.flatten()}\")\n",
        "\n",
        "    # 9. Final evaluation and visualization\n",
        "    final_accuracy = epoch_metrics['val_accuracy'][-1] if epoch_metrics['val_accuracy'] else 0\n",
        "    final_f1 = epoch_metrics['val_f1'][-1] if epoch_metrics['val_f1'] else 0\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"FINAL MODEL PERFORMANCE\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Final Accuracy: {final_accuracy:.4f}\")\n",
        "    print(f\"Final F1-Score: {final_f1:.4f}\")\n",
        "\n",
        "    # Create comprehensive visualization dashboard\n",
        "    if visualize:\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        fig.suptitle('Hybrid Medical Fact-Checking Training Dashboard', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # 1. Training and Validation Loss\n",
        "        axes[0, 0].plot(range(1, len(epoch_metrics['train_loss']) + 1), epoch_metrics['train_loss'], 'b-', marker='o', label='Train Loss')\n",
        "        axes[0, 0].plot(range(1, len(epoch_metrics['val_loss']) + 1), epoch_metrics['val_loss'], 'r-', marker='s', label='Val Loss')\n",
        "        axes[0, 0].set_title('Training and Validation Loss')\n",
        "        axes[0, 0].set_xlabel('Epoch')\n",
        "        axes[0, 0].set_ylabel('Loss')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True)\n",
        "\n",
        "        # 2. Accuracy over epochs\n",
        "        axes[0, 1].plot(range(1, len(epoch_metrics['val_accuracy']) + 1), epoch_metrics['val_accuracy'], 'g-', marker='o')\n",
        "        axes[0, 1].set_title('Validation Accuracy')\n",
        "        axes[0, 1].set_xlabel('Epoch')\n",
        "        axes[0, 1].set_ylabel('Accuracy')\n",
        "        axes[0, 1].grid(True)\n",
        "\n",
        "        # 3. Precision, Recall, F1 over epochs\n",
        "        axes[0, 2].plot(range(1, len(epoch_metrics['val_precision']) + 1), epoch_metrics['val_precision'], 'b-', marker='o', label='Precision')\n",
        "        axes[0, 2].plot(range(1, len(epoch_metrics['val_recall']) + 1), epoch_metrics['val_recall'], 'r-', marker='s', label='Recall')\n",
        "        axes[0, 2].plot(range(1, len(epoch_metrics['val_f1']) + 1), epoch_metrics['val_f1'], 'g-', marker='^', label='F1-Score')\n",
        "        axes[0, 2].set_title('Validation Metrics')\n",
        "        axes[0, 2].set_xlabel('Epoch')\n",
        "        axes[0, 2].set_ylabel('Score')\n",
        "        axes[0, 2].legend()\n",
        "        axes[0, 2].grid(True)\n",
        "\n",
        "        # 4. Final confusion matrix\n",
        "        if val_true_labels and val_predictions:\n",
        "            final_cm = confusion_matrix(val_true_labels, val_predictions)\n",
        "            sns.heatmap(final_cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0])\n",
        "            axes[1, 0].set_title('Final Confusion Matrix')\n",
        "            axes[1, 0].set_xlabel('Predicted')\n",
        "            axes[1, 0].set_ylabel('Actual')\n",
        "\n",
        "        # 5. Class distribution in validation set\n",
        "        val_label_counts = Counter(val_true_labels)\n",
        "        class_names = ['Refuted', 'Supported']\n",
        "        class_counts = [val_label_counts[0], val_label_counts[1]] if val_true_labels else [0, 0]\n",
        "\n",
        "        # Fix deprecation warning for palette\n",
        "        bars = axes[1, 1].bar(class_names, class_counts, color=['#FF6B6B', '#4ECDC4'])\n",
        "        axes[1, 1].set_title('Validation Set Class Distribution')\n",
        "        axes[1, 1].set_ylabel('Count')\n",
        "        axes[1, 1].bar_label(bars)\n",
        "\n",
        "        # 6. Performance metrics comparison\n",
        "        final_metrics = [final_accuracy,\n",
        "                        epoch_metrics['val_precision'][-1] if epoch_metrics['val_precision'] else 0,\n",
        "                        epoch_metrics['val_recall'][-1] if epoch_metrics['val_recall'] else 0,\n",
        "                        final_f1]\n",
        "        metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "\n",
        "        # Fix deprecation warning for palette\n",
        "        bars = axes[1, 2].bar(metric_names, final_metrics, color=['#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD'])\n",
        "        axes[1, 2].set_title('Final Performance Metrics')\n",
        "        axes[1, 2].set_ylabel('Score')\n",
        "        axes[1, 2].set_ylim(0, 1)\n",
        "        axes[1, 2].bar_label(bars, fmt='%.3f')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('training_dashboard.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    # Print detailed summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"📊 TRAINING SUMMARY\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Model Configuration:\")\n",
        "    print(f\"  Base Model: {model_name}\")\n",
        "    print(f\"  Epochs: {epochs}\")\n",
        "    print(f\"  Batch Size: {batch_size}\")\n",
        "    print(f\"  Learning Rate: {learning_rate}\")\n",
        "    print(f\"  Device: {device}\")\n",
        "    print(f\"  PubMed Integration: {'Enabled' if use_pubmed else 'Disabled'}\")\n",
        "    print(f\"  GNN Integration: {'Enabled' if use_gnn else 'Disabled'}\")\n",
        "    print(f\"\\nDataset Information:\")\n",
        "    print(f\"  Total Samples: {len(labels)}\")\n",
        "    print(f\"  Supported Claims: {sum(labels)} ({sum(labels)/len(labels)*100:.1f}%)\")\n",
        "    print(f\"  Refuted Claims: {len(labels) - sum(labels)} ({(len(labels) - sum(labels))/len(labels)*100:.1f}%)\")\n",
        "    print(f\"\\nPerformance Metrics:\")\n",
        "    print(f\"  Final Accuracy: {final_accuracy:.4f}\")\n",
        "    print(f\"  Final Precision: {epoch_metrics['val_precision'][-1] if epoch_metrics['val_precision'] else 0:.4f}\")\n",
        "    print(f\"  Final Recall: {epoch_metrics['val_recall'][-1] if epoch_metrics['val_recall'] else 0:.4f}\")\n",
        "    print(f\"  Final F1-Score: {final_f1:.4f}\")\n",
        "    if epoch_metrics['val_accuracy']:\n",
        "        print(f\"  Best Accuracy: {max(epoch_metrics['val_accuracy']):.4f}\")\n",
        "    if epoch_metrics['val_f1']:\n",
        "        print(f\"  Best F1-Score: {max(epoch_metrics['val_f1']):.4f}\")\n",
        "\n",
        "    return hybrid_model, tokenizer, final_accuracy, \"Success\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    print(\"🚀 Starting BioMedAI Medical Fact Checking with Hybrid Approach\")\n",
        "    print(\"Integrated Technologies:\")\n",
        "    print(\"  • RoBERTa: Advanced medical text understanding\")\n",
        "    print(\"  • PubMed: Real-time scientific literature search (with API key)\")\n",
        "    print(\"  • GNN: Knowledge graph reasoning and multi-hop inference\")\n",
        "    print(\"  • Graph Visualization: Interactive knowledge graph visualization\")\n",
        "    print(\"\\nDataset: Imbalanced medical claims (~90% refuted, realistic scenario)\")\n",
        "\n",
        "    # Check if API tokens are available\n",
        "    if PUBMED_TOKEN:\n",
        "        print(f\"✅ PubMed API token detected\")\n",
        "    else:\n",
        "        print(\"⚠️  No PubMed API token found. Set PUBMED_TOKEN environment variable to avoid rate limits.\")\n",
        "\n",
        "    if HF_TOKEN:\n",
        "        print(\"✅ Hugging Face token detected\")\n",
        "    else:\n",
        "        print(\"⚠️  No Hugging Face token found. Set HF_TOKEN environment variable for private models.\")\n",
        "\n",
        "    # Run training and evaluation\n",
        "    model, tokenizer, accuracy, status = train_and_evaluate_medical_baseline(\n",
        "        model_name='roberta-base',\n",
        "        epochs=3,\n",
        "        batch_size=4,  # Reduced for sample data\n",
        "        learning_rate=2e-1,\n",
        "        visualize=True,\n",
        "        use_pubmed=True,  # Enable PubMed integration\n",
        "        use_gnn=True      # Enable GNN integration\n",
        "    )\n",
        "\n",
        "    if status == \"Success\":\n",
        "        print(f\"\\n✅ Training completed successfully!\")\n",
        "        print(f\"Final model accuracy: {accuracy:.4f}\")\n",
        "        print(\"\\n🎯 Integrated Fact Checking Benefits:\")\n",
        "        print(\"  🤖 RoBERTa: Deep medical text understanding and claim analysis\")\n",
        "        print(\"  📚 PubMed: Real scientific evidence validation and confidence boosting\")\n",
        "        print(\"  🔗 GNN: Multi-hop reasoning over knowledge graphs and entity relationships\")\n",
        "        print(\"  🎨 Visualization: Interactive graph visualization for interpretability\")\n",
        "        print(\"  🔄 Hybrid: Combined strengths for robust medical fact checking\")\n",
        "        print(\"\\n🧠 Graph Neural Network Capabilities:\")\n",
        "        print(\"  • Multi-hop reasoning across medical knowledge\")\n",
        "        print(\"  • Entity relationship analysis\")\n",
        "        print(\"  • Contradiction detection in evidence\")\n",
        "        print(\"  • Confidence propagation through knowledge graphs\")\n",
        "        print(\"\\n🖼️  Enhanced Graph Visualization Features:\")\n",
        "        print(\"  • Complete integration of all test claims and papers\")\n",
        "        print(\"  • Paper citation networks with weighted edges\")\n",
        "        print(\"  • Rich node features with metadata collection\")\n",
        "        print(\"  • Scalable layout for large knowledge graphs\")\n",
        "        print(\"  • Statistical analysis dashboards\")\n",
        "        print(\"  • High-resolution export for documentation\")\n",
        "        print(\"\\nThe system demonstrates state-of-the-art medical claim evaluation.\")\n",
        "        print(\"Note: Performance on imbalanced datasets may favor majority class (Refuted).\")\n",
        "    else:\n",
        "        print(f\"\\n❌ Training failed with status: {status}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss8TpUUMWqLC",
        "outputId": "4d528578-5087-4c57-bc3e-909911953231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting BioMedAI Medical Fact Checking with Hybrid Approach\n",
            "Integrated Technologies:\n",
            "  • RoBERTa: Advanced medical text understanding\n",
            "  • PubMed: Real-time scientific literature search (with API key)\n",
            "  • GNN: Knowledge graph reasoning and multi-hop inference\n",
            "  • Graph Visualization: Interactive knowledge graph visualization\n",
            "\n",
            "Dataset: Imbalanced medical claims (~90% refuted, realistic scenario)\n",
            "✅ PubMed API token detected\n",
            "✅ Hugging Face token detected\n",
            "🔍 Integrating PubMed literature search and GNN knowledge graphs...\n",
            "  Processing claim 1/73: Microwave cooking destroys all nutrients....\n",
            "  Processing claim 6/73: Fasting cleanses toxins from organs....\n",
            "  Processing claim 11/73: Drinking exactly 8 glasses of water daily is requi...\n",
            "  Processing claim 16/73: Alkaline water prevents cancer....\n",
            "  Processing claim 21/73: Fruits and vegetables provide essential antioxidan...\n",
            "  Processing claim 26/73: Crash diets are effective for long-term weight los...\n",
            "  Processing claim 31/73: Organic food always prevents disease....\n",
            "  Processing claim 36/73: Detox diets are necessary for body cleansing....\n",
            "  Processing claim 41/73: Homeopathy cures serious illnesses....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3XPeYQQmY8mp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}