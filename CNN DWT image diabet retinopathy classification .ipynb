{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFWz9cM8vfWPCt3Y/lkrM9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAUforPython/BioMedAI/blob/main/CNN%20DWT%20image%20diabet%20retinopathy%20classification%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, here is the Google Colab code based on your requirements. It includes the CNN class with DWT preprocessing, image-by-image loading, visualization, training, evaluation, and confusion matrix computation.\n",
        "\n",
        "Diabetic Retinopathy Classification using CNN and Discrete Wavelet Transform (DWT)\n",
        "\n",
        "This notebook demonstrates a pipeline for classifying diabetic retinopathy stages\n",
        "using a Convolutional Neural Network (CNN) with Discrete Wavelet Transform (DWT)\n",
        "preprocessing. The model is trained on the APTOS 2019 dataset.\n",
        "The code processes images one-by-one to manage memory efficiently.\n",
        "\n",
        "https://www.kaggle.com/competitions/aptos2019-blindness-detection/data?select=train.csv"
      ],
      "metadata": {
        "id": "BcACPF_xcSK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyWavelets for DWT\n",
        "!pip install PyWavelets -q"
      ],
      "metadata": {
        "id": "NlIQkndVcU-_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle -q"
      ],
      "metadata": {
        "id": "BxJjMGzwePQH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Get Hugging Face and PubMed token from environment\n",
        "KG_TOKEN_NAME = userdata.get(\"KAGGLE_USER_SECRETS_TOKEN_ENV_VAR_NAME\")\n",
        "KAGGLE_KEY_TOKEN = userdata.get(\"KAGGLE_KEY\")\n",
        "\n",
        "if KAGGLE_KEY_TOKEN is None:\n",
        "  print(\"Kaggle API need to be resolved.\")\n",
        "else:\n",
        "  print(\"Kaggle API configured successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vFGOA5keaYd",
        "outputId": "ae036b2c-f108-4f28-e3fe-ee1790e69e84"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API configured successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pywt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import zipfile\n",
        "\n",
        "# Check for GPU availability\n",
        "print(\"Num GPUs Available:\", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "if tf.config.experimental.list_physical_devices('GPU'):\n",
        "    tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfEGXdj2cxAL",
        "outputId": "777650bb-90cd-407c-aa65-373a4d4594ce"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataset name and download path\n",
        "DATASET_NAME = \"aptos2019-blindness-detection\"\n",
        "DOWNLOAD_DIR = \"/content/kaggle_dataset\"\n",
        "\n",
        "# Create download directory\n",
        "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
        "\n",
        "# Download the dataset using Kaggle API\n",
        "!kaggle competitions download -c {DATASET_NAME} -p {DOWNLOAD_DIR}\n",
        "\n",
        "# Extract the downloaded zip file\n",
        "zip_file_path = os.path.join(DOWNLOAD_DIR, f\"{DATASET_NAME}.zip\")\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(DOWNLOAD_DIR)\n",
        "\n",
        "print(f\"Dataset extracted to: {DOWNLOAD_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "x7qQjzl0wcFG",
        "outputId": "d8eb4aed-cc65-4dac-9a88-397acd92dd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 4, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/__init__.py\", line 6, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 434, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/kaggle_dataset/aptos2019-blindness-detection.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-710754948.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Extract the downloaded zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mzip_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDOWNLOAD_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{DATASET_NAME}.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDOWNLOAD_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1350\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/kaggle_dataset/aptos2019-blindness-detection.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## 2. Data Preparation and Loading\n",
        "# This section handles downloading and preparing the dataset paths.\n",
        "# We assume you have uploaded the train.csv file to your Colab environment.\n",
        "\n",
        "# %%\n",
        "# Define paths\n",
        "# You need to upload your train.csv file to the Colab environment first\n",
        "# You will need to download the train.zip from Kaggle and upload it here too\n",
        "# For demonstration, we assume the train images are in a folder named 'train_images'\n",
        "# which you need to upload or mount from your Drive containing the Kaggle data.\n",
        "TRAIN_CSV_PATH = \"train.csv\" # Update if necessary\n",
        "TRAIN_IMAGES_DIR = \"train_images\" # Update this path to where your images are located\n",
        "# Example: TRAIN_IMAGES_DIR = \"/content/drive/MyDrive/kaggle_data/aptos2019-blindness-detection/train_images\"\n",
        "\n",
        "# Load the training labels\n",
        "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
        "print(f\"Loaded training CSV with {len(df_train)} samples.\")\n",
        "print(df_train.head())\n",
        "\n",
        "# Ensure the image paths are correctly formed\n",
        "df_train[\"image_path\"] = df_train[\"id_code\"].apply(lambda x: os.path.join(TRAIN_IMAGES_DIR, x + \".png\"))\n",
        "\n",
        "# Check if all images exist\n",
        "missing_images = df_train[~df_train[\"image_path\"].apply(os.path.exists)]\n",
        "if not missing_images.empty:\n",
        "    print(f\"Warning: {len(missing_images)} images listed in CSV were not found in {TRAIN_IMAGES_DIR}.\")\n",
        "    print(\"Example missing images:\")\n",
        "    print(missing_images.head())\n",
        "    # Remove missing images\n",
        "    df_train = df_train[df_train[\"image_path\"].apply(os.path.exists)]\n",
        "\n",
        "print(f\"Final training DataFrame shape after checking for files: {df_train.shape}\")"
      ],
      "metadata": {
        "id": "kWueX3aUdAH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## 3. DWT Preprocessing and Visualization\n",
        "# This section defines functions for DWT preprocessing and visualizes the process.\n",
        "\n",
        "# %%\n",
        "def apply_dwt_and_visualize(image_path, wavelet='db1', levels=2, img_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Applies Discrete Wavelet Transform (DWT) to an image and visualizes the decomposition.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input image.\n",
        "        wavelet (str): Wavelet type to use (e.g., 'db1', 'haar').\n",
        "        levels (int): Number of DWT levels to perform.\n",
        "        img_size (tuple): Target size to resize the image.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The reconstructed image from the final level approximation and details.\n",
        "    \"\"\"\n",
        "    # Read and resize the image\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Unable to read image at path: {image_path}\")\n",
        "    image = cv2.resize(image, img_size)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "\n",
        "    # Convert to grayscale for DWT visualization (optional, can apply to each channel)\n",
        "    gray_image = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY).astype(np.float32) / 255.0\n",
        "\n",
        "    # Perform DWT\n",
        "    coeffs = pywt.wavedec2(gray_image, wavelet, level=levels)\n",
        "    cA_n, (cH_n, cV_n, cD_n) = coeffs[0], coeffs[-1] # Approximation and last level details\n",
        "\n",
        "    # Visualize the original image and the DWT components\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
        "    fig.suptitle(f'DWT Decomposition (Levels={levels}, Wavelet={wavelet}) - {os.path.basename(image_path)}', fontsize=14)\n",
        "\n",
        "    axes[0, 0].imshow(gray_image, cmap='gray')\n",
        "    axes[0, 0].set_title('Original Grayscale Image')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    axes[0, 1].imshow(cA_n, cmap='gray')\n",
        "    axes[0, 1].set_title(f'Approximation Coefficients (Level {levels})')\n",
        "    axes[0, 1].axis('off')\n",
        "\n",
        "    axes[1, 0].imshow(cH_n, cmap='gray')\n",
        "    axes[1, 0].set_title(f'Horizontal Details (Level {levels})')\n",
        "    axes[1, 0].axis('off')\n",
        "\n",
        "    axes[1, 1].imshow(cV_n, cmap='gray')\n",
        "    axes[1, 1].set_title(f'Vertical Details (Level {levels})')\n",
        "    axes[1, 1].axis('off')\n",
        "\n",
        "    # Optionally, show diagonal details\n",
        "    # axes[1, 2].imshow(cD_n, cmap='gray')\n",
        "    # axes[1, 2].set_title(f'Diagonal Details (Level {levels})')\n",
        "    # axes[1, 2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # For the actual preprocessing, we might just use the approximation coefficients\n",
        "    # or reconstruct a lower-resolution version. Here, we reconstruct the full image\n",
        "    # from the final level coefficients for demonstration.\n",
        "    reconstructed_gray = pywt.waverec2(coeffs, wavelet)\n",
        "    # Ensure the reconstructed image matches the original size\n",
        "    reconstructed_gray = cv2.resize(reconstructed_gray, img_size)\n",
        "\n",
        "    return reconstructed_gray\n",
        "\n",
        "def apply_dwt_and_save(image_path, save_dir, wavelet='db1', levels=2, img_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Applies DWT to an image and saves the processed version.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input image.\n",
        "        save_dir (str): Directory to save the processed image.\n",
        "        wavelet (str): Wavelet type to use.\n",
        "        levels (int): Number of DWT levels.\n",
        "        img_size (tuple): Target size for the image.\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the saved processed image.\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Read and resize the image\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Unable to read image at path: {image_path}\")\n",
        "    image = cv2.resize(image, img_size)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "\n",
        "    # Apply DWT to each channel (RGB)\n",
        "    processed_channels = []\n",
        "    for i in range(3): # Iterate over R, G, B channels\n",
        "        channel = image[:, :, i]\n",
        "        coeffs = pywt.wavedec2(channel, wavelet, level=levels)\n",
        "        # Reconstruct from coefficients (can modify coefficients here if needed)\n",
        "        reconstructed_channel = pywt.waverec2(coeffs, wavelet)\n",
        "        # Ensure size matches\n",
        "        reconstructed_channel = cv2.resize(reconstructed_channel, img_size)\n",
        "        processed_channels.append(reconstructed_channel)\n",
        "\n",
        "    # Stack the processed channels back\n",
        "    processed_image = np.stack(processed_channels, axis=-1)\n",
        "\n",
        "    # Clip values to [0, 1] range after reconstruction\n",
        "    processed_image = np.clip(processed_image, 0.0, 1.0)\n",
        "\n",
        "    # Save the processed image\n",
        "    base_name = os.path.basename(image_path)\n",
        "    save_path = os.path.join(save_dir, base_name)\n",
        "    # Convert back to BGR for OpenCV saving\n",
        "    processed_image_bgr = cv2.cvtColor((processed_image * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
        "    cv2.imwrite(save_path, processed_image_bgr)\n",
        "\n",
        "    return save_path\n",
        "\n",
        "\n",
        "# %%\n",
        "# Example visualization of DWT on a sample image\n",
        "sample_image_path = df_train.iloc[0][\"image_path\"]\n",
        "print(f\"Sample image path: {sample_image_path}\")\n",
        "if os.path.exists(sample_image_path):\n",
        "    dwt_result = apply_dwt_and_visualize(sample_image_path, wavelet='db1', levels=2)\n",
        "    print(\"DWT visualization complete.\")\n",
        "else:\n",
        "    print(f\"Sample image does not exist: {sample_image_path}\")\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 4. Custom Dataset Generator (Image-by-Image)\n",
        "# This generator loads and preprocesses images on-the-fly during training.\n",
        "\n",
        "# %%\n",
        "class DWTImageGenerator(tf.keras.utils.Sequence):\n",
        "    \"\"\"\n",
        "    Custom Keras Sequence for loading and preprocessing images using DWT on-the-fly.\n",
        "    \"\"\"\n",
        "    def __init__(self, image_paths, labels, batch_size=32, img_size=(224, 224), wavelet='db1', levels=2, shuffle=True):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.wavelet = wavelet\n",
        "        self.levels = levels\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.image_paths))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the number of batches per epoch.\"\"\"\n",
        "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Generate one batch of data.\"\"\"\n",
        "        # Generate indices for the batch\n",
        "        start_idx = index * self.batch_size\n",
        "        end_idx = min((index + 1) * self.batch_size, len(self.indices))\n",
        "        batch_indices = self.indices[start_idx:end_idx]\n",
        "\n",
        "        # Generate data\n",
        "        batch_images = np.empty((len(batch_indices), *self.img_size, 3))\n",
        "        batch_labels = np.empty((len(batch_indices)), dtype=int)\n",
        "\n",
        "        for i, idx in enumerate(batch_indices):\n",
        "            img_path = self.image_paths.iloc[idx]\n",
        "            label = self.labels.iloc[idx]\n",
        "\n",
        "            # Load and preprocess image using DWT\n",
        "            image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "            if image is None:\n",
        "                 # Handle potential loading errors, maybe load a default or skip\n",
        "                 # For simplicity, we'll load a blank image here, but robust error handling is better\n",
        "                 image = np.zeros((*self.img_size, 3), dtype=np.uint8)\n",
        "                 print(f\"Warning: Could not load image {img_path}. Using blank image.\")\n",
        "            else:\n",
        "                image = cv2.resize(image, self.img_size)\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "\n",
        "                # Apply DWT to each channel\n",
        "                processed_channels = []\n",
        "                for ch in range(3):\n",
        "                    channel = image[:, :, ch]\n",
        "                    coeffs = pywt.wavedec2(channel, self.wavelet, level=self.levels)\n",
        "                    reconstructed_channel = pywt.waverec2(coeffs, self.wavelet)\n",
        "                    reconstructed_channel = cv2.resize(reconstructed_channel, self.img_size)\n",
        "                    processed_channels.append(reconstructed_channel)\n",
        "                image = np.stack(processed_channels, axis=-1)\n",
        "                image = np.clip(image, 0.0, 1.0) # Clip values after reconstruction\n",
        "\n",
        "            batch_images[i] = image\n",
        "            batch_labels[i] = label\n",
        "\n",
        "        return batch_images, batch_labels\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indices after each epoch.\"\"\"\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 5. Define the CNN Model\n",
        "\n",
        "# %%\n",
        "def build_cnn_model(input_shape=(224, 224, 3), num_classes=5):\n",
        "    \"\"\"\n",
        "    Builds a simple CNN model for classification.\n",
        "    \"\"\"\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    # Convolutional Block 1\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_1')(inputs)\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_2')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), name='pool1')(x)\n",
        "\n",
        "    # Convolutional Block 2\n",
        "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2_1')(x)\n",
        "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2_2')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), name='pool2')(x)\n",
        "\n",
        "    # Convolutional Block 3\n",
        "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3_1')(x)\n",
        "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3_2')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), name='pool3')(x)\n",
        "\n",
        "    # Global Average Pooling instead of Flatten + Dense for reduction\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
        "    x = tf.keras.layers.Dropout(0.5, name='dropout1')(x)\n",
        "\n",
        "    # Dense Layer\n",
        "    x = tf.keras.layers.Dense(256, activation='relu', name='dense1')(x)\n",
        "    x = tf.keras.layers.Dropout(0.5, name='dropout2')(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs, name='DWT_CNN_Model')\n",
        "    return model\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 6. Split Data and Create Generators\n",
        "\n",
        "# %%\n",
        "# Split the data\n",
        "X_paths = df_train['image_path']\n",
        "y_labels = df_train['diagnosis']\n",
        "\n",
        "# Use stratify to maintain class distribution\n",
        "X_train_paths, X_temp_paths, y_train_labels, y_temp_labels = train_test_split(\n",
        "    X_paths, y_labels, test_size=0.3, random_state=42, stratify=y_labels\n",
        ")\n",
        "X_val_paths, X_test_paths, y_val_labels, y_test_labels = train_test_split(\n",
        "    X_temp_paths, y_temp_labels, test_size=0.5, random_state=42, stratify=y_temp_labels # 0.5 x 0.3 = 0.15 for val, 0.15 for test\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(X_train_paths)}\")\n",
        "print(f\"Validation samples: {len(X_val_paths)}\")\n",
        "print(f\"Test samples: {len(X_test_paths)}\")\n",
        "\n",
        "# Compute class weights to handle imbalance\n",
        "class_weights_raw = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
        "class_weights_dict = dict(enumerate(class_weights_raw))\n",
        "print(f\"Computed class weights: {class_weights_dict}\")\n",
        "\n",
        "# Create generators\n",
        "BATCH_SIZE = 16 # Reduced batch size due to potential memory constraints in Colab\n",
        "IMG_SIZE = (224, 224)\n",
        "WAVELET_TYPE = 'db1'\n",
        "DWT_LEVELS = 2\n",
        "\n",
        "train_gen = DWTImageGenerator(\n",
        "    X_train_paths, y_train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    img_size=IMG_SIZE,\n",
        "    wavelet=WAVELET_TYPE,\n",
        "    levels=DWT_LEVELS,\n",
        "    shuffle=True\n",
        ")\n",
        "val_gen = DWTImageGenerator(\n",
        "    X_val_paths, y_val_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    img_size=IMG_SIZE,\n",
        "    wavelet=WAVELET_TYPE,\n",
        "    levels=DWT_LEVELS,\n",
        "    shuffle=False # Don't shuffle validation data\n",
        ")\n",
        "test_gen = DWTImageGenerator(\n",
        "    X_test_paths, y_test_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    img_size=IMG_SIZE,\n",
        "    wavelet=WAVELET_TYPE,\n",
        "    levels=DWT_LEVELS,\n",
        "    shuffle=False # Don't shuffle test data\n",
        ")\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 7. Train the Model\n",
        "\n",
        "# %%\n",
        "# Build the model\n",
        "model = build_cnn_model(input_shape=(*IMG_SIZE, 3), num_classes=5)\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='sparse_categorical_crossentropy', # Use sparse for integer labels\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "EPOCHS = 20 # Adjust based on your resources and time\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 8. Evaluate the Model\n",
        "\n",
        "# %%\n",
        "# Evaluate on the test set\n",
        "test_loss, test_acc = model.evaluate(test_gen, verbose=1)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 9. Plot Training History\n",
        "\n",
        "# %%\n",
        "# Plot training history\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plots the training and validation accuracy and loss.\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # Plot accuracy\n",
        "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    ax1.set_title('Model Accuracy')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Plot loss\n",
        "    ax2.plot(history.history['loss'], label='Training Loss')\n",
        "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    ax2.set_title('Model Loss')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 10. Compute and Plot Confusion Matrix\n",
        "\n",
        "# %%\n",
        "# Get predictions for the test set\n",
        "print(\"Generating predictions for confusion matrix...\")\n",
        "test_predictions = model.predict(test_gen, verbose=1)\n",
        "predicted_classes = np.argmax(test_predictions, axis=1)\n",
        "true_classes = y_test_labels.values # Get the actual labels from the series\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative DR'],\n",
        "            yticklabels=['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative DR'])\n",
        "plt.title('Confusion Matrix - Test Set')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 11. Example Prediction on a Single Image\n",
        "\n",
        "# %%\n",
        "def predict_single_image(model, image_path, wavelet='db1', levels=2, img_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Predicts the class for a single image.\n",
        "    \"\"\"\n",
        "    # Load and preprocess\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Could not load image: {image_path}\")\n",
        "    image = cv2.resize(image, img_size)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "\n",
        "    # Apply DWT\n",
        "    processed_channels = []\n",
        "    for ch in range(3):\n",
        "        channel = image[:, :, ch]\n",
        "        coeffs = pywt.wavedec2(channel, wavelet, level=levels)\n",
        "        reconstructed_channel = pywt.waverec2(coeffs, wavelet)\n",
        "        reconstructed_channel = cv2.resize(reconstructed_channel, img_size)\n",
        "        processed_channels.append(reconstructed_channel)\n",
        "    image = np.stack(processed_channels, axis=-1)\n",
        "    image = np.clip(image, 0.0, 1.0)\n",
        "\n",
        "    # Expand dimensions for batch prediction\n",
        "    image_batch = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Predict\n",
        "    prediction_probs = model.predict(image_batch, verbose=0)[0]\n",
        "    predicted_class = np.argmax(prediction_probs)\n",
        "    confidence = prediction_probs[predicted_class]\n",
        "\n",
        "    class_names = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative DR']\n",
        "    print(f\"Predicted Class: {class_names[predicted_class]} (Index: {predicted_class})\")\n",
        "    print(f\"Confidence: {confidence*100:.2f}%\")\n",
        "    print(f\"All Probabilities: {prediction_probs}\")\n",
        "\n",
        "    # Visualize the original and processed image\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    original_img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
        "    ax1.imshow(original_img)\n",
        "    ax1.set_title('Original Image')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    ax2.imshow(image)\n",
        "    ax2.set_title('DWT Preprocessed Image')\n",
        "    ax2.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return predicted_class, confidence, prediction_probs\n",
        "\n",
        "# Example prediction (use a path from your test set or another image you have)\n",
        "example_image_path = X_test_paths.iloc[0] # Use the first image from the test set\n",
        "print(f\"Predicting for image: {example_image_path}\")\n",
        "predict_single_image(model, example_image_path, wavelet=WAVELET_TYPE, levels=DWT_LEVELS, img_size=IMG_SIZE)"
      ],
      "metadata": {
        "id": "mi7ijVdgcIP1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}