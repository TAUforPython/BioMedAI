{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/jKjgdtPuy89slCGD10IY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAUforPython/BioMedAI/blob/main/ML%20TMS%20feature%20Shapley%20vectors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Install necessary packages (if not already installed in the environment) ---\n",
        "# We'll use H2O for AutoML\n",
        "!pip install h2o\n",
        "\n",
        "# --- Import necessary libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") # Suppress potential warnings\n",
        "\n",
        "# --- 1. Initialize H2O ---\n",
        "print(\"Initializing H2O...\")\n",
        "h2o.init()\n",
        "\n",
        "# --- 2. Load the data ---\n",
        "# Assuming the file is uploaded to the Colab environment\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# Upload the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(io.BytesIO(uploaded['TMS_timeseries_clusters.csv']))\n",
        "\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# --- 3. Data Preprocessing for H2O ---\n",
        "# Identify columns to use for modeling (features and potential targets)\n",
        "# Exclude 'patient_id' as it's an identifier\n",
        "all_columns = df.columns.tolist()\n",
        "feature_columns = [col for col in all_columns if col != 'patient_id']\n",
        "\n",
        "print(f\"\\nAll columns: {all_columns}\")\n",
        "print(f\"\\nFeature columns identified: {feature_columns}\")\n",
        "\n",
        "# Handle missing values (H2O can handle some NA, but for consistency in target evaluation,\n",
        "# let's drop rows with any missing values in potential target columns)\n",
        "# It's often better to let H2O handle missing values internally for features during modeling.\n",
        "# However, for evaluating target performance, clean targets are needed.\n",
        "# Let's drop rows where ANY column has missing values for this analysis.\n",
        "df_clean = df.dropna()\n",
        "print(f\"\\nShape after dropping rows with missing values: {df_clean.shape}\")\n",
        "\n",
        "X_clean_df = df_clean[feature_columns].copy()\n",
        "y_potential_df = df_clean[feature_columns] # All features are potential targets\n",
        "\n",
        "# Convert the clean pandas DataFrame to an H2O Frame\n",
        "h2o_df = h2o.H2OFrame(df_clean)\n",
        "print(\"\\nData successfully converted to H2O Frame.\")\n",
        "\n",
        "# --- 4. Define a function to evaluate H2O AutoML performance for each potential target column ---\n",
        "def find_best_target_h2o_automl(h2o_frame, feature_cols, potential_target_cols, max_runtime_secs=120):\n",
        "    \"\"\"\n",
        "    Iterates through each column in potential_target_cols, treating it as a target,\n",
        "    and uses H2O AutoML to build a model. The performance (e.g., R2 for regression,\n",
        "    AUC/M logloss for classification) of the model is used as a proxy to determine\n",
        "    the 'best' target column. Higher performance might indicate that the column\n",
        "    is easier to predict from the other features, suggesting a strong underlying\n",
        "    relationship or structure.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    best_score = float('-inf') # We'll use a generic 'score', taking the primary metric\n",
        "    best_column = None\n",
        "    best_task = None\n",
        "    best_leaderboard = None\n",
        "\n",
        "    for col in potential_target_cols:\n",
        "        print(f\"\\n--- Evaluating '{col}' as potential target ---\")\n",
        "        y = col\n",
        "        X = [c for c in feature_cols if c != y] # Use all other features as predictors\n",
        "\n",
        "        # Determine task type based on the target column's data type in the H2O frame\n",
        "        h2o_type = h2o_frame.type(col)\n",
        "        print(f\"  H2O determined type for '{col}': {h2o_type}\")\n",
        "\n",
        "        # H2O usually infers 'enum' for categorical/string and 'int'/'real' for numeric.\n",
        "        # For integer columns that might represent clusters (classification),\n",
        "        # H2O might still treat them as regression. We might need to explicitly convert.\n",
        "        # Let's assume H2O's inference is mostly correct for now, but check unique values.\n",
        "        unique_vals_frame = h2o_frame[y].unique()\n",
        "        unique_count = unique_vals_frame.nrows\n",
        "        total_count = h2o_frame.nrows\n",
        "        print(f\"  Unique values in '{col}': {unique_count}\")\n",
        "\n",
        "        if h2o_type == 'enum' or unique_count < max(2, total_count * 0.05): # Treat as classification\n",
        "             task = 'classification'\n",
        "             # Ensure the target is treated as enum if it's numeric but categorical\n",
        "             h2o_frame[y] = h2o_frame[y].asfactor()\n",
        "        elif h2o_type in ['int', 'real']:\n",
        "             task = 'regression'\n",
        "        else:\n",
        "            print(f\"  Skipping '{col}' due to unsupported H2O type: {h2o_type}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"  Determined task type: {task}\")\n",
        "\n",
        "        # Split the H2O frame\n",
        "        train, test = h2o_frame.split_frame(ratios=[0.8], seed=42)\n",
        "\n",
        "        # Initialize H2O AutoML\n",
        "        aml = H2OAutoML(\n",
        "            max_runtime_secs=max_runtime_secs, # Run for max 2 minutes per target\n",
        "            seed=42,\n",
        "            verbosity='info' # Can be 'info', 'warn', 'quiet' to manage output\n",
        "        )\n",
        "\n",
        "        # Fit the AutoML model\n",
        "        print(f\"  Fitting H2O AutoML for {task} on '{col}'...\")\n",
        "        aml.train(x=X, y=y, training_frame=train)\n",
        "\n",
        "        # Check the leaderboard for the best model's performance\n",
        "        lb = aml.leaderboard\n",
        "        print(lb.head())\n",
        "\n",
        "        if lb.nrows == 0:\n",
        "            print(f\"  No models were trained successfully for target '{col}'. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Get the primary metric for the best model\n",
        "        # H2O AutoML leaderboard has standard column names.\n",
        "        # For regression: 'r2', 'rmse', 'mae', 'deviance'\n",
        "        # For classification: 'mean_per_class_error', 'logloss', 'AUC' (if binary), 'AUCpr'\n",
        "        # We'll take the best model's R2 for regression or mean_per_class_error (minimize) or logloss (minimize) for classification.\n",
        "        best_model_id = lb[0, 'model_id']\n",
        "        print(f\"  Best model for '{col}': {best_model_id}\")\n",
        "\n",
        "        if task == 'regression':\n",
        "            # Look for R2 score (higher is better)\n",
        "            if 'r2' in lb.columns:\n",
        "                score_val = lb[0, 'r2']\n",
        "                score_name = \"R2\"\n",
        "                if score_val is not None:\n",
        "                    score_val = float(score_val) # H2O returns H2OFloat, convert to Python float\n",
        "                    score = score_val # Higher R2 is better\n",
        "                else:\n",
        "                     print(f\"    R2 not found for best model of '{col}', using 0.\")\n",
        "                     score = 0.0\n",
        "            else:\n",
        "                # If R2 is not present (e.g., if all models failed to report it), use another metric like negative RMSE\n",
        "                rmse_val = lb[0, 'rmse']\n",
        "                if rmse_val is not None:\n",
        "                    rmse_val = float(rmse_val)\n",
        "                    score = -rmse_val # Negative RMSE, so higher (less negative) is better\n",
        "                    score_name = \"-RMSE\"\n",
        "                else:\n",
        "                     print(f\"    R2 and RMSE not found for best model of '{col}', using 0.\")\n",
        "                     score = 0.0\n",
        "                     score_name = \"Placeholder\"\n",
        "\n",
        "        elif task == 'classification':\n",
        "             # Look for mean_per_class_error (lower is better) or logloss (lower is better)\n",
        "             # We want a score where HIGHER is better, so we'll use negative error or inverse of logloss if needed.\n",
        "             # logloss is usually lower for better models. We can use negative logloss.\n",
        "             if 'logloss' in lb.columns and lb[0, 'logloss'] is not None:\n",
        "                 logloss_val = float(lb[0, 'logloss'])\n",
        "                 score = -logloss_val # Negative logloss, so higher (less negative) is better\n",
        "                 score_name = \"-LogLoss\"\n",
        "             elif 'mean_per_class_error' in lb.columns and lb[0, 'mean_per_class_error'] is not None:\n",
        "                  mce_val = float(lb[0, 'mean_per_class_error'])\n",
        "                  score = -mce_val # Negative mean per class error, so higher (less negative) is better\n",
        "                  score_name = \"-MeanPerClassError\"\n",
        "             elif 'auc' in lb.columns and lb[0, 'auc'] is not None: # For binary classification\n",
        "                  auc_val = float(lb[0, 'auc'])\n",
        "                  score = auc_val # AUC, higher is better\n",
        "                  score_name = \"AUC\"\n",
        "             else:\n",
        "                 print(f\"    No standard classification metric found for best model of '{col}', using 0.\")\n",
        "                 score = 0.0\n",
        "                 score_name = \"Placeholder\"\n",
        "\n",
        "        print(f\"  Best {score_name} for '{col}': {score:.4f}\")\n",
        "\n",
        "        results[col] = {\n",
        "            'score': score,\n",
        "            'score_name': score_name,\n",
        "            'task': task,\n",
        "            'leaderboard': lb\n",
        "        }\n",
        "\n",
        "        # Update best column if current score is better\n",
        "        # Note: This comparison works if score is consistently higher for better performance\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_column = col\n",
        "            best_task = task\n",
        "            best_leaderboard = lb\n",
        "\n",
        "    print(\"\\n--- Summary of H2O AutoML Performance for Potential Targets ---\")\n",
        "    # Sort results by score (descending) for better readability\n",
        "    sorted_results = sorted(results.items(), key=lambda item: item[1]['score'], reverse=True)\n",
        "    for col, res in sorted_results:\n",
        "        print(f\"  {col:<25} | {res['score_name']:<15} | {res['score']:.4f} | Task: {res['task']}\")\n",
        "    print(f\"\\nBest target column based on H2O AutoML performance: '{best_column}' with {results[best_column]['score_name']}: {best_score:.4f} (Task: {best_task})\")\n",
        "\n",
        "    return best_column, best_score, best_task, results, best_leaderboard\n",
        "\n",
        "\n",
        "# --- Run the H2O AutoML-based target identification ---\n",
        "best_target_col, best_score, best_task, all_results, best_lb = find_best_target_h2o_automl(\n",
        "    h2o_df, feature_columns, y_potential_df.columns, max_runtime_secs=120\n",
        ")\n",
        "\n",
        "# --- Print the leaderboard for the best target ---\n",
        "print(f\"\\n--- Leaderboard for the Best Target ('{best_target_col}') ---\")\n",
        "print(best_lb)\n",
        "\n",
        "# --- 5. Shutdown H2O ---\n",
        "print(\"\\nShutting down H2O...\")\n",
        "h2o.shutdown(prompt=False)\n",
        "\n",
        "print(\"\\nDone.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mkAlG2IGxQvZ",
        "outputId": "86f92ae1-b5da-4b24-fe8b-70314d9b8ec1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h2o\n",
            "  Downloading h2o-3.46.0.9-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from h2o) (2.32.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from h2o) (0.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->h2o) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->h2o) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->h2o) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->h2o) (2025.11.12)\n",
            "Downloading h2o-3.46.0.9-py2.py3-none-any.whl (266.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.0/266.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h2o\n",
            "Successfully installed h2o-3.46.0.9\n",
            "Initializing H2O...\n",
            "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"17.0.16\" 2025-07-15; OpenJDK Runtime Environment (build 17.0.16+8-Ubuntu-0ubuntu122.04.1); OpenJDK 64-Bit Server VM (build 17.0.16+8-Ubuntu-0ubuntu122.04.1, mixed mode, sharing)\n",
            "  Starting server from /usr/local/lib/python3.12/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmplvu6fb5g\n",
            "  JVM stdout: /tmp/tmplvu6fb5g/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmplvu6fb5g/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  -----------------------------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         08 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.46.0.9\n",
              "H2O_cluster_version_age:    12 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_6cav2p\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.168 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.12.12 final\n",
              "--------------------------  -----------------------------------------------------------------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-1.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-1 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-1 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-1 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table th,\n",
              "#h2o-table-1 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>08 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.46.0.9</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>12 days</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_6cav2p</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.168 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.12.12 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6fa5876f-756b-4057-8912-e7fb617f6b88\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6fa5876f-756b-4057-8912-e7fb617f6b88\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TMS_timeseries_clusters.csv to TMS_timeseries_clusters.csv\n",
            "Dataset loaded successfully!\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 46 entries, 0 to 45\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   Unnamed: 0              46 non-null     int64  \n",
            " 1   patient_id              46 non-null     object \n",
            " 2   Avg_Resp_Left_Mean      45 non-null     float64\n",
            " 3   Avg_Resp_Left_Std       45 non-null     float64\n",
            " 4   Avg_Resp_Left_Hurst     44 non-null     float64\n",
            " 5   Avg_Resp_Right_Mean     45 non-null     float64\n",
            " 6   Avg_Resp_Right_Std      45 non-null     float64\n",
            " 7   Avg_Resp_Right_Hurst    45 non-null     float64\n",
            " 8   Avg_Resp_DWT_Cluster    44 non-null     float64\n",
            " 9   Inh_Thresh_DTW_Cluster  46 non-null     int64  \n",
            "dtypes: float64(7), int64(2), object(1)\n",
            "memory usage: 3.7+ KB\n",
            "None\n",
            "\n",
            "First few rows:\n",
            "   Unnamed: 0  patient_id  Avg_Resp_Left_Mean  Avg_Resp_Left_Std  \\\n",
            "0           0  patient_ 1          178.163333          67.882676   \n",
            "1           1  patient_ 2           51.333667          30.594125   \n",
            "2           2  patient_ 3          189.062500          63.825718   \n",
            "3           3  patient_ 4           88.539167          29.056679   \n",
            "4           4  patient_ 5           59.761333          46.520112   \n",
            "\n",
            "   Avg_Resp_Left_Hurst  Avg_Resp_Right_Mean  Avg_Resp_Right_Std  \\\n",
            "0             1.257902           140.767500           27.082901   \n",
            "1             1.937557            73.485333           30.241820   \n",
            "2             1.729370           145.275000           35.421334   \n",
            "3             0.237006            66.661917           16.158868   \n",
            "4             1.369517            59.291833           28.441472   \n",
            "\n",
            "   Avg_Resp_Right_Hurst  Avg_Resp_DWT_Cluster  Inh_Thresh_DTW_Cluster  \n",
            "0              0.291345                   0.0                       0  \n",
            "1              0.849184                   0.0                       1  \n",
            "2              0.495146                   0.0                       0  \n",
            "3              0.504025                   0.0                       1  \n",
            "4              1.495100                   0.0                       1  \n",
            "\n",
            "All columns: ['Unnamed: 0', 'patient_id', 'Avg_Resp_Left_Mean', 'Avg_Resp_Left_Std', 'Avg_Resp_Left_Hurst', 'Avg_Resp_Right_Mean', 'Avg_Resp_Right_Std', 'Avg_Resp_Right_Hurst', 'Avg_Resp_DWT_Cluster', 'Inh_Thresh_DTW_Cluster']\n",
            "\n",
            "Feature columns identified: ['Unnamed: 0', 'Avg_Resp_Left_Mean', 'Avg_Resp_Left_Std', 'Avg_Resp_Left_Hurst', 'Avg_Resp_Right_Mean', 'Avg_Resp_Right_Std', 'Avg_Resp_Right_Hurst', 'Avg_Resp_DWT_Cluster', 'Inh_Thresh_DTW_Cluster']\n",
            "\n",
            "Shape after dropping rows with missing values: (44, 10)\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "\n",
            "Data successfully converted to H2O Frame.\n",
            "\n",
            "--- Evaluating 'Unnamed: 0' as potential target ---\n",
            "  H2O determined type for 'Unnamed: 0': int\n",
            "  Unique values in 'Unnamed: 0': 44\n",
            "  Determined task type: regression\n",
            "  Fitting H2O AutoML for regression on 'Unnamed: 0'...\n",
            "AutoML progress: |\n",
            "13:07:02.929: Project: AutoML_1_20251207_130702\n",
            "13:07:02.936: 5-fold cross-validation will be used.\n",
            "13:07:02.937: Setting stopping tolerance adaptively based on the training frame: 0.05\n",
            "13:07:02.939: Build control seed: 42\n",
            "13:07:02.940: training frame: Frame key: AutoML_1_20251207_130702_training_py_3_sid_8553    cols: 10    rows: 38  chunks: 1    size: 3208  checksum: 1803724448260043734\n",
            "13:07:02.941: validation frame: NULL\n",
            "13:07:02.941: leaderboard frame: NULL\n",
            "13:07:02.944: blending frame: NULL\n",
            "13:07:02.944: response column: Unnamed: 0\n",
            "13:07:02.944: fold column: null\n",
            "13:07:02.945: weights column: null\n",
            "13:07:02.984: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
            "13:07:03.35: AutoML job created: 2025.12.07 13:07:02.873\n",
            "13:07:03.37: AutoML build started: 2025.12.07 13:07:03.36\n",
            "13:07:03.108: AutoML: starting XGBoost_1_AutoML_1_20251207_130702 model training\n",
            "\n",
            "█\n",
            "13:07:06.589: New leader: XGBoost_1_AutoML_1_20251207_130702, rmse: 15.211289145829971\n",
            "13:07:06.605: AutoML: starting GLM_1_AutoML_1_20251207_130702 model training\n",
            "\n",
            "█\n",
            "13:07:07.593: New leader: GLM_1_AutoML_1_20251207_130702, rmse: 13.971464966417313\n",
            "13:07:07.602: AutoML: starting GBM_1_AutoML_1_20251207_130702 model training\n",
            "13:07:07.605: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 38.0.\n",
            "13:07:07.630: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_1_20251207_130702 model training\n",
            "\n",
            "\n",
            "13:07:07.945: AutoML: starting XGBoost_2_AutoML_1_20251207_130702 model training\n",
            "\n",
            "███\n",
            "13:07:13.397: AutoML: starting DRF_1_AutoML_1_20251207_130702 model training\n",
            "\n",
            "█\n",
            "13:07:15.209: New leader: DRF_1_AutoML_1_20251207_130702, rmse: 13.79443033317727\n",
            "13:07:15.214: AutoML: starting GBM_2_AutoML_1_20251207_130702 model training\n",
            "13:07:15.875: AutoML: starting GBM_3_AutoML_1_20251207_130702 model training\n",
            "\n",
            "█\n",
            "13:07:16.479: New leader: GBM_3_AutoML_1_20251207_130702, rmse: 13.552884531846006\n",
            "13:07:16.483: AutoML: starting GBM_4_AutoML_1_20251207_130702 model training\n",
            "13:07:17.52: AutoML: starting StackedEnsemble_BestOfFamily_2_AutoML_1_20251207_130702 model training\n",
            "13:07:17.296: AutoML: starting StackedEnsemble_AllModels_1_AutoML_1_20251207_130702 model training\n",
            "\n",
            "\n",
            "13:07:17.548: AutoML: starting XGBoost_3_AutoML_1_20251207_130702 model training\n",
            "\n",
            "█\n",
            "13:07:19.523: AutoML: starting XRT_1_AutoML_1_20251207_130702 model training\n",
            "\n",
            "█\n",
            "13:07:21.138: AutoML: starting GBM_5_AutoML_1_20251207_130702 model training\n",
            "\n",
            "█\n",
            "13:07:22.329: New leader: GBM_5_AutoML_1_20251207_130702, rmse: 13.372966427821748\n",
            "13:07:22.344: AutoML: starting DeepLearning_1_AutoML_1_20251207_130702 model training\n",
            "\n",
            "█\n",
            "13:07:23.314: AutoML: starting StackedEnsemble_BestOfFamily_3_AutoML_1_20251207_130702 model training\n",
            "13:07:23.676: AutoML: starting StackedEnsemble_AllModels_2_AutoML_1_20251207_130702 model training\n",
            "\n",
            "██\n",
            "13:07:24.161: AutoML: starting XGBoost_grid_1_AutoML_1_20251207_130702 hyperparameter search\n",
            "\n",
            "███████\n",
            "13:07:37.305: New leader: XGBoost_grid_1_AutoML_1_20251207_130702_model_4, rmse: 13.29220799446737\n",
            "\n",
            "███████████████\n",
            "13:08:10.551: AutoML: starting GBM_grid_1_AutoML_1_20251207_130702 hyperparameter search\n",
            "\n",
            "█\n",
            "13:08:11.564: New leader: GBM_grid_1_AutoML_1_20251207_130702_model_1, rmse: 13.02406895700865\n",
            "\n",
            "████\n",
            "13:08:19.699: New leader: GBM_grid_1_AutoML_1_20251207_130702_model_30, rmse: 12.736271726522538\n",
            "\n",
            "██\n",
            "13:08:24.583: AutoML: starting DeepLearning_grid_1_AutoML_1_20251207_130702 hyperparameter search\n",
            "\n",
            "██████████████\n",
            "13:08:50.364: AutoML: starting StackedEnsemble_BestOfFamily_4_AutoML_1_20251207_130702 model training\n",
            "13:08:50.532: AutoML: starting StackedEnsemble_AllModels_3_AutoML_1_20251207_130702 model training\n",
            "\n",
            "\n",
            "13:08:50.982: AutoML: starting DeepLearning_grid_2_AutoML_1_20251207_130702 hyperparameter search\n",
            "\n",
            "███\n",
            "13:08:55.856: AutoML: starting DeepLearning_grid_3_AutoML_1_20251207_130702 hyperparameter search\n",
            "\n",
            "███\n",
            "13:09:01.143: AutoML: starting StackedEnsemble_AllModels_4_AutoML_1_20251207_130702 model training\n",
            "13:09:01.404: Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_1_20251207_130702_model_4\n",
            "13:09:01.404: AutoML: starting XGBoost_lr_search_selection_AutoML_1_20251207_130702_select model training\n",
            "\n",
            "█| (done) 100%\n",
            "\n",
            "13:09:03.459: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {StackedEnsemble : [best_of_family_2 (2g, 5w), all_2 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {StackedEnsemble : [best_of_family_3 (3g, 5w), all_3 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {DeepLearning : [grid_1 (4g, 30w)]}, {StackedEnsemble : [best_of_family_4 (4g, 5w), all_4 (4g, 10w)]}, {DeepLearning : [grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {StackedEnsemble : [all_5 (5g, 10w)]}, {XGBoost : [lr_search (6g, 30w)]}]\n",
            "13:09:03.460: AutoML build stopped: 2025.12.07 13:09:03.459\n",
            "13:09:03.460: AutoML build done: built 69 models\n",
            "13:09:03.460: AutoML duration:  2 min  0.423 sec\n",
            "\n",
            "model_id                                            rmse      mse      mae     rmsle    mean_residual_deviance\n",
            "GBM_grid_1_AutoML_1_20251207_130702_model_30     12.7363  162.213  10.9686  0.872134                   162.213\n",
            "GBM_grid_1_AutoML_1_20251207_130702_model_1      13.0241  169.626  11.2409  0.902315                   169.626\n",
            "GBM_grid_1_AutoML_1_20251207_130702_model_44     13.0279  169.727  10.9908  0.871369                   169.727\n",
            "GBM_grid_1_AutoML_1_20251207_130702_model_25     13.0349  169.909  11.3012  0.916081                   169.909\n",
            "GBM_grid_1_AutoML_1_20251207_130702_model_2      13.1906  173.991  11.2503  0.91723                    173.991\n",
            "GBM_grid_1_AutoML_1_20251207_130702_model_21     13.2163  174.672  11.333   0.923497                   174.672\n",
            "GBM_grid_1_AutoML_1_20251207_130702_model_5      13.2431  175.379  11.3868  0.903125                   175.379\n",
            "XGBoost_grid_1_AutoML_1_20251207_130702_model_4  13.2922  176.683  11.7028  0.836141                   176.683\n",
            "GBM_grid_1_AutoML_1_20251207_130702_model_20     13.3199  177.421  11.6766  0.936849                   177.421\n",
            "GBM_grid_1_AutoML_1_20251207_130702_model_26     13.3377  177.895  11.5773  0.917298                   177.895\n",
            "[10 rows x 6 columns]\n",
            "\n",
            "  Best model for 'Unnamed: 0': GBM_grid_1_AutoML_1_20251207_130702_model_30\n",
            "  Best -RMSE for 'Unnamed: 0': -12.7363\n",
            "\n",
            "--- Evaluating 'Avg_Resp_Left_Mean' as potential target ---\n",
            "  H2O determined type for 'Avg_Resp_Left_Mean': real\n",
            "  Unique values in 'Avg_Resp_Left_Mean': 43\n",
            "  Determined task type: regression\n",
            "  Fitting H2O AutoML for regression on 'Avg_Resp_Left_Mean'...\n",
            "AutoML progress: |\n",
            "13:09:07.333: Project: AutoML_2_20251207_130907\n",
            "13:09:07.333: 5-fold cross-validation will be used.\n",
            "13:09:07.333: Setting stopping tolerance adaptively based on the training frame: 0.05\n",
            "13:09:07.333: Build control seed: 42\n",
            "13:09:07.334: training frame: Frame key: AutoML_2_20251207_130907_training_py_13_sid_8553    cols: 10    rows: 38  chunks: 1    size: 3208  checksum: 1803724448260043734\n",
            "13:09:07.334: validation frame: NULL\n",
            "13:09:07.334: leaderboard frame: NULL\n",
            "13:09:07.335: blending frame: NULL\n",
            "13:09:07.335: response column: Avg_Resp_Left_Mean\n",
            "13:09:07.335: fold column: null\n",
            "13:09:07.335: weights column: null\n",
            "13:09:07.337: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
            "13:09:07.343: AutoML job created: 2025.12.07 13:09:07.329\n",
            "13:09:07.344: AutoML build started: 2025.12.07 13:09:07.344\n",
            "13:09:07.346: AutoML: starting XGBoost_1_AutoML_2_20251207_130907 model training\n",
            "\n",
            "█\n",
            "13:09:10.54: New leader: XGBoost_1_AutoML_2_20251207_130907, rmse: 65.47285651963278\n",
            "13:09:10.55: AutoML: starting GLM_1_AutoML_2_20251207_130907 model training\n",
            "\n",
            "\n",
            "13:09:10.328: New leader: GLM_1_AutoML_2_20251207_130907, rmse: 47.955970960911785\n",
            "13:09:10.329: AutoML: starting GBM_1_AutoML_2_20251207_130907 model training\n",
            "13:09:10.329: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 38.0.\n",
            "13:09:10.330: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_2_20251207_130907 model training\n",
            "13:09:10.445: AutoML: starting XGBoost_2_AutoML_2_20251207_130907 model training\n",
            "\n",
            "██\n",
            "13:09:12.695: AutoML: starting DRF_1_AutoML_2_20251207_130907 model training\n",
            "13:09:13.233: AutoML: starting GBM_2_AutoML_2_20251207_130907 model training\n",
            "13:09:13.593: AutoML: starting GBM_3_AutoML_2_20251207_130907 model training\n",
            "\n",
            "█\n",
            "13:09:13.909: AutoML: starting GBM_4_AutoML_2_20251207_130907 model training\n",
            "13:09:14.243: AutoML: starting StackedEnsemble_BestOfFamily_2_AutoML_2_20251207_130907 model training\n",
            "13:09:14.364: AutoML: starting StackedEnsemble_AllModels_1_AutoML_2_20251207_130907 model training\n",
            "13:09:14.481: AutoML: starting XGBoost_3_AutoML_2_20251207_130907 model training\n",
            "\n",
            "████\n",
            "13:09:16.811: AutoML: starting XRT_1_AutoML_2_20251207_130907 model training\n",
            "\n",
            "██\n",
            "13:09:17.740: AutoML: starting GBM_5_AutoML_2_20251207_130907 model training\n",
            "13:09:18.234: AutoML: starting DeepLearning_1_AutoML_2_20251207_130907 model training\n",
            "13:09:18.428: AutoML: starting StackedEnsemble_BestOfFamily_3_AutoML_2_20251207_130907 model training\n",
            "13:09:18.547: AutoML: starting StackedEnsemble_AllModels_2_AutoML_2_20251207_130907 model training\n",
            "13:09:18.682: AutoML: starting XGBoost_grid_1_AutoML_2_20251207_130907 hyperparameter search\n",
            "\n",
            "████████████████████████\n",
            "13:10:08.968: AutoML: starting GBM_grid_1_AutoML_2_20251207_130907 hyperparameter search\n",
            "\n",
            "█████████\n",
            "13:10:26.238: New leader: GBM_grid_1_AutoML_2_20251207_130907_model_64, rmse: 46.850856225892365\n",
            "\n",
            "███████\n",
            "13:10:42.402: AutoML: starting DeepLearning_grid_1_AutoML_2_20251207_130907 hyperparameter search\n",
            "\n",
            "████████\n",
            "13:10:58.494: New leader: DeepLearning_grid_1_AutoML_2_20251207_130907_model_2, rmse: 27.35902157984637\n",
            "13:10:59.59: AutoML: starting StackedEnsemble_BestOfFamily_4_AutoML_2_20251207_130907 model training\n",
            "\n",
            "█\n",
            "13:10:59.200: AutoML: starting StackedEnsemble_AllModels_3_AutoML_2_20251207_130907 model training\n",
            "13:10:59.494: AutoML: starting DeepLearning_grid_2_AutoML_2_20251207_130907 hyperparameter search\n",
            "\n",
            "█\n",
            "13:11:03.36: AutoML: starting DeepLearning_grid_3_AutoML_2_20251207_130907 hyperparameter search\n",
            "\n",
            "██\n",
            "13:11:06.221: AutoML: starting StackedEnsemble_AllModels_4_AutoML_2_20251207_130907 model training\n",
            "13:11:06.493: Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_2_20251207_130907_model_1\n",
            "13:11:06.494: AutoML: starting XGBoost_lr_search_selection_AutoML_2_20251207_130907_select model training\n",
            "\n",
            "█| (done) 100%\n",
            "\n",
            "13:11:08.704: New leader: DeepLearning_grid_1_AutoML_2_20251207_130907_model_2, rmse: 27.35902157984637\n",
            "13:11:08.727: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {StackedEnsemble : [best_of_family_2 (2g, 5w), all_2 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {StackedEnsemble : [best_of_family_3 (3g, 5w), all_3 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {DeepLearning : [grid_1 (4g, 30w)]}, {StackedEnsemble : [best_of_family_4 (4g, 5w), all_4 (4g, 10w)]}, {DeepLearning : [grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {StackedEnsemble : [all_5 (5g, 10w)]}, {XGBoost : [lr_search (6g, 30w)]}]\n",
            "13:11:08.728: AutoML build stopped: 2025.12.07 13:11:08.727\n",
            "13:11:08.728: AutoML build done: built 134 models\n",
            "13:11:08.728: AutoML duration:  2 min  1.383 sec\n",
            "\n",
            "model_id                                                                     rmse       mse      mae     rmsle    mean_residual_deviance\n",
            "DeepLearning_grid_1_AutoML_2_20251207_130907_model_2                      27.359    748.516  21.2929  0.379747                   748.516\n",
            "DeepLearning_grid_1_AutoML_2_20251207_130907_model_3                      32.4889  1055.53   23.0717  0.433531                  1055.53\n",
            "StackedEnsemble_BestOfFamily_4_AutoML_2_20251207_130907                   42.4324  1800.51   24.8112  0.374585                  1800.51\n",
            "DeepLearning_grid_3_AutoML_2_20251207_130907_model_1                      43.8009  1918.52   28.0441  0.394969                  1918.52\n",
            "StackedEnsemble_AllModels_4_AutoML_2_20251207_130907                      44.641   1992.82   26.1604  0.40693                   1992.82\n",
            "XGBoost_lr_search_selection_AutoML_2_20251207_130907_select_grid_model_1  46.2079  2135.17   27.3937  0.370314                  2135.17\n",
            "DeepLearning_grid_2_AutoML_2_20251207_130907_model_1                      46.8497  2194.9    29.2201  0.421692                  2194.9\n",
            "GBM_grid_1_AutoML_2_20251207_130907_model_64                              46.8509  2195      26.4646  0.360639                  2195\n",
            "GBM_grid_1_AutoML_2_20251207_130907_model_81                              47.0448  2213.21   25.2173  0.355288                  2213.21\n",
            "DeepLearning_grid_1_AutoML_2_20251207_130907_model_4                      47.1304  2221.28   32.843   0.60218                   2221.28\n",
            "[10 rows x 6 columns]\n",
            "\n",
            "  Best model for 'Avg_Resp_Left_Mean': DeepLearning_grid_1_AutoML_2_20251207_130907_model_2\n",
            "  Best -RMSE for 'Avg_Resp_Left_Mean': -27.3590\n",
            "\n",
            "--- Evaluating 'Avg_Resp_Left_Std' as potential target ---\n",
            "  H2O determined type for 'Avg_Resp_Left_Std': real\n",
            "  Unique values in 'Avg_Resp_Left_Std': 43\n",
            "  Determined task type: regression\n",
            "  Fitting H2O AutoML for regression on 'Avg_Resp_Left_Std'...\n",
            "AutoML progress: |\n",
            "13:11:10.955: Project: AutoML_3_20251207_131110\n",
            "13:11:10.955: 5-fold cross-validation will be used.\n",
            "13:11:10.957: Setting stopping tolerance adaptively based on the training frame: 0.05\n",
            "13:11:10.957: Build control seed: 42\n",
            "13:11:10.957: training frame: Frame key: AutoML_3_20251207_131110_training_py_23_sid_8553    cols: 10    rows: 38  chunks: 1    size: 3208  checksum: 1803724448260043734\n",
            "13:11:10.957: validation frame: NULL\n",
            "13:11:10.957: leaderboard frame: NULL\n",
            "13:11:10.957: blending frame: NULL\n",
            "13:11:10.958: response column: Avg_Resp_Left_Std\n",
            "13:11:10.958: fold column: null\n",
            "13:11:10.958: weights column: null\n",
            "13:11:10.958: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
            "13:11:10.961: AutoML job created: 2025.12.07 13:11:10.954\n",
            "13:11:10.961: AutoML build started: 2025.12.07 13:11:10.961\n",
            "13:11:10.962: AutoML: starting XGBoost_1_AutoML_3_20251207_131110 model training\n",
            "\n",
            "█\n",
            "13:11:12.957: New leader: XGBoost_1_AutoML_3_20251207_131110, rmse: 26.231591877165815\n",
            "13:11:12.957: AutoML: starting GLM_1_AutoML_3_20251207_131110 model training\n",
            "\n",
            "\n",
            "13:11:13.129: New leader: GLM_1_AutoML_3_20251207_131110, rmse: 15.427187530360367\n",
            "13:11:13.130: AutoML: starting GBM_1_AutoML_3_20251207_131110 model training\n",
            "13:11:13.130: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 38.0.\n",
            "13:11:13.131: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_3_20251207_131110 model training\n",
            "13:11:13.248: AutoML: starting XGBoost_2_AutoML_3_20251207_131110 model training\n",
            "\n",
            "██\n",
            "13:11:15.575: AutoML: starting DRF_1_AutoML_3_20251207_131110 model training\n",
            "13:11:16.380: AutoML: starting GBM_2_AutoML_3_20251207_131110 model training\n",
            "\n",
            "█\n",
            "13:11:17.52: AutoML: starting GBM_3_AutoML_3_20251207_131110 model training\n",
            "13:11:17.465: AutoML: starting GBM_4_AutoML_3_20251207_131110 model training\n",
            "13:11:17.974: AutoML: starting StackedEnsemble_BestOfFamily_2_AutoML_3_20251207_131110 model training\n",
            "13:11:18.103: AutoML: starting StackedEnsemble_AllModels_1_AutoML_3_20251207_131110 model training\n",
            "\n",
            "█\n",
            "13:11:18.234: AutoML: starting XGBoost_3_AutoML_3_20251207_131110 model training\n",
            "\n",
            "████\n",
            "13:11:20.208: AutoML: starting XRT_1_AutoML_3_20251207_131110 model training\n",
            "13:11:21.40: AutoML: starting GBM_5_AutoML_3_20251207_131110 model training\n",
            "13:11:21.529: AutoML: starting DeepLearning_1_AutoML_3_20251207_131110 model training\n",
            "13:11:21.646: AutoML: starting StackedEnsemble_BestOfFamily_3_AutoML_3_20251207_131110 model training\n",
            "13:11:21.759: AutoML: starting StackedEnsemble_AllModels_2_AutoML_3_20251207_131110 model training\n",
            "\n",
            "██\n",
            "13:11:21.880: AutoML: starting XGBoost_grid_1_AutoML_3_20251207_131110 hyperparameter search\n",
            "\n",
            "███████████████████████\n",
            "13:12:12.387: AutoML: starting GBM_grid_1_AutoML_3_20251207_131110 hyperparameter search\n",
            "\n",
            "████████████████\n",
            "13:12:45.929: AutoML: starting DeepLearning_grid_1_AutoML_3_20251207_131110 hyperparameter search\n",
            "\n",
            "████████\n",
            "13:13:02.23: New leader: DeepLearning_grid_1_AutoML_3_20251207_131110_model_2, rmse: 15.381146251146138\n",
            "13:13:02.656: New leader: DeepLearning_grid_1_AutoML_3_20251207_131110_model_3, rmse: 14.737155231782902\n",
            "13:13:02.657: AutoML: starting StackedEnsemble_BestOfFamily_4_AutoML_3_20251207_131110 model training\n",
            "13:13:02.778: AutoML: starting StackedEnsemble_AllModels_3_AutoML_3_20251207_131110 model training\n",
            "\n",
            "█\n",
            "13:13:03.32: AutoML: starting DeepLearning_grid_2_AutoML_3_20251207_131110 hyperparameter search\n",
            "\n",
            "█\n",
            "13:13:06.264: AutoML: starting DeepLearning_grid_3_AutoML_3_20251207_131110 hyperparameter search\n",
            "\n",
            "██\n",
            "13:13:10.52: AutoML: starting StackedEnsemble_AllModels_4_AutoML_3_20251207_131110 model training\n",
            "13:13:10.439: Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_3_20251207_131110_model_1\n",
            "13:13:10.439: AutoML: starting XGBoost_lr_search_selection_AutoML_3_20251207_131110_select model training\n",
            "\n",
            "█| (done) 100%\n",
            "\n",
            "13:13:12.470: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {StackedEnsemble : [best_of_family_2 (2g, 5w), all_2 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {StackedEnsemble : [best_of_family_3 (3g, 5w), all_3 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {DeepLearning : [grid_1 (4g, 30w)]}, {StackedEnsemble : [best_of_family_4 (4g, 5w), all_4 (4g, 10w)]}, {DeepLearning : [grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {StackedEnsemble : [all_5 (5g, 10w)]}, {XGBoost : [lr_search (6g, 30w)]}]\n",
            "13:13:12.471: AutoML build stopped: 2025.12.07 13:13:12.470\n",
            "13:13:12.471: AutoML build done: built 149 models\n",
            "13:13:12.471: AutoML duration:  2 min  1.509 sec\n",
            "\n",
            "model_id                                                    rmse      mse      mae       rmsle    mean_residual_deviance\n",
            "DeepLearning_grid_1_AutoML_3_20251207_131110_model_3     14.7372  217.184  10.3841  nan                          217.184\n",
            "DeepLearning_grid_1_AutoML_3_20251207_131110_model_2     15.3811  236.58   10.2105  nan                          236.58\n",
            "GLM_1_AutoML_3_20251207_131110                           15.4272  237.998  10.5105    0.406895                   237.998\n",
            "DeepLearning_grid_1_AutoML_3_20251207_131110_model_4     18.5248  343.169  11.4321  nan                          343.169\n",
            "GBM_grid_1_AutoML_3_20251207_131110_model_81             18.7061  349.918  11.2422    0.402939                   349.918\n",
            "GBM_grid_1_AutoML_3_20251207_131110_model_31             18.8236  354.33   11.9415    0.431897                   354.33\n",
            "GBM_grid_1_AutoML_3_20251207_131110_model_1              19.6497  386.11   12.0765    0.442489                   386.11\n",
            "StackedEnsemble_BestOfFamily_2_AutoML_3_20251207_131110  19.7324  389.368  11.7145  nan                          389.368\n",
            "StackedEnsemble_BestOfFamily_4_AutoML_3_20251207_131110  19.7388  389.622  12.0337  nan                          389.622\n",
            "StackedEnsemble_BestOfFamily_3_AutoML_3_20251207_131110  19.8983  395.944  12.6348  nan                          395.944\n",
            "[10 rows x 6 columns]\n",
            "\n",
            "  Best model for 'Avg_Resp_Left_Std': DeepLearning_grid_1_AutoML_3_20251207_131110_model_3\n",
            "  Best -RMSE for 'Avg_Resp_Left_Std': -14.7372\n",
            "\n",
            "--- Evaluating 'Avg_Resp_Left_Hurst' as potential target ---\n",
            "  H2O determined type for 'Avg_Resp_Left_Hurst': real\n",
            "  Unique values in 'Avg_Resp_Left_Hurst': 43\n",
            "  Determined task type: regression\n",
            "  Fitting H2O AutoML for regression on 'Avg_Resp_Left_Hurst'...\n",
            "AutoML progress: |\n",
            "13:13:14.741: Project: AutoML_4_20251207_131314\n",
            "13:13:14.741: 5-fold cross-validation will be used.\n",
            "13:13:14.741: Setting stopping tolerance adaptively based on the training frame: 0.05\n",
            "13:13:14.741: Build control seed: 42\n",
            "13:13:14.741: training frame: Frame key: AutoML_4_20251207_131314_training_py_33_sid_8553    cols: 10    rows: 38  chunks: 1    size: 3208  checksum: 1803724448260043734\n",
            "13:13:14.741: validation frame: NULL\n",
            "13:13:14.742: leaderboard frame: NULL\n",
            "13:13:14.742: blending frame: NULL\n",
            "13:13:14.742: response column: Avg_Resp_Left_Hurst\n",
            "13:13:14.742: fold column: null\n",
            "13:13:14.742: weights column: null\n",
            "13:13:14.742: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
            "13:13:14.744: AutoML job created: 2025.12.07 13:13:14.741\n",
            "13:13:14.745: AutoML build started: 2025.12.07 13:13:14.745\n",
            "13:13:14.746: AutoML: starting XGBoost_1_AutoML_4_20251207_131314 model training\n",
            "\n",
            "\n",
            "13:13:16.303: New leader: XGBoost_1_AutoML_4_20251207_131314, rmse: 0.4769366404243159\n",
            "13:13:16.304: AutoML: starting GLM_1_AutoML_4_20251207_131314 model training\n",
            "\n",
            "█\n",
            "13:13:16.486: New leader: GLM_1_AutoML_4_20251207_131314, rmse: 0.43840762919324644\n",
            "13:13:16.486: AutoML: starting GBM_1_AutoML_4_20251207_131314 model training\n",
            "13:13:16.487: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 38.0.\n",
            "13:13:16.487: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_4_20251207_131314 model training\n",
            "13:13:16.599: AutoML: starting XGBoost_2_AutoML_4_20251207_131314 model training\n",
            "\n",
            "█\n",
            "13:13:17.842: AutoML: starting DRF_1_AutoML_4_20251207_131314 model training\n",
            "13:13:18.246: AutoML: starting GBM_2_AutoML_4_20251207_131314 model training\n",
            "13:13:18.445: AutoML: starting GBM_3_AutoML_4_20251207_131314 model training\n",
            "13:13:18.588: AutoML: starting GBM_4_AutoML_4_20251207_131314 model training\n",
            "\n",
            "█\n",
            "13:13:18.780: AutoML: starting StackedEnsemble_BestOfFamily_2_AutoML_4_20251207_131314 model training\n",
            "13:13:18.889: AutoML: starting StackedEnsemble_AllModels_1_AutoML_4_20251207_131314 model training\n",
            "13:13:19.0: AutoML: starting XGBoost_3_AutoML_4_20251207_131314 model training\n",
            "\n",
            "███\n",
            "13:13:20.424: AutoML: starting XRT_1_AutoML_4_20251207_131314 model training\n",
            "\n",
            "███\n",
            "13:13:21.48: AutoML: starting GBM_5_AutoML_4_20251207_131314 model training\n",
            "13:13:21.444: AutoML: starting DeepLearning_1_AutoML_4_20251207_131314 model training\n",
            "13:13:21.648: AutoML: starting StackedEnsemble_BestOfFamily_3_AutoML_4_20251207_131314 model training\n",
            "13:13:21.782: AutoML: starting StackedEnsemble_AllModels_2_AutoML_4_20251207_131314 model training\n",
            "13:13:22.5: AutoML: starting XGBoost_grid_1_AutoML_4_20251207_131314 hyperparameter search\n",
            "\n",
            "██████████████\n",
            "13:13:30.19: New leader: XGBoost_grid_1_AutoML_4_20251207_131314_model_4, rmse: 0.4239605698527828\n",
            "\n",
            "████████████\n",
            "13:14:14.111: AutoML: starting GBM_grid_1_AutoML_4_20251207_131314 hyperparameter search\n",
            "\n",
            "██\n",
            "13:14:17.876: AutoML: starting DeepLearning_grid_1_AutoML_4_20251207_131314 hyperparameter search\n",
            "\n",
            "█████████████████\n",
            "13:14:55.853: AutoML: starting StackedEnsemble_BestOfFamily_4_AutoML_4_20251207_131314 model training\n",
            "13:14:55.965: AutoML: starting StackedEnsemble_AllModels_3_AutoML_4_20251207_131314 model training\n",
            "13:14:56.91: AutoML: starting DeepLearning_grid_2_AutoML_4_20251207_131314 hyperparameter search\n",
            "\n",
            "████\n",
            "13:15:03.660: AutoML: starting DeepLearning_grid_3_AutoML_4_20251207_131314 hyperparameter search\n",
            "\n",
            "███\n",
            "13:15:12.124: AutoML: starting StackedEnsemble_AllModels_4_AutoML_4_20251207_131314 model training\n",
            "13:15:12.263: Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_4_20251207_131314_model_4\n",
            "13:15:12.263: AutoML: starting XGBoost_lr_search_selection_AutoML_4_20251207_131314_select model training\n",
            "\n",
            "██| (done) 100%\n",
            "\n",
            "13:15:14.294: Retraining best GBM with learning rate annealing: GBM_grid_1_AutoML_4_20251207_131314_model_4\n",
            "13:15:14.294: AutoML: starting GBM_lr_annealing_selection_AutoML_4_20251207_131314_select_model model training\n",
            "13:15:14.440: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
            "13:15:14.441: AutoML: starting StackedEnsemble_BestOfFamily_5_AutoML_4_20251207_131314 model training\n",
            "13:15:15.5: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {StackedEnsemble : [best_of_family_2 (2g, 5w), all_2 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {StackedEnsemble : [best_of_family_3 (3g, 5w), all_3 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {DeepLearning : [grid_1 (4g, 30w)]}, {StackedEnsemble : [best_of_family_4 (4g, 5w), all_4 (4g, 10w)]}, {DeepLearning : [grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {StackedEnsemble : [all_5 (5g, 10w)]}, {XGBoost : [lr_search (6g, 30w)]}, {GBM : [lr_annealing (6g, 10w)]}, {StackedEnsemble : [best_of_family_gbm (6g, 10w)]}]\n",
            "13:15:15.5: AutoML build stopped: 2025.12.07 13:15:15.5\n",
            "13:15:15.5: AutoML build done: built 69 models\n",
            "13:15:15.6: AutoML duration:  2 min  0.260 sec\n",
            "\n",
            "model_id                                                     rmse       mse       mae     rmsle    mean_residual_deviance\n",
            "XGBoost_grid_1_AutoML_4_20251207_131314_model_4          0.423961  0.179743  0.327892  0.197194                  0.179743\n",
            "XGBoost_grid_1_AutoML_4_20251207_131314_model_20         0.42987   0.184788  0.346981  0.197912                  0.184788\n",
            "GLM_1_AutoML_4_20251207_131314                           0.438408  0.192201  0.341752  0.201143                  0.192201\n",
            "GBM_grid_1_AutoML_4_20251207_131314_model_4              0.441193  0.194651  0.351235  0.205049                  0.194651\n",
            "XRT_1_AutoML_4_20251207_131314                           0.442134  0.195483  0.357441  0.204615                  0.195483\n",
            "StackedEnsemble_BestOfFamily_4_AutoML_4_20251207_131314  0.442734  0.196014  0.360274  0.20566                   0.196014\n",
            "StackedEnsemble_AllModels_2_AutoML_4_20251207_131314     0.44519   0.198195  0.365201  0.205723                  0.198195\n",
            "GBM_grid_1_AutoML_4_20251207_131314_model_21             0.445316  0.198307  0.371001  0.206161                  0.198307\n",
            "XGBoost_grid_1_AutoML_4_20251207_131314_model_22         0.448293  0.200966  0.367643  0.20639                   0.200966\n",
            "XGBoost_grid_1_AutoML_4_20251207_131314_model_27         0.448403  0.201065  0.353874  0.206369                  0.201065\n",
            "[10 rows x 6 columns]\n",
            "\n",
            "  Best model for 'Avg_Resp_Left_Hurst': XGBoost_grid_1_AutoML_4_20251207_131314_model_4\n",
            "  Best -RMSE for 'Avg_Resp_Left_Hurst': -0.4240\n",
            "\n",
            "--- Evaluating 'Avg_Resp_Right_Mean' as potential target ---\n",
            "  H2O determined type for 'Avg_Resp_Right_Mean': real\n",
            "  Unique values in 'Avg_Resp_Right_Mean': 43\n",
            "  Determined task type: regression\n",
            "  Fitting H2O AutoML for regression on 'Avg_Resp_Right_Mean'...\n",
            "AutoML progress: |\n",
            "13:15:17.478: Project: AutoML_5_20251207_131517\n",
            "13:15:17.478: 5-fold cross-validation will be used.\n",
            "13:15:17.478: Setting stopping tolerance adaptively based on the training frame: 0.05\n",
            "13:15:17.478: Build control seed: 42\n",
            "13:15:17.478: training frame: Frame key: AutoML_5_20251207_131517_training_py_43_sid_8553    cols: 10    rows: 38  chunks: 1    size: 3208  checksum: 1803724448260043734\n",
            "13:15:17.478: validation frame: NULL\n",
            "13:15:17.478: leaderboard frame: NULL\n",
            "13:15:17.478: blending frame: NULL\n",
            "13:15:17.478: response column: Avg_Resp_Right_Mean\n",
            "13:15:17.478: fold column: null\n",
            "13:15:17.478: weights column: null\n",
            "13:15:17.479: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
            "13:15:17.486: AutoML job created: 2025.12.07 13:15:17.478\n",
            "13:15:17.488: AutoML build started: 2025.12.07 13:15:17.488\n",
            "13:15:17.492: AutoML: starting XGBoost_1_AutoML_5_20251207_131517 model training\n",
            "\n",
            "█\n",
            "13:15:19.544: New leader: XGBoost_1_AutoML_5_20251207_131517, rmse: 39.04312615125401\n",
            "13:15:19.545: AutoML: starting GLM_1_AutoML_5_20251207_131517 model training\n",
            "\n",
            "\n",
            "13:15:19.707: New leader: GLM_1_AutoML_5_20251207_131517, rmse: 25.894623124251627\n",
            "13:15:19.708: AutoML: starting GBM_1_AutoML_5_20251207_131517 model training\n",
            "13:15:19.708: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 38.0.\n",
            "13:15:19.709: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_5_20251207_131517 model training\n",
            "13:15:19.817: AutoML: starting XGBoost_2_AutoML_5_20251207_131517 model training\n",
            "\n",
            "█\n",
            "13:15:21.186: AutoML: starting DRF_1_AutoML_5_20251207_131517 model training\n",
            "\n",
            "█\n",
            "13:15:21.529: AutoML: starting GBM_2_AutoML_5_20251207_131517 model training\n",
            "13:15:21.725: AutoML: starting GBM_3_AutoML_5_20251207_131517 model training\n",
            "13:15:21.960: AutoML: starting GBM_4_AutoML_5_20251207_131517 model training\n",
            "\n",
            "█\n",
            "13:15:22.172: AutoML: starting StackedEnsemble_BestOfFamily_2_AutoML_5_20251207_131517 model training\n",
            "13:15:22.283: AutoML: starting StackedEnsemble_AllModels_1_AutoML_5_20251207_131517 model training\n",
            "13:15:22.392: AutoML: starting XGBoost_3_AutoML_5_20251207_131517 model training\n",
            "\n",
            "██\n",
            "13:15:23.779: AutoML: starting XRT_1_AutoML_5_20251207_131517 model training\n",
            "\n",
            "██\n",
            "13:15:24.278: AutoML: starting GBM_5_AutoML_5_20251207_131517 model training\n",
            "13:15:24.723: AutoML: starting DeepLearning_1_AutoML_5_20251207_131517 model training\n",
            "13:15:24.842: AutoML: starting StackedEnsemble_BestOfFamily_3_AutoML_5_20251207_131517 model training\n",
            "13:15:24.954: AutoML: starting StackedEnsemble_AllModels_2_AutoML_5_20251207_131517 model training\n",
            "13:15:25.66: AutoML: starting XGBoost_grid_1_AutoML_5_20251207_131517 hyperparameter search\n",
            "\n",
            "███████████████████\n",
            "13:15:48.113: New leader: XGBoost_grid_1_AutoML_5_20251207_131517_model_11, rmse: 25.618927008645148\n",
            "\n",
            "██\n",
            "13:16:03.171: New leader: XGBoost_grid_1_AutoML_5_20251207_131517_model_19, rmse: 22.789590657053928\n",
            "\n",
            "██████\n",
            "13:16:17.35: AutoML: starting GBM_grid_1_AutoML_5_20251207_131517 hyperparameter search\n",
            "\n",
            "████████████████\n",
            "13:16:51.630: New leader: GBM_grid_1_AutoML_5_20251207_131517_model_151, rmse: 22.068451825665306\n",
            "13:16:51.631: AutoML: starting DeepLearning_grid_1_AutoML_5_20251207_131517 hyperparameter search\n",
            "\n",
            "████████\n",
            "13:17:09.3: AutoML: starting StackedEnsemble_BestOfFamily_4_AutoML_5_20251207_131517 model training\n",
            "13:17:09.142: AutoML: starting StackedEnsemble_AllModels_3_AutoML_5_20251207_131517 model training\n",
            "\n",
            "\n",
            "13:17:09.588: AutoML: starting DeepLearning_grid_2_AutoML_5_20251207_131517 hyperparameter search\n",
            "\n",
            "█\n",
            "13:17:12.644: New leader: DeepLearning_grid_2_AutoML_5_20251207_131517_model_1, rmse: 19.410699586164437\n",
            "13:17:12.766: AutoML: starting DeepLearning_grid_3_AutoML_5_20251207_131517 hyperparameter search\n",
            "\n",
            "██\n",
            "13:17:16.113: AutoML: starting StackedEnsemble_BestOfFamily_5_AutoML_5_20251207_131517 model training\n",
            "13:17:16.233: AutoML: starting StackedEnsemble_AllModels_4_AutoML_5_20251207_131517 model training\n",
            "13:17:16.510: Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_5_20251207_131517_model_19\n",
            "13:17:16.510: AutoML: starting XGBoost_lr_search_selection_AutoML_5_20251207_131517_select model training\n",
            "\n",
            "█| (done) 100%\n",
            "\n",
            "13:17:17.545: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {StackedEnsemble : [best_of_family_2 (2g, 5w), all_2 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {StackedEnsemble : [best_of_family_3 (3g, 5w), all_3 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {DeepLearning : [grid_1 (4g, 30w)]}, {StackedEnsemble : [best_of_family_4 (4g, 5w), all_4 (4g, 10w)]}, {DeepLearning : [grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {StackedEnsemble : [best_of_family_5 (5g, 5w), all_5 (5g, 10w)]}, {XGBoost : [lr_search (6g, 30w)]}]\n",
            "13:17:17.545: AutoML build stopped: 2025.12.07 13:17:17.545\n",
            "13:17:17.545: AutoML build done: built 155 models\n",
            "13:17:17.545: AutoML duration:  2 min  0.057 sec\n",
            "\n",
            "model_id                                                    rmse      mse      mae     rmsle    mean_residual_deviance\n",
            "DeepLearning_grid_2_AutoML_5_20251207_131517_model_1     19.4107  376.775  15.2813  0.255294                   376.775\n",
            "StackedEnsemble_BestOfFamily_5_AutoML_5_20251207_131517  21.4658  460.781  17.6136  0.269706                   460.781\n",
            "DeepLearning_grid_3_AutoML_5_20251207_131517_model_1     21.4792  461.358  17.3699  0.28205                    461.358\n",
            "GBM_grid_1_AutoML_5_20251207_131517_model_151            22.0685  487.017  17.758   0.265466                   487.017\n",
            "XGBoost_grid_1_AutoML_5_20251207_131517_model_19         22.7896  519.365  18.7749  0.284852                   519.365\n",
            "StackedEnsemble_BestOfFamily_4_AutoML_5_20251207_131517  22.8852  523.733  17.9671  0.268847                   523.733\n",
            "DeepLearning_grid_1_AutoML_5_20251207_131517_model_2     22.8896  523.933  17.7074  0.267446                   523.933\n",
            "StackedEnsemble_AllModels_4_AutoML_5_20251207_131517     23.1491  535.88   18.3291  0.280027                   535.88\n",
            "GBM_grid_1_AutoML_5_20251207_131517_model_1              23.707   562.024  19.2558  0.295365                   562.024\n",
            "GBM_grid_1_AutoML_5_20251207_131517_model_34             23.82    567.394  19.4805  0.297383                   567.394\n",
            "[10 rows x 6 columns]\n",
            "\n",
            "  Best model for 'Avg_Resp_Right_Mean': DeepLearning_grid_2_AutoML_5_20251207_131517_model_1\n",
            "  Best -RMSE for 'Avg_Resp_Right_Mean': -19.4107\n",
            "\n",
            "--- Evaluating 'Avg_Resp_Right_Std' as potential target ---\n",
            "  H2O determined type for 'Avg_Resp_Right_Std': real\n",
            "  Unique values in 'Avg_Resp_Right_Std': 43\n",
            "  Determined task type: regression\n",
            "  Fitting H2O AutoML for regression on 'Avg_Resp_Right_Std'...\n",
            "AutoML progress: |\n",
            "13:17:18.958: Project: AutoML_6_20251207_131718\n",
            "13:17:18.958: 5-fold cross-validation will be used.\n",
            "13:17:18.958: Setting stopping tolerance adaptively based on the training frame: 0.05\n",
            "13:17:18.958: Build control seed: 42\n",
            "13:17:18.958: training frame: Frame key: AutoML_6_20251207_131718_training_py_53_sid_8553    cols: 10    rows: 38  chunks: 1    size: 3208  checksum: 1803724448260043734\n",
            "13:17:18.958: validation frame: NULL\n",
            "13:17:18.958: leaderboard frame: NULL\n",
            "13:17:18.958: blending frame: NULL\n",
            "13:17:18.958: response column: Avg_Resp_Right_Std\n",
            "13:17:18.958: fold column: null\n",
            "13:17:18.958: weights column: null\n",
            "13:17:18.958: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
            "13:17:18.959: AutoML job created: 2025.12.07 13:17:18.957\n",
            "13:17:18.961: AutoML build started: 2025.12.07 13:17:18.961\n",
            "13:17:18.962: AutoML: starting XGBoost_1_AutoML_6_20251207_131718 model training\n",
            "\n",
            "\n",
            "13:17:20.398: New leader: XGBoost_1_AutoML_6_20251207_131718, rmse: 14.710593690502593\n",
            "13:17:20.398: AutoML: starting GLM_1_AutoML_6_20251207_131718 model training\n",
            "13:17:20.558: New leader: GLM_1_AutoML_6_20251207_131718, rmse: 11.170382498284884\n",
            "13:17:20.559: AutoML: starting GBM_1_AutoML_6_20251207_131718 model training\n",
            "13:17:20.560: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 38.0.\n",
            "13:17:20.562: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_6_20251207_131718 model training\n",
            "\n",
            "█\n",
            "13:17:20.680: AutoML: starting XGBoost_2_AutoML_6_20251207_131718 model training\n",
            "\n",
            "█\n",
            "13:17:22.150: AutoML: starting DRF_1_AutoML_6_20251207_131718 model training\n",
            "\n",
            "\n",
            "13:17:22.570: New leader: DRF_1_AutoML_6_20251207_131718, rmse: 10.362542052637796\n",
            "13:17:22.570: AutoML: starting GBM_2_AutoML_6_20251207_131718 model training\n",
            "\n",
            "█\n",
            "13:17:22.834: AutoML: starting GBM_3_AutoML_6_20251207_131718 model training\n",
            "13:17:23.188: AutoML: starting GBM_4_AutoML_6_20251207_131718 model training\n",
            "13:17:23.477: AutoML: starting StackedEnsemble_BestOfFamily_2_AutoML_6_20251207_131718 model training\n",
            "13:17:23.601: AutoML: starting StackedEnsemble_AllModels_1_AutoML_6_20251207_131718 model training\n",
            "\n",
            "█\n",
            "13:17:23.724: AutoML: starting XGBoost_3_AutoML_6_20251207_131718 model training\n",
            "\n",
            "██████\n",
            "13:17:26.615: New leader: XGBoost_3_AutoML_6_20251207_131718, rmse: 10.2199943868099\n",
            "13:17:26.616: AutoML: starting XRT_1_AutoML_6_20251207_131718 model training\n",
            "13:17:27.143: New leader: XRT_1_AutoML_6_20251207_131718, rmse: 10.12519515857431\n",
            "13:17:27.144: AutoML: starting GBM_5_AutoML_6_20251207_131718 model training\n",
            "13:17:27.571: AutoML: starting DeepLearning_1_AutoML_6_20251207_131718 model training\n",
            "13:17:27.701: AutoML: starting StackedEnsemble_BestOfFamily_3_AutoML_6_20251207_131718 model training\n",
            "\n",
            "███\n",
            "13:17:27.812: AutoML: starting StackedEnsemble_AllModels_2_AutoML_6_20251207_131718 model training\n",
            "13:17:27.924: AutoML: starting XGBoost_grid_1_AutoML_6_20251207_131718 hyperparameter search\n",
            "\n",
            "████████████\n",
            "13:17:49.966: New leader: XGBoost_grid_1_AutoML_6_20251207_131718_model_13, rmse: 10.110285288767898\n",
            "\n",
            "██\n",
            "13:18:01.998: New leader: XGBoost_grid_1_AutoML_6_20251207_131718_model_19, rmse: 9.762483899922195\n",
            "\n",
            "███████\n",
            "13:18:19.723: AutoML: starting GBM_grid_1_AutoML_6_20251207_131718 hyperparameter search\n",
            "\n",
            "█\n",
            "13:18:20.742: New leader: GBM_grid_1_AutoML_6_20251207_131718_model_1, rmse: 9.367461493614606\n",
            "\n",
            "████████████████\n",
            "13:18:53.645: AutoML: starting DeepLearning_grid_1_AutoML_6_20251207_131718 hyperparameter search\n",
            "\n",
            "████████\n",
            "13:19:10.582: AutoML: starting StackedEnsemble_BestOfFamily_4_AutoML_6_20251207_131718 model training\n",
            "13:19:10.714: AutoML: starting StackedEnsemble_AllModels_3_AutoML_6_20251207_131718 model training\n",
            "13:19:10.982: AutoML: starting DeepLearning_grid_2_AutoML_6_20251207_131718 hyperparameter search\n",
            "\n",
            "█\n",
            "13:19:14.26: New leader: DeepLearning_grid_2_AutoML_6_20251207_131718_model_1, rmse: 8.836802330967286\n",
            "13:19:14.253: AutoML: starting DeepLearning_grid_3_AutoML_6_20251207_131718 hyperparameter search\n",
            "\n",
            "██\n",
            "13:19:18.8: AutoML: starting StackedEnsemble_BestOfFamily_5_AutoML_6_20251207_131718 model training\n",
            "13:19:18.172: AutoML: starting StackedEnsemble_AllModels_4_AutoML_6_20251207_131718 model training\n",
            "13:19:18.434: Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_6_20251207_131718_model_19\n",
            "13:19:18.434: AutoML: starting XGBoost_lr_search_selection_AutoML_6_20251207_131718_select model training\n",
            "\n",
            "█| (done) 100%\n",
            "\n",
            "13:19:19.490: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {StackedEnsemble : [best_of_family_2 (2g, 5w), all_2 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {StackedEnsemble : [best_of_family_3 (3g, 5w), all_3 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {DeepLearning : [grid_1 (4g, 30w)]}, {StackedEnsemble : [best_of_family_4 (4g, 5w), all_4 (4g, 10w)]}, {DeepLearning : [grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {StackedEnsemble : [best_of_family_5 (5g, 5w), all_5 (5g, 10w)]}, {XGBoost : [lr_search (6g, 30w)]}]\n",
            "13:19:19.490: AutoML build stopped: 2025.12.07 13:19:19.490\n",
            "13:19:19.490: AutoML build done: built 149 models\n",
            "13:19:19.490: AutoML duration:  2 min  0.529 sec\n",
            "\n",
            "model_id                                                    rmse      mse      mae     rmsle    mean_residual_deviance\n",
            "DeepLearning_grid_2_AutoML_6_20251207_131718_model_1     8.8368   78.0891  6.38539  0.356378                   78.0891\n",
            "DeepLearning_grid_3_AutoML_6_20251207_131718_model_1     9.11639  83.1086  6.83745  0.300688                   83.1086\n",
            "GBM_grid_1_AutoML_6_20251207_131718_model_1              9.36746  87.7493  7.25548  0.354956                   87.7493\n",
            "DeepLearning_grid_1_AutoML_6_20251207_131718_model_2     9.40752  88.5015  6.0763   0.288556                   88.5015\n",
            "GBM_grid_1_AutoML_6_20251207_131718_model_122            9.60116  92.1823  7.86208  0.371764                   92.1823\n",
            "XGBoost_grid_1_AutoML_6_20251207_131718_model_19         9.76248  95.3061  7.01153  0.362161                   95.3061\n",
            "GBM_grid_1_AutoML_6_20251207_131718_model_103            9.83805  96.7873  7.64449  0.36139                    96.7873\n",
            "GBM_grid_1_AutoML_6_20251207_131718_model_86             9.84689  96.9613  7.76409  0.369179                   96.9613\n",
            "StackedEnsemble_BestOfFamily_5_AutoML_6_20251207_131718  9.88713  97.7554  6.61644  0.337551                   97.7554\n",
            "GBM_grid_1_AutoML_6_20251207_131718_model_54             9.9434   98.8712  7.68111  0.389482                   98.8712\n",
            "[10 rows x 6 columns]\n",
            "\n",
            "  Best model for 'Avg_Resp_Right_Std': DeepLearning_grid_2_AutoML_6_20251207_131718_model_1\n",
            "  Best -RMSE for 'Avg_Resp_Right_Std': -8.8368\n",
            "\n",
            "--- Evaluating 'Avg_Resp_Right_Hurst' as potential target ---\n",
            "  H2O determined type for 'Avg_Resp_Right_Hurst': real\n",
            "  Unique values in 'Avg_Resp_Right_Hurst': 43\n",
            "  Determined task type: regression\n",
            "  Fitting H2O AutoML for regression on 'Avg_Resp_Right_Hurst'...\n",
            "AutoML progress: |\n",
            "13:19:20.536: Project: AutoML_7_20251207_131920\n",
            "13:19:20.536: 5-fold cross-validation will be used.\n",
            "13:19:20.536: Setting stopping tolerance adaptively based on the training frame: 0.05\n",
            "13:19:20.536: Build control seed: 42\n",
            "13:19:20.536: training frame: Frame key: AutoML_7_20251207_131920_training_py_63_sid_8553    cols: 10    rows: 38  chunks: 1    size: 3208  checksum: 1803724448260043734\n",
            "13:19:20.536: validation frame: NULL\n",
            "13:19:20.536: leaderboard frame: NULL\n",
            "13:19:20.536: blending frame: NULL\n",
            "13:19:20.536: response column: Avg_Resp_Right_Hurst\n",
            "13:19:20.536: fold column: null\n",
            "13:19:20.536: weights column: null\n",
            "13:19:20.537: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
            "13:19:20.538: AutoML job created: 2025.12.07 13:19:20.536\n",
            "13:19:20.539: AutoML build started: 2025.12.07 13:19:20.539\n",
            "13:19:20.542: AutoML: starting XGBoost_1_AutoML_7_20251207_131920 model training\n",
            "\n",
            "\n",
            "13:19:22.16: New leader: XGBoost_1_AutoML_7_20251207_131920, rmse: 0.41462568606788924\n",
            "13:19:22.17: AutoML: starting GLM_1_AutoML_7_20251207_131920 model training\n",
            "\n",
            "\n",
            "13:19:22.164: New leader: GLM_1_AutoML_7_20251207_131920, rmse: 0.411393773844113\n",
            "13:19:22.164: AutoML: starting GBM_1_AutoML_7_20251207_131920 model training\n",
            "13:19:22.165: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 38.0.\n",
            "13:19:22.166: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_7_20251207_131920 model training\n",
            "\n",
            "█\n",
            "13:19:22.273: AutoML: starting XGBoost_2_AutoML_7_20251207_131920 model training\n",
            "\n",
            "█\n",
            "13:19:23.639: AutoML: starting DRF_1_AutoML_7_20251207_131920 model training\n",
            "\n",
            "█\n",
            "13:19:24.5: AutoML: starting GBM_2_AutoML_7_20251207_131920 model training\n",
            "13:19:24.179: AutoML: starting GBM_3_AutoML_7_20251207_131920 model training\n",
            "13:19:24.354: AutoML: starting GBM_4_AutoML_7_20251207_131920 model training\n",
            "13:19:24.535: New leader: GBM_4_AutoML_7_20251207_131920, rmse: 0.4112406949501543\n",
            "13:19:24.535: AutoML: starting StackedEnsemble_BestOfFamily_2_AutoML_7_20251207_131920 model training\n",
            "13:19:24.644: AutoML: starting StackedEnsemble_AllModels_1_AutoML_7_20251207_131920 model training\n",
            "13:19:24.757: AutoML: starting XGBoost_3_AutoML_7_20251207_131920 model training\n",
            "\n",
            "███\n",
            "13:19:26.38: AutoML: starting XRT_1_AutoML_7_20251207_131920 model training\n",
            "13:19:26.474: AutoML: starting GBM_5_AutoML_7_20251207_131920 model training\n",
            "\n",
            "███\n",
            "13:19:26.823: AutoML: starting DeepLearning_1_AutoML_7_20251207_131920 model training\n",
            "13:19:26.939: AutoML: starting StackedEnsemble_BestOfFamily_3_AutoML_7_20251207_131920 model training\n",
            "13:19:27.48: AutoML: starting StackedEnsemble_AllModels_2_AutoML_7_20251207_131920 model training\n",
            "13:19:27.157: AutoML: starting XGBoost_grid_1_AutoML_7_20251207_131920 hyperparameter search\n",
            "\n",
            "██████████████████████████\n",
            "13:20:19.312: New leader: XGBoost_grid_1_AutoML_7_20251207_131920_model_30, rmse: 0.4078709965751812\n",
            "\n",
            "█\n",
            "13:20:19.870: AutoML: starting GBM_grid_1_AutoML_7_20251207_131920 hyperparameter search\n",
            "13:20:20.876: New leader: GBM_grid_1_AutoML_7_20251207_131920_model_4, rmse: 0.4023066494679482\n",
            "\n",
            "██\n",
            "13:20:24.949: New leader: GBM_grid_1_AutoML_7_20251207_131920_model_25, rmse: 0.3927773663035648\n",
            "\n",
            "\n",
            "13:20:25.674: AutoML: starting DeepLearning_grid_1_AutoML_7_20251207_131920 hyperparameter search\n",
            "\n",
            "█████████████████\n",
            "13:21:02.321: AutoML: starting StackedEnsemble_BestOfFamily_4_AutoML_7_20251207_131920 model training\n",
            "13:21:02.433: AutoML: starting StackedEnsemble_AllModels_3_AutoML_7_20251207_131920 model training\n",
            "13:21:02.573: AutoML: starting DeepLearning_grid_2_AutoML_7_20251207_131920 hyperparameter search\n",
            "\n",
            "███\n",
            "13:21:09.874: AutoML: starting DeepLearning_grid_3_AutoML_7_20251207_131920 hyperparameter search\n",
            "\n",
            "███\n",
            "13:21:17.45: AutoML: starting StackedEnsemble_AllModels_4_AutoML_7_20251207_131920 model training\n",
            "13:21:17.173: Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_7_20251207_131920_model_30\n",
            "13:21:17.173: AutoML: starting XGBoost_lr_search_selection_AutoML_7_20251207_131920_select model training\n",
            "\n",
            "█\n",
            "13:21:19.217: Retraining best GBM with learning rate annealing: GBM_grid_1_AutoML_7_20251207_131920_model_25\n",
            "13:21:19.217: AutoML: starting GBM_lr_annealing_selection_AutoML_7_20251207_131920_select_model model training\n",
            "13:21:19.548: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
            "13:21:19.549: AutoML: starting StackedEnsemble_BestOfFamily_5_AutoML_7_20251207_131920 model training\n",
            "\n",
            "\n",
            "13:21:20.72: AutoML: starting StackedEnsemble_AllModels_5_AutoML_7_20251207_131920 model training\n",
            "\n",
            "█| (done) 100%\n",
            "\n",
            "13:21:21.116: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {StackedEnsemble : [best_of_family_2 (2g, 5w), all_2 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {StackedEnsemble : [best_of_family_3 (3g, 5w), all_3 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {DeepLearning : [grid_1 (4g, 30w)]}, {StackedEnsemble : [best_of_family_4 (4g, 5w), all_4 (4g, 10w)]}, {DeepLearning : [grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {StackedEnsemble : [all_5 (5g, 10w)]}, {XGBoost : [lr_search (6g, 30w)]}, {GBM : [lr_annealing (6g, 10w)]}, {StackedEnsemble : [best_of_family_gbm (6g, 10w), all_gbm (7g, 10w)]}]\n",
            "13:21:21.116: AutoML build stopped: 2025.12.07 13:21:21.116\n",
            "13:21:21.116: AutoML build done: built 73 models\n",
            "13:21:21.116: AutoML duration:  2 min  0.577 sec\n",
            "\n",
            "model_id                                              rmse       mse       mae     rmsle    mean_residual_deviance\n",
            "GBM_grid_1_AutoML_7_20251207_131920_model_25      0.392777  0.154274  0.34271   0.186645                  0.154274\n",
            "GBM_grid_1_AutoML_7_20251207_131920_model_4       0.402307  0.161851  0.340181  0.194222                  0.161851\n",
            "GBM_grid_1_AutoML_7_20251207_131920_model_21      0.407258  0.165859  0.341679  0.197565                  0.165859\n",
            "XGBoost_grid_1_AutoML_7_20251207_131920_model_30  0.407871  0.166359  0.347641  0.196579                  0.166359\n",
            "GBM_grid_1_AutoML_7_20251207_131920_model_9       0.407904  0.166386  0.353439  0.198075                  0.166386\n",
            "GBM_grid_1_AutoML_7_20251207_131920_model_15      0.408111  0.166555  0.344984  0.198281                  0.166555\n",
            "GBM_4_AutoML_7_20251207_131920                    0.411241  0.169119  0.352957  0.198525                  0.169119\n",
            "GLM_1_AutoML_7_20251207_131920                    0.411394  0.169245  0.359532  0.194546                  0.169245\n",
            "GBM_grid_1_AutoML_7_20251207_131920_model_13      0.412173  0.169886  0.356358  0.199446                  0.169886\n",
            "GBM_grid_1_AutoML_7_20251207_131920_model_11      0.412598  0.170237  0.355092  0.200082                  0.170237\n",
            "[10 rows x 6 columns]\n",
            "\n",
            "  Best model for 'Avg_Resp_Right_Hurst': GBM_grid_1_AutoML_7_20251207_131920_model_25\n",
            "  Best -RMSE for 'Avg_Resp_Right_Hurst': -0.3928\n",
            "\n",
            "--- Evaluating 'Avg_Resp_DWT_Cluster' as potential target ---\n",
            "  H2O determined type for 'Avg_Resp_DWT_Cluster': int\n",
            "  Unique values in 'Avg_Resp_DWT_Cluster': 3\n",
            "  Determined task type: regression\n",
            "  Fitting H2O AutoML for regression on 'Avg_Resp_DWT_Cluster'...\n",
            "AutoML progress: |\n",
            "13:21:23.138: Project: AutoML_8_20251207_132123\n",
            "13:21:23.138: 5-fold cross-validation will be used.\n",
            "13:21:23.138: Setting stopping tolerance adaptively based on the training frame: 0.05\n",
            "13:21:23.138: Build control seed: 42\n",
            "13:21:23.138: training frame: Frame key: AutoML_8_20251207_132123_training_py_73_sid_8553    cols: 10    rows: 38  chunks: 1    size: 3208  checksum: 1803724448260043734\n",
            "13:21:23.138: validation frame: NULL\n",
            "13:21:23.138: leaderboard frame: NULL\n",
            "13:21:23.138: blending frame: NULL\n",
            "13:21:23.138: response column: Avg_Resp_DWT_Cluster\n",
            "13:21:23.138: fold column: null\n",
            "13:21:23.138: weights column: null\n",
            "13:21:23.138: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
            "13:21:23.140: AutoML job created: 2025.12.07 13:21:23.137\n",
            "13:21:23.140: AutoML build started: 2025.12.07 13:21:23.140\n",
            "13:21:23.141: AutoML: starting XGBoost_1_AutoML_8_20251207_132123 model training\n",
            "\n",
            "█\n",
            "13:21:25.308: New leader: XGBoost_1_AutoML_8_20251207_132123, rmse: 0.4171991750412055\n",
            "13:21:25.309: AutoML: starting GLM_1_AutoML_8_20251207_132123 model training\n",
            "13:21:25.446: New leader: GLM_1_AutoML_8_20251207_132123, rmse: 0.38249639904855304\n",
            "13:21:25.446: AutoML: starting GBM_1_AutoML_8_20251207_132123 model training\n",
            "13:21:25.447: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 38.0.\n",
            "13:21:25.447: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_8_20251207_132123 model training\n",
            "13:21:25.555: AutoML: starting XGBoost_2_AutoML_8_20251207_132123 model training\n",
            "\n",
            "█\n",
            "13:21:26.996: New leader: XGBoost_2_AutoML_8_20251207_132123, rmse: 0.3512007895520266\n",
            "13:21:26.997: AutoML: starting DRF_1_AutoML_8_20251207_132123 model training\n",
            "\n",
            "\n",
            "13:21:27.279: New leader: DRF_1_AutoML_8_20251207_132123, rmse: 0.26181455958994226\n",
            "13:21:27.279: AutoML: starting GBM_2_AutoML_8_20251207_132123 model training\n",
            "\n",
            "█\n",
            "13:21:27.630: AutoML: starting GBM_3_AutoML_8_20251207_132123 model training\n",
            "13:21:27.942: AutoML: starting GBM_4_AutoML_8_20251207_132123 model training\n",
            "13:21:28.135: AutoML: starting StackedEnsemble_BestOfFamily_2_AutoML_8_20251207_132123 model training\n",
            "13:21:28.247: AutoML: starting StackedEnsemble_AllModels_1_AutoML_8_20251207_132123 model training\n",
            "13:21:28.358: AutoML: starting XGBoost_3_AutoML_8_20251207_132123 model training\n",
            "\n",
            "████\n",
            "13:21:29.668: New leader: XGBoost_3_AutoML_8_20251207_132123, rmse: 0.2464300653557764\n",
            "13:21:29.669: AutoML: starting XRT_1_AutoML_8_20251207_132123 model training\n",
            "13:21:29.980: AutoML: starting GBM_5_AutoML_8_20251207_132123 model training\n",
            "13:21:30.472: New leader: GBM_5_AutoML_8_20251207_132123, rmse: 0.20273953110042137\n",
            "13:21:30.473: AutoML: starting DeepLearning_1_AutoML_8_20251207_132123 model training\n",
            "13:21:30.608: AutoML: starting StackedEnsemble_BestOfFamily_3_AutoML_8_20251207_132123 model training\n",
            "\n",
            "████\n",
            "13:21:30.717: AutoML: starting StackedEnsemble_AllModels_2_AutoML_8_20251207_132123 model training\n",
            "13:21:30.827: AutoML: starting XGBoost_grid_1_AutoML_8_20251207_132123 hyperparameter search\n",
            "\n",
            "██████\n",
            "13:21:33.831: New leader: XGBoost_grid_1_AutoML_8_20251207_132123_model_2, rmse: 0.2024081934020427\n",
            "\n",
            "██████████████████\n",
            "13:22:22.675: AutoML: starting GBM_grid_1_AutoML_8_20251207_132123 hyperparameter search\n",
            "\n",
            "███\n",
            "13:22:29.729: New leader: GBM_grid_1_AutoML_8_20251207_132123_model_31, rmse: 0.1682861542436811\n",
            "\n",
            "██████\n",
            "13:22:41.915: New leader: GBM_grid_1_AutoML_8_20251207_132123_model_81, rmse: 0.1654588787704524\n",
            "\n",
            "███████\n",
            "13:22:57.263: AutoML: starting DeepLearning_grid_1_AutoML_8_20251207_132123 hyperparameter search\n",
            "\n",
            "████████\n",
            "13:23:14.723: AutoML: starting StackedEnsemble_BestOfFamily_4_AutoML_8_20251207_132123 model training\n",
            "13:23:14.894: AutoML: starting StackedEnsemble_AllModels_3_AutoML_8_20251207_132123 model training\n",
            "13:23:15.269: AutoML: starting DeepLearning_grid_2_AutoML_8_20251207_132123 hyperparameter search\n",
            "\n",
            "█\n",
            "13:23:18.502: AutoML: starting DeepLearning_grid_3_AutoML_8_20251207_132123 hyperparameter search\n",
            "\n",
            "██\n",
            "13:23:21.818: AutoML: starting StackedEnsemble_BestOfFamily_5_AutoML_8_20251207_132123 model training\n",
            "13:23:21.938: AutoML: starting StackedEnsemble_AllModels_4_AutoML_8_20251207_132123 model training\n",
            "13:23:22.182: Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_8_20251207_132123_model_2\n",
            "13:23:22.182: AutoML: starting XGBoost_lr_search_selection_AutoML_8_20251207_132123_select model training\n",
            "\n",
            "█| (done) 100%\n",
            "\n",
            "13:23:24.361: New leader: GBM_grid_1_AutoML_8_20251207_132123_model_81, rmse: 0.1654588787704524\n",
            "13:23:24.372: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {StackedEnsemble : [best_of_family_2 (2g, 5w), all_2 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {StackedEnsemble : [best_of_family_3 (3g, 5w), all_3 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {DeepLearning : [grid_1 (4g, 30w)]}, {StackedEnsemble : [best_of_family_4 (4g, 5w), all_4 (4g, 10w)]}, {DeepLearning : [grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {StackedEnsemble : [best_of_family_5 (5g, 5w), all_5 (5g, 10w)]}, {XGBoost : [lr_search (6g, 30w)]}]\n",
            "13:23:24.372: AutoML build stopped: 2025.12.07 13:23:24.372\n",
            "13:23:24.372: AutoML build done: built 149 models\n",
            "13:23:24.372: AutoML duration:  2 min  1.232 sec\n",
            "\n",
            "model_id                                                                      rmse        mse        mae      rmsle    mean_residual_deviance\n",
            "GBM_grid_1_AutoML_8_20251207_132123_model_81                              0.165459  0.0273766  0.0370997  0.0687463                 0.0273766\n",
            "GBM_grid_1_AutoML_8_20251207_132123_model_31                              0.168286  0.0283202  0.0367828  0.0693679                 0.0283202\n",
            "XGBoost_lr_search_selection_AutoML_8_20251207_132123_select_grid_model_1  0.201925  0.0407735  0.060984   0.092124                  0.0407735\n",
            "GBM_5_AutoML_8_20251207_132123                                            0.20274   0.0411033  0.0376119  0.0874812                 0.0411033\n",
            "GBM_grid_1_AutoML_8_20251207_132123_model_96                              0.205437  0.0422045  0.0492507  0.08486                   0.0422045\n",
            "XGBoost_grid_1_AutoML_8_20251207_132123_model_14                          0.205936  0.0424096  0.0383735  0.089574                  0.0424096\n",
            "StackedEnsemble_BestOfFamily_4_AutoML_8_20251207_132123                   0.221315  0.0489801  0.0725187  0.102901                  0.0489801\n",
            "StackedEnsemble_BestOfFamily_5_AutoML_8_20251207_132123                   0.222417  0.0494695  0.0760792  0.103638                  0.0494695\n",
            "GBM_grid_1_AutoML_8_20251207_132123_model_1                               0.225069  0.0506561  0.0399373  0.100882                  0.0506561\n",
            "GBM_grid_1_AutoML_8_20251207_132123_model_34                              0.225187  0.0507093  0.0546215  0.102659                  0.0507093\n",
            "[10 rows x 6 columns]\n",
            "\n",
            "  Best model for 'Avg_Resp_DWT_Cluster': GBM_grid_1_AutoML_8_20251207_132123_model_81\n",
            "  Best -RMSE for 'Avg_Resp_DWT_Cluster': -0.1655\n",
            "\n",
            "--- Evaluating 'Inh_Thresh_DTW_Cluster' as potential target ---\n",
            "  H2O determined type for 'Inh_Thresh_DTW_Cluster': int\n",
            "  Unique values in 'Inh_Thresh_DTW_Cluster': 3\n",
            "  Determined task type: regression\n",
            "  Fitting H2O AutoML for regression on 'Inh_Thresh_DTW_Cluster'...\n",
            "AutoML progress: |\n",
            "13:23:25.955: Project: AutoML_9_20251207_132325\n",
            "13:23:25.955: 5-fold cross-validation will be used.\n",
            "13:23:25.955: Setting stopping tolerance adaptively based on the training frame: 0.05\n",
            "13:23:25.955: Build control seed: 42\n",
            "13:23:25.955: training frame: Frame key: AutoML_9_20251207_132325_training_py_83_sid_8553    cols: 10    rows: 38  chunks: 1    size: 3208  checksum: 1803724448260043734\n",
            "13:23:25.955: validation frame: NULL\n",
            "13:23:25.955: leaderboard frame: NULL\n",
            "13:23:25.955: blending frame: NULL\n",
            "13:23:25.955: response column: Inh_Thresh_DTW_Cluster\n",
            "13:23:25.955: fold column: null\n",
            "13:23:25.955: weights column: null\n",
            "13:23:25.955: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
            "13:23:25.956: AutoML job created: 2025.12.07 13:23:25.955\n",
            "13:23:25.957: AutoML build started: 2025.12.07 13:23:25.956\n",
            "13:23:25.957: AutoML: starting XGBoost_1_AutoML_9_20251207_132325 model training\n",
            "\n",
            "\n",
            "13:23:27.43: New leader: XGBoost_1_AutoML_9_20251207_132325, rmse: 0.794589958471502\n",
            "13:23:27.44: AutoML: starting GLM_1_AutoML_9_20251207_132325 model training\n",
            "13:23:27.131: New leader: GLM_1_AutoML_9_20251207_132325, rmse: 0.6964658318177018\n",
            "13:23:27.132: AutoML: starting GBM_1_AutoML_9_20251207_132325 model training\n",
            "13:23:27.132: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 38.0.\n",
            "13:23:27.133: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_9_20251207_132325 model training\n",
            "13:23:27.244: AutoML: starting XGBoost_2_AutoML_9_20251207_132325 model training\n",
            "\n",
            "███\n",
            "13:23:29.423: AutoML: starting DRF_1_AutoML_9_20251207_132325 model training\n",
            "13:23:29.769: AutoML: starting GBM_2_AutoML_9_20251207_132325 model training\n",
            "13:23:29.991: AutoML: starting GBM_3_AutoML_9_20251207_132325 model training\n",
            "\n",
            "\n",
            "13:23:30.272: AutoML: starting GBM_4_AutoML_9_20251207_132325 model training\n",
            "\n",
            "█\n",
            "13:23:30.481: AutoML: starting StackedEnsemble_BestOfFamily_2_AutoML_9_20251207_132325 model training\n",
            "13:23:30.597: New leader: StackedEnsemble_BestOfFamily_2_AutoML_9_20251207_132325, rmse: 0.6917993051702924\n",
            "13:23:30.598: AutoML: starting StackedEnsemble_AllModels_1_AutoML_9_20251207_132325 model training\n",
            "13:23:30.721: AutoML: starting XGBoost_3_AutoML_9_20251207_132325 model training\n",
            "\n",
            "██\n",
            "13:23:32.91: AutoML: starting XRT_1_AutoML_9_20251207_132325 model training\n",
            "\n",
            "██\n",
            "13:23:32.526: AutoML: starting GBM_5_AutoML_9_20251207_132325 model training\n",
            "13:23:32.813: AutoML: starting DeepLearning_1_AutoML_9_20251207_132325 model training\n",
            "13:23:32.929: AutoML: starting StackedEnsemble_BestOfFamily_3_AutoML_9_20251207_132325 model training\n",
            "13:23:33.37: AutoML: starting StackedEnsemble_AllModels_2_AutoML_9_20251207_132325 model training\n",
            "13:23:33.148: AutoML: starting XGBoost_grid_1_AutoML_9_20251207_132325 hyperparameter search\n",
            "\n",
            "████████████████████████\n",
            "13:24:17.780: AutoML: starting GBM_grid_1_AutoML_9_20251207_132325 hyperparameter search\n",
            "\n",
            "███████\n",
            "13:24:34.216: AutoML: starting DeepLearning_grid_1_AutoML_9_20251207_132325 hyperparameter search\n",
            "\n",
            "████████████████\n",
            "13:25:08.834: AutoML: starting StackedEnsemble_BestOfFamily_4_AutoML_9_20251207_132325 model training\n",
            "13:25:08.959: AutoML: starting StackedEnsemble_AllModels_3_AutoML_9_20251207_132325 model training\n",
            "\n",
            "\n",
            "13:25:09.282: AutoML: starting DeepLearning_grid_2_AutoML_9_20251207_132325 hyperparameter search\n",
            "\n",
            "███\n",
            "13:25:16.581: AutoML: starting DeepLearning_grid_3_AutoML_9_20251207_132325 hyperparameter search\n",
            "\n",
            "███\n",
            "13:25:23.239: AutoML: starting StackedEnsemble_BestOfFamily_5_AutoML_9_20251207_132325 model training\n",
            "13:25:23.374: AutoML: starting StackedEnsemble_AllModels_4_AutoML_9_20251207_132325 model training\n",
            "13:25:23.649: Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_9_20251207_132325_model_6\n",
            "13:25:23.649: AutoML: starting XGBoost_lr_search_selection_AutoML_9_20251207_132325_select model training\n",
            "\n",
            "██| (done) 100%\n",
            "\n",
            "13:25:25.704: Retraining best GBM with learning rate annealing: GBM_grid_1_AutoML_9_20251207_132325_model_20\n",
            "13:25:25.704: AutoML: starting GBM_lr_annealing_selection_AutoML_9_20251207_132325_select_model model training\n",
            "13:25:25.812: New leader: StackedEnsemble_BestOfFamily_2_AutoML_9_20251207_132325, rmse: 0.6917993051702924\n",
            "13:25:25.821: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
            "13:25:25.822: AutoML: starting StackedEnsemble_BestOfFamily_6_AutoML_9_20251207_132325 model training\n",
            "13:25:26.417: New leader: StackedEnsemble_BestOfFamily_6_AutoML_9_20251207_132325, rmse: 0.6698996449213137\n",
            "13:25:26.417: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {StackedEnsemble : [best_of_family_2 (2g, 5w), all_2 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {StackedEnsemble : [best_of_family_3 (3g, 5w), all_3 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {DeepLearning : [grid_1 (4g, 30w)]}, {StackedEnsemble : [best_of_family_4 (4g, 5w), all_4 (4g, 10w)]}, {DeepLearning : [grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {StackedEnsemble : [best_of_family_5 (5g, 5w), all_5 (5g, 10w)]}, {XGBoost : [lr_search (6g, 30w)]}, {GBM : [lr_annealing (6g, 10w)]}, {StackedEnsemble : [best_of_family_gbm (6g, 10w)]}]\n",
            "13:25:26.417: AutoML build stopped: 2025.12.07 13:25:26.417\n",
            "13:25:26.417: AutoML build done: built 116 models\n",
            "13:25:26.417: AutoML duration:  2 min  0.461 sec\n",
            "\n",
            "model_id                                                     rmse       mse       mae     rmsle    mean_residual_deviance\n",
            "StackedEnsemble_BestOfFamily_6_AutoML_9_20251207_132325  0.6699    0.448766  0.564101  0.399628                  0.448766\n",
            "StackedEnsemble_BestOfFamily_2_AutoML_9_20251207_132325  0.691799  0.478586  0.60751   0.420973                  0.478586\n",
            "XGBoost_grid_1_AutoML_9_20251207_132325_model_6          0.691913  0.478743  0.608401  0.417109                  0.478743\n",
            "XGBoost_grid_1_AutoML_9_20251207_132325_model_29         0.693962  0.481583  0.607332  0.421927                  0.481583\n",
            "XGBoost_grid_1_AutoML_9_20251207_132325_model_26         0.69511   0.483178  0.605666  0.421927                  0.483178\n",
            "XGBoost_grid_1_AutoML_9_20251207_132325_model_25         0.695336  0.483492  0.607726  0.420591                  0.483492\n",
            "XGBoost_grid_1_AutoML_9_20251207_132325_model_28         0.695765  0.48409   0.608552  0.419889                  0.48409\n",
            "GLM_1_AutoML_9_20251207_132325                           0.696466  0.485065  0.60574   0.422804                  0.485065\n",
            "XGBoost_grid_1_AutoML_9_20251207_132325_model_18         0.696787  0.485512  0.609463  0.422683                  0.485512\n",
            "XGBoost_grid_1_AutoML_9_20251207_132325_model_32         0.698128  0.487382  0.608194  0.42205                   0.487382\n",
            "[10 rows x 6 columns]\n",
            "\n",
            "  Best model for 'Inh_Thresh_DTW_Cluster': StackedEnsemble_BestOfFamily_6_AutoML_9_20251207_132325\n",
            "  Best -RMSE for 'Inh_Thresh_DTW_Cluster': -0.6699\n",
            "\n",
            "--- Summary of H2O AutoML Performance for Potential Targets ---\n",
            "  Avg_Resp_DWT_Cluster      | -RMSE           | -0.1655 | Task: regression\n",
            "  Avg_Resp_Right_Hurst      | -RMSE           | -0.3928 | Task: regression\n",
            "  Avg_Resp_Left_Hurst       | -RMSE           | -0.4240 | Task: regression\n",
            "  Inh_Thresh_DTW_Cluster    | -RMSE           | -0.6699 | Task: regression\n",
            "  Avg_Resp_Right_Std        | -RMSE           | -8.8368 | Task: regression\n",
            "  Unnamed: 0                | -RMSE           | -12.7363 | Task: regression\n",
            "  Avg_Resp_Left_Std         | -RMSE           | -14.7372 | Task: regression\n",
            "  Avg_Resp_Right_Mean       | -RMSE           | -19.4107 | Task: regression\n",
            "  Avg_Resp_Left_Mean        | -RMSE           | -27.3590 | Task: regression\n",
            "\n",
            "Best target column based on H2O AutoML performance: 'Avg_Resp_DWT_Cluster' with -RMSE: -0.1655 (Task: regression)\n",
            "\n",
            "--- Leaderboard for the Best Target ('Avg_Resp_DWT_Cluster') ---\n",
            "model_id                                                                      rmse        mse        mae      rmsle    mean_residual_deviance\n",
            "GBM_grid_1_AutoML_8_20251207_132123_model_81                              0.165459  0.0273766  0.0370997  0.0687463                 0.0273766\n",
            "GBM_grid_1_AutoML_8_20251207_132123_model_31                              0.168286  0.0283202  0.0367828  0.0693679                 0.0283202\n",
            "XGBoost_lr_search_selection_AutoML_8_20251207_132123_select_grid_model_1  0.201925  0.0407735  0.060984   0.092124                  0.0407735\n",
            "GBM_5_AutoML_8_20251207_132123                                            0.20274   0.0411033  0.0376119  0.0874812                 0.0411033\n",
            "GBM_grid_1_AutoML_8_20251207_132123_model_96                              0.205437  0.0422045  0.0492507  0.08486                   0.0422045\n",
            "XGBoost_grid_1_AutoML_8_20251207_132123_model_14                          0.205936  0.0424096  0.0383735  0.089574                  0.0424096\n",
            "StackedEnsemble_BestOfFamily_4_AutoML_8_20251207_132123                   0.221315  0.0489801  0.0725187  0.102901                  0.0489801\n",
            "StackedEnsemble_BestOfFamily_5_AutoML_8_20251207_132123                   0.222417  0.0494695  0.0760792  0.103638                  0.0494695\n",
            "GBM_grid_1_AutoML_8_20251207_132123_model_1                               0.225069  0.0506561  0.0399373  0.100882                  0.0506561\n",
            "GBM_grid_1_AutoML_8_20251207_132123_model_34                              0.225187  0.0507093  0.0546215  0.102659                  0.0507093\n",
            "[158 rows x 6 columns]\n",
            "\n",
            "\n",
            "Shutting down H2O...\n",
            "H2O session _sid_8553 closed.\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hnz5LXmN4hk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75eae7a9"
      },
      "source": [
        "# Task\n",
        "Initialize H2O, load `df_clean` into an H2OFrame, retrieve the best model using `best_lb`, calculate Shapley values for the best model on the training data, and then visualize the feature importance using these Shapley values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38a9e613"
      },
      "source": [
        "## Re-initialize H2O and Load Data\n",
        "\n",
        "### Subtask:\n",
        "Initialize H2O and load the cleaned dataset into an H2OFrame, similar to the initial setup, as the H2O session was shut down.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28731933"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires re-initializing H2O and converting the cleaned Pandas DataFrame (`df_clean`) back into an H2OFrame for further processing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "45328ac3",
        "outputId": "3efe4ec6-e4e0-44cf-abd8-e62c81b74b65"
      },
      "source": [
        "print(\"Initializing H2O...\")\n",
        "h2o.init(strict_version_check=False) # Use strict_version_check=False to avoid issues with different H2O versions\n",
        "\n",
        "# Convert the clean pandas DataFrame to an H2O Frame\n",
        "h2o_df_reinit = h2o.H2OFrame(df_clean)\n",
        "print(\"Data successfully converted to H2O Frame after re-initialization.\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing H2O...\n",
            "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"17.0.16\" 2025-07-15; OpenJDK Runtime Environment (build 17.0.16+8-Ubuntu-0ubuntu122.04.1); OpenJDK 64-Bit Server VM (build 17.0.16+8-Ubuntu-0ubuntu122.04.1, mixed mode, sharing)\n",
            "  Starting server from /usr/local/lib/python3.12/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmpkab03s8w\n",
            "  JVM stdout: /tmp/tmpkab03s8w/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmpkab03s8w/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  -----------------------------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         03 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.46.0.9\n",
              "H2O_cluster_version_age:    12 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_smxdyr\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.168 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.12.12 final\n",
              "--------------------------  -----------------------------------------------------------------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-2.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-2 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-2 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-2 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table th,\n",
              "#h2o-table-2 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>03 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.46.0.9</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>12 days</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_smxdyr</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.168 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.12.12 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "Data successfully converted to H2O Frame after re-initialization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3acf906c"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to retrieve the best model from the `best_lb` leaderboard, which was determined in the previous H2O AutoML run. This model will be used for further analysis, specifically for calculating Shapley values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "1b9039df",
        "outputId": "09277dc4-cb06-461d-b375-8a28626c9175"
      },
      "source": [
        "model_id = best_lb[0, 'model_id']\n",
        "best_model = h2o.get_model(model_id)\n",
        "\n",
        "print(f\"Retrieved best model: {best_model.model_id}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "H2OResponseError",
          "evalue": "Server error java.lang.IllegalArgumentException:\n  Error: Name lookup of 'AutoML_8_20251207_132123_leaderboard' failed\n  Request: POST /99/Rapids\n    data: {'ast': \"(tmp= py_91_sid_af73 (rows (cols_py AutoML_8_20251207_132123_leaderboard 'model_id') 0))\", 'session_id': '_sid_af73'}\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mH2OResponseError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1907056968.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_lb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Retrieved best model: {best_model.model_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2160\u001b[0m         \u001b[0;31m# return a Frame, EVEN IF the selectors are e.g. slices-of-1-value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2162\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2164\u001b[0m         \u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_ncols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/frame.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mframe2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \"\"\"\n\u001b[0;32m--> 791\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mH2OValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not a 1x1 Frame\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mExprNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"flatten\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/frame.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \"\"\"\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/frame.py\u001b[0m in \u001b[0;36mnrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_frame\u001b[0;34m(self, rows, rows_offset, cols, cols_offset, fill_cache)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfill_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrows_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/expr.py\u001b[0m in \u001b[0;36m_eager_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m  \u001b[0;31m# Data already computed under ID, but not cached locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_eager_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# returns a scalar (or a list of scalars)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/expr.py\u001b[0m in \u001b[0;36m_eval_driver\u001b[0;34m(self, top)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \"\"\"\n\u001b[1;32m    113\u001b[0m         \u001b[0mexec_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_ast_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExprNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrapids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'scalar'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scalar'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/expr.py\u001b[0m in \u001b[0;36mrapids\u001b[0;34m(expr)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mJSON\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpython\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mRapids\u001b[0m \u001b[0mexecution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \"\"\"\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST /99/Rapids\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ast\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"session_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mapi\u001b[0;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m# type checks are performed in H2OConnection class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0m_check_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh2oconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    497\u001b[0m                     \u001b[0msave_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_end_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36m_process_response\u001b[0;34m(response, save_to)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m412\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH2OErrorV3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_stacktrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mH2OResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;31m# Server errors (notably 500 = \"Server Error\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mH2OResponseError\u001b[0m: Server error java.lang.IllegalArgumentException:\n  Error: Name lookup of 'AutoML_8_20251207_132123_leaderboard' failed\n  Request: POST /99/Rapids\n    data: {'ast': \"(tmp= py_91_sid_af73 (rows (cols_py AutoML_8_20251207_132123_leaderboard 'model_id') 0))\", 'session_id': '_sid_af73'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce5cf8fe"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous error occurred because the `best_lb` H2OFrame became invalid after the H2O session was shut down and re-initialized. To resolve this, I will retrieve the correct leaderboard for the `best_target_col` from the `all_results` dictionary, which was stored in the previous execution, and then extract the `model_id` from that valid leaderboard to get the best model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "260f64c3",
        "outputId": "7d6d87a7-aca7-4cc2-bae0-f0dc89c008f5"
      },
      "source": [
        "model_id = all_results[best_target_col]['leaderboard'][0, 'model_id']\n",
        "best_model = h2o.get_model(model_id)\n",
        "\n",
        "print(f\"Retrieved best model: {best_model.model_id}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "H2OResponseError",
          "evalue": "Server error java.lang.IllegalArgumentException:\n  Error: Name lookup of 'AutoML_8_20251207_132123_leaderboard' failed\n  Request: POST /99/Rapids\n    data: {'ast': \"(tmp= py_92_sid_af73 (rows (cols_py AutoML_8_20251207_132123_leaderboard 'model_id') 0))\", 'session_id': '_sid_af73'}\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mH2OResponseError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3709129089.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_target_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'leaderboard'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Retrieved best model: {best_model.model_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2160\u001b[0m         \u001b[0;31m# return a Frame, EVEN IF the selectors are e.g. slices-of-1-value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2162\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2164\u001b[0m         \u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_ncols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/frame.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mframe2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \"\"\"\n\u001b[0;32m--> 791\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mH2OValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not a 1x1 Frame\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mExprNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"flatten\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/frame.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \"\"\"\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/frame.py\u001b[0m in \u001b[0;36mnrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_frame\u001b[0;34m(self, rows, rows_offset, cols, cols_offset, fill_cache)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfill_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrows_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/expr.py\u001b[0m in \u001b[0;36m_eager_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m  \u001b[0;31m# Data already computed under ID, but not cached locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_eager_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# returns a scalar (or a list of scalars)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/expr.py\u001b[0m in \u001b[0;36m_eval_driver\u001b[0;34m(self, top)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \"\"\"\n\u001b[1;32m    113\u001b[0m         \u001b[0mexec_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_ast_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExprNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrapids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'scalar'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scalar'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/expr.py\u001b[0m in \u001b[0;36mrapids\u001b[0;34m(expr)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mJSON\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpython\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mRapids\u001b[0m \u001b[0mexecution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \"\"\"\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST /99/Rapids\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ast\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"session_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mapi\u001b[0;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m# type checks are performed in H2OConnection class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0m_check_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh2oconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    497\u001b[0m                     \u001b[0msave_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_end_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36m_process_response\u001b[0;34m(response, save_to)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m412\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH2OErrorV3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_stacktrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mH2OResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;31m# Server errors (notably 500 = \"Server Error\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mH2OResponseError\u001b[0m: Server error java.lang.IllegalArgumentException:\n  Error: Name lookup of 'AutoML_8_20251207_132123_leaderboard' failed\n  Request: POST /99/Rapids\n    data: {'ast': \"(tmp= py_92_sid_af73 (rows (cols_py AutoML_8_20251207_132123_leaderboard 'model_id') 0))\", 'session_id': '_sid_af73'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8487a7b3"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to retrieve the best model failed because the H2O session was shut down and re-initialized, making the `best_lb` (and any H2OFrame objects in `all_results`) stale. To get a valid model for subsequent steps (like Shapley values), it's necessary to re-run the H2O AutoML process specifically for the `best_target_col` within the newly initialized H2O session, then retrieve the best model from this new AutoML run.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6576ef3a",
        "outputId": "4e460591-e19a-47e6-a410-e9ce9b9b42c4"
      },
      "source": [
        "y = best_target_col\n",
        "X = [col for col in feature_columns if col != y]\n",
        "\n",
        "# Ensure the target column type is correctly set for H2O AutoML\n",
        "h2o_type = h2o_df_reinit.type(y)\n",
        "unique_vals_frame = h2o_df_reinit[y].unique()\n",
        "unique_count = unique_vals_frame.nrows\n",
        "total_count = h2o_df_reinit.nrows\n",
        "\n",
        "if h2o_type == 'enum' or unique_count < max(2, total_count * 0.05): # Treat as classification\n",
        "     h2o_df_reinit[y] = h2o_df_reinit[y].asfactor() # Convert to factor for classification\n",
        "     task = 'classification'\n",
        "else:\n",
        "    task = 'regression'\n",
        "\n",
        "print(f\"Re-training AutoML for the best target '{y}' (Task: {task})...\")\n",
        "\n",
        "# Split the H2O frame into training and testing sets\n",
        "train, test = h2o_df_reinit.split_frame(ratios=[0.8], seed=42)\n",
        "\n",
        "# Initialize H2O AutoML for the best target column\n",
        "# Use a shorter max_runtime_secs for quicker re-training in this context\n",
        "automl_re_run = H2OAutoML(\n",
        "    max_runtime_secs=60, # Reduced runtime for re-training\n",
        "    seed=42,\n",
        "    verbosity='info'\n",
        ")\n",
        "\n",
        "# Fit the AutoML model\n",
        "automl_re_run.train(x=X, y=y, training_frame=train)\n",
        "\n",
        "# Get the leaderboard from this new AutoML run\n",
        "new_leaderboard = automl_re_run.leaderboard\n",
        "\n",
        "# Get the model_id of the top model from the new leaderboard\n",
        "model_id = new_leaderboard[0, 'model_id']\n",
        "\n",
        "# Retrieve the best model object using its ID from the current H2O session\n",
        "best_model = h2o.get_model(model_id)\n",
        "\n",
        "print(f\"Retrieved newly trained best model: {best_model.model_id}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Re-training AutoML for the best target 'Avg_Resp_DWT_Cluster' (Task: regression)...\n",
            "AutoML progress: |\n",
            "13:35:58.586: Project: AutoML_1_20251207_133558\n",
            "13:35:58.596: 5-fold cross-validation will be used.\n",
            "13:35:58.602: Setting stopping tolerance adaptively based on the training frame: 0.05\n",
            "13:35:58.602: Build control seed: 42\n",
            "13:35:58.606: training frame: Frame key: AutoML_1_20251207_133558_training_py_95_sid_af73    cols: 10    rows: 38  chunks: 1    size: 3208  checksum: 1803724448260043734\n",
            "13:35:58.606: validation frame: NULL\n",
            "13:35:58.606: leaderboard frame: NULL\n",
            "13:35:58.607: blending frame: NULL\n",
            "13:35:58.609: response column: Avg_Resp_DWT_Cluster\n",
            "13:35:58.609: fold column: null\n",
            "13:35:58.611: weights column: null\n",
            "13:35:58.707: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
            "13:35:58.877: AutoML job created: 2025.12.07 13:35:58.425\n",
            "13:35:58.879: AutoML build started: 2025.12.07 13:35:58.878\n",
            "13:35:58.989: AutoML: starting XGBoost_1_AutoML_1_20251207_133558 model training\n",
            "\n",
            "████\n",
            "13:36:05.641: New leader: XGBoost_1_AutoML_1_20251207_133558, rmse: 0.4171991750412055\n",
            "13:36:05.655: AutoML: starting GLM_1_AutoML_1_20251207_133558 model training\n",
            "\n",
            "██\n",
            "13:36:06.537: New leader: GLM_1_AutoML_1_20251207_133558, rmse: 0.38249639904855304\n",
            "13:36:06.552: AutoML: starting GBM_1_AutoML_1_20251207_133558 model training\n",
            "13:36:06.553: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 38.0.\n",
            "13:36:06.580: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_1_20251207_133558 model training\n",
            "13:36:06.894: AutoML: starting XGBoost_2_AutoML_1_20251207_133558 model training\n",
            "\n",
            "████\n",
            "13:36:09.914: New leader: XGBoost_2_AutoML_1_20251207_133558, rmse: 0.3512007895520266\n",
            "13:36:09.924: AutoML: starting DRF_1_AutoML_1_20251207_133558 model training\n",
            "\n",
            "█\n",
            "13:36:11.163: New leader: DRF_1_AutoML_1_20251207_133558, rmse: 0.26181455958994226\n",
            "13:36:11.166: AutoML: starting GBM_2_AutoML_1_20251207_133558 model training\n",
            "13:36:12.74: AutoML: starting GBM_3_AutoML_1_20251207_133558 model training\n",
            "\n",
            "██\n",
            "13:36:12.726: AutoML: starting GBM_4_AutoML_1_20251207_133558 model training\n",
            "13:36:13.501: AutoML: starting StackedEnsemble_BestOfFamily_2_AutoML_1_20251207_133558 model training\n",
            "\n",
            "█\n",
            "13:36:13.764: AutoML: starting StackedEnsemble_AllModels_1_AutoML_1_20251207_133558 model training\n",
            "13:36:14.43: AutoML: starting XGBoost_3_AutoML_1_20251207_133558 model training\n",
            "\n",
            "█████\n",
            "13:36:18.284: New leader: XGBoost_3_AutoML_1_20251207_133558, rmse: 0.2464300653557764\n",
            "13:36:18.288: AutoML: starting XRT_1_AutoML_1_20251207_133558 model training\n",
            "13:36:19.265: AutoML: starting GBM_5_AutoML_1_20251207_133558 model training\n",
            "\n",
            "██\n",
            "13:36:20.696: New leader: GBM_5_AutoML_1_20251207_133558, rmse: 0.20273953110042137\n",
            "13:36:20.709: AutoML: starting DeepLearning_1_AutoML_1_20251207_133558 model training\n",
            "\n",
            "██\n",
            "13:36:21.571: AutoML: starting StackedEnsemble_BestOfFamily_3_AutoML_1_20251207_133558 model training\n",
            "13:36:21.828: AutoML: starting StackedEnsemble_AllModels_2_AutoML_1_20251207_133558 model training\n",
            "13:36:22.87: AutoML: starting XGBoost_grid_1_AutoML_1_20251207_133558 hyperparameter search\n",
            "\n",
            "██████████\n",
            "13:36:31.182: New leader: XGBoost_grid_1_AutoML_1_20251207_133558_model_2, rmse: 0.2024081934020427\n",
            "\n",
            "████████\n",
            "13:36:39.155: AutoML: starting GBM_grid_1_AutoML_1_20251207_133558 hyperparameter search\n",
            "\n",
            "████████████\n",
            "13:36:50.490: AutoML: starting DeepLearning_grid_1_AutoML_1_20251207_133558 hyperparameter search\n",
            "\n",
            "███████\n",
            "13:36:56.274: AutoML: starting StackedEnsemble_BestOfFamily_4_AutoML_1_20251207_133558 model training\n",
            "13:36:56.552: AutoML: starting StackedEnsemble_AllModels_3_AutoML_1_20251207_133558 model training\n",
            "\n",
            "█\n",
            "13:36:56.943: AutoML: starting DeepLearning_grid_2_AutoML_1_20251207_133558 hyperparameter search\n",
            "\n",
            "\n",
            "13:36:57.782: AutoML: starting DeepLearning_grid_3_AutoML_1_20251207_133558 hyperparameter search\n",
            "\n",
            "█\n",
            "13:36:58.601: AutoML: starting StackedEnsemble_AllModels_4_AutoML_1_20251207_133558 model training\n",
            "13:36:58.972: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {StackedEnsemble : [best_of_family_2 (2g, 5w), all_2 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {StackedEnsemble : [best_of_family_3 (3g, 5w), all_3 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {DeepLearning : [grid_1 (4g, 30w)]}, {StackedEnsemble : [best_of_family_4 (4g, 5w), all_4 (4g, 10w)]}, {DeepLearning : [grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {StackedEnsemble : [all_5 (5g, 10w)]}]\n",
            "13:36:58.972: AutoML build stopped: 2025.12.07 13:36:58.972\n",
            "13:36:58.972: AutoML build done: built 44 models\n",
            "13:36:58.976: AutoML duration:  1 min  0.094 sec\n",
            "\n",
            "█| (done) 100%\n",
            "Retrieved newly trained best model: XGBoost_grid_1_AutoML_1_20251207_133558_model_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a8b23aa"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the best model has been successfully retrieved, the next step is to calculate the Shapley values for this model on the training data. This will provide insights into each feature's contribution to the model's predictions, which is crucial for understanding feature importance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "bab1a279",
        "outputId": "13a26d33-c1c4-40b6-eb3c-74cee6d9e93e"
      },
      "source": [
        "print(\"Calculating Shapley values...\")\n",
        "# Calculate Shapley values for the best model on the training data\n",
        "# Note: This can be computationally intensive for large datasets or complex models.\n",
        "# For demonstration, we'll calculate on a subset or the training frame directly if it's small.\n",
        "\n",
        "# Ensure the training data used for the re-run is available\n",
        "# The 'train' H2OFrame was created in the previous step during the re-training process\n",
        "\n",
        "shapley_values = best_model.shapley_explanation(frame=train)\n",
        "\n",
        "print(\"Shapley values calculated successfully!\")\n",
        "print(\"First few rows of Shapley values:\")\n",
        "shapley_values.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Shapley values...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "type object 'ModelBase' has no attribute 'shapley_explanation'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3859412097.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# The 'train' H2OFrame was created in the previous step during the re-training process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mshapley_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshapley_explanation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapley values calculated successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/utils/metaclass.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_bci'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bci\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bci\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_clz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mnew_clz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend_and_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/utils/metaclass.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mMetaFeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_FOUND\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'ModelBase' has no attribute 'shapley_explanation'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e94e87c9"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed with an `AttributeError` because `shapley_explanation` is not directly accessible as a method of the `ModelBase` type. To correctly calculate Shapley values as a table, the `h2o.explanation.shap.shap_explanation_table` function should be used, taking the model and the data frame as arguments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "764efd11",
        "outputId": "d43e6e88-b6ec-41ba-9330-ff47f66fdf4f"
      },
      "source": [
        "import h2o.explanation # Ensure the explanation module is imported\n",
        "\n",
        "print(\"Calculating Shapley values...\")\n",
        "\n",
        "# Calculate Shapley values for the best model on the training data\n",
        "# Using h2o.explanation.shap.shap_explanation_table for direct access to SHAP table\n",
        "# This method takes the model and the frame as arguments\n",
        "shapley_values = h2o.explanation.shap.shap_explanation_table(model=best_model, frame=train)\n",
        "\n",
        "print(\"Shapley values calculated successfully!\")\n",
        "print(\"First few rows of Shapley values:\")\n",
        "shapley_values.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Shapley values...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'h2o.explanation' has no attribute 'shap'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-854740301.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Using h2o.explanation.shap.shap_explanation_table for direct access to SHAP table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# This method takes the model and the frame as arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mshapley_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplanation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_explanation_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapley values calculated successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'h2o.explanation' has no attribute 'shap'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca86ddff"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous error `AttributeError: module 'h2o.explanation' has no attribute 'shap'` indicates that the `h2o.explanation.shap` submodule does not exist or is not used in this manner. Instead, the `shap_explanation` method is directly available on the H2O model object itself for models that support it (like the `XGBoost` model we have). I will revert to using `best_model.shapley_explanation(frame=train)`, which is the correct way to calculate Shapley values for an H2O model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "bc6a7803",
        "outputId": "f2fa8063-c717-40a4-f54c-65ffd32c12da"
      },
      "source": [
        "print(\"Calculating Shapley values...\")\n",
        "\n",
        "# Calculate Shapley values for the best model on the training data\n",
        "# The shapley_explanation method is directly available on the H2O model object\n",
        "shapley_values = best_model.shapley_explanation(frame=train)\n",
        "\n",
        "print(\"Shapley values calculated successfully!\")\n",
        "print(\"First few rows of Shapley values:\")\n",
        "shapley_values.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Shapley values...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "type object 'ModelBase' has no attribute 'shapley_explanation'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-486046416.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Calculate Shapley values for the best model on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# The shapley_explanation method is directly available on the H2O model object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mshapley_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshapley_explanation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapley values calculated successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/utils/metaclass.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_bci'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bci\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bci\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_clz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mnew_clz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend_and_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h2o/utils/metaclass.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mMetaFeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_FOUND\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'ModelBase' has no attribute 'shapley_explanation'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49988153"
      },
      "source": [
        "**Reasoning**:\n",
        "The `best_model.shapley_explanation` method has consistently failed with an `AttributeError`, suggesting it might not be accessible in this specific H2O environment or version, despite the model being of a type (XGBoost) that typically supports it. To fulfill the requirement of visualizing feature importance and proceeding with the task without errors, I will use `best_model.varimp()` to calculate global feature importance. While this does not provide per-instance Shapley values, it is a robust alternative for understanding feature contributions. I will store the result in a Pandas DataFrame for easier handling and visualization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "fb2b994a",
        "outputId": "8a26b081-79c8-43b8-a12d-68d9450a37f2"
      },
      "source": [
        "import matplotlib.pyplot as plt # Import for plotting\n",
        "\n",
        "print(\"Calculating feature importance using model.varimp() as an alternative...\")\n",
        "\n",
        "# The best_model.shapley_explanation method is currently failing with AttributeError.\n",
        "# As a robust alternative to get feature importance for visualization,\n",
        "# we will use the model's global variable importance (varimp).\n",
        "# Note: This provides global feature importance, not per-instance Shapley values.\n",
        "\n",
        "feature_importance_df = best_model.varimp(use_pandas=True)\n",
        "\n",
        "print(\"Feature importance calculated successfully!\")\n",
        "print(\"First few rows of feature importance:\")\n",
        "print(feature_importance_df.head())\n",
        "\n",
        "# --- Visualize Feature Importance ---\n",
        "# For visualization, we will plot the variable importance results.\n",
        "\n",
        "if not feature_importance_df.empty:\n",
        "    # Sort by percentage for better visualization\n",
        "    feature_importance_df_sorted = feature_importance_df.sort_values(by='percentage', ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(feature_importance_df_sorted['variable'], feature_importance_df_sorted['percentage'], color='skyblue')\n",
        "    plt.xlabel('Importance Percentage')\n",
        "    plt.ylabel('Features')\n",
        "    plt.title('Global Feature Importance (from varimp())')\n",
        "    plt.gca().invert_yaxis() # Highest importance at the top\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No feature importance data to visualize.\")\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating feature importance using model.varimp() as an alternative...\n",
            "Feature importance calculated successfully!\n",
            "First few rows of feature importance:\n",
            "              variable  relative_importance  scaled_importance  percentage\n",
            "0  Avg_Resp_Right_Mean             9.701118           1.000000    0.785029\n",
            "1    Avg_Resp_Left_Std             2.298195           0.236900    0.185973\n",
            "2           Unnamed: 0             0.221518           0.022834    0.017926\n",
            "3  Avg_Resp_Left_Hurst             0.070010           0.007217    0.005665\n",
            "4   Avg_Resp_Left_Mean             0.064344           0.006633    0.005207\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "958b746a"
      },
      "source": [
        "## Analyze and Summarize Feature Importance\n",
        "\n",
        "### Subtask:\n",
        "Analyze the visualized global feature importance and summarize key observations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e665308"
      },
      "source": [
        "### Analyzing Global Feature Importance (from `varimp()`)\n",
        "\n",
        "The bar plot displays the global feature importance as calculated by the `varimp()` method of the best H2O model (which was an XGBoost model in this re-run). This method provides a global perspective on how much each feature contributes to the model's overall predictive power, rather than individual instance explanations like Shapley values.\n",
        "\n",
        "**Key Observations:**\n",
        "\n",
        "1.  **Dominant Feature:** `Avg_Resp_Right_Mean` stands out as the most influential feature, accounting for approximately 78.5% of the total relative importance. This suggests that the average response of the right side is by far the strongest predictor for the target variable `Avg_Resp_DWT_Cluster`.\n",
        "\n",
        "2.  **Secondary Importance:** `Avg_Resp_Left_Std` is the second most important feature, but its contribution (around 18.6%) is significantly lower than that of `Avg_Resp_Right_Mean`. This indicates that the standard deviation of the left response also plays a role, though a much smaller one.\n",
        "\n",
        "3.  **Minor Contributions:** Other features such as `Unnamed: 0`, `Avg_Resp_Left_Hurst`, and `Avg_Resp_Left_Mean` have very marginal contributions (each less than 2%). The remaining features (`Avg_Resp_Right_Hurst` and `Inh_Thresh_DTW_Cluster`) contribute even less, almost negligible in this model.\n",
        "\n",
        "**Insights:**\n",
        "\n",
        "The strong dominance of `Avg_Resp_Right_Mean` suggests that the average response on the right side of the body is a critical determinant of the `Avg_Resp_DWT_Cluster`. This could imply a significant physiological or behavioral pattern linked to right-side activity that strongly influences the clustering outcome. The comparatively minor role of other features, particularly the low importance of the `Inh_Thresh_DTW_Cluster`, is notable. While `Avg_Resp_Left_Std` has some importance, it pales in comparison to `Avg_Resp_Right_Mean`.\n",
        "\n",
        "It is important to remember that these are global importances. While they guide us towards the most impactful features overall, they do not explain individual predictions. Also, this analysis is based on `varimp()` due to technical difficulties with `shapley_explanation` and provides a global aggregate view of feature influence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "349a0154"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The H2O environment was successfully re-initialized, and the `df_clean` DataFrame was loaded as an H2OFrame.\n",
        "*   Due to the H2O session re-initialization, the best model from a previous run could not be retrieved directly. A new H2O AutoML process was executed for the `best_target_col` (resulting in an XGBoost model) to obtain an active best model.\n",
        "*   Attempts to calculate Shapley values using `best_model.shapley_explanation()` and `h2o.explanation.shap.shap_explanation_table()` failed due to `AttributeError`s.\n",
        "*   Global feature importance was successfully calculated and visualized using the `best_model.varimp()` method.\n",
        "*   `Avg_Resp_Right_Mean` was identified as the most influential feature, contributing approximately 78.5% to the total relative importance.\n",
        "*   `Avg_Resp_Left_Std` was the second most important feature, contributing about 18.6%.\n",
        "*   Other features, including `Unnamed: 0`, `Avg_Resp_Left_Hurst`, `Avg_Resp_Left_Mean`, `Avg_Resp_Right_Hurst`, and `Inh_Thresh_DTW_Cluster`, showed very marginal contributions (less than 2% each).\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The overwhelming dominance of `Avg_Resp_Right_Mean` in predicting `Avg_Resp_DWT_Cluster` suggests a critical underlying physiological or behavioral pattern linked to right-side activity that warrants further investigation.\n",
        "*   Future analysis should aim to resolve the `AttributeError` with Shapley explanation methods to enable per-instance feature importance, which can provide more granular insights into individual predictions rather than just global feature influence.\n"
      ]
    }
  ]
}