{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAUforPython/BioMedAI/blob/dev/NN%20LSTM%20ECG%20classification%20ArrayArrowData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт необходимых библиотек.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Bidirectional, LSTM, Dense, Masking, Dropout, GlobalMaxPooling1D, GlobalAveragePooling1D, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "M7iQfHGvQNdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Загрузка и предобработка данных\n",
        "# -------------------------------\n",
        "\n",
        "# Читаем данные из CSV файла.\n",
        "data = pd.read_csv('test_data_ECG.csv')\n",
        "\n",
        "# Убираем лишние пробелы в названиях колонок, чтобы не возникало ошибок при обращении к ним.\n",
        "data = data.rename(columns=lambda x: x.strip())\n",
        "\n",
        "# Сохраняем исходные данные в переменной clear_data для последующей работы.\n",
        "clear_data = data.copy()\n",
        "\n",
        "# Удаляем текстовые отчеты (столбцы report_0 ... report_17),\n",
        "# поскольку они могут привести к переобучению модели.\n",
        "reports_columns = [f'report_{x}' for x in range(18)]\n",
        "clear_data = clear_data.drop(columns=reports_columns, errors='ignore')\n",
        "\n",
        "# Преобразуем дату и время в единый формат.\n",
        "# Объединяем столбцы 'eeg_date' и 'eeg_time' и конвертируем их в формат datetime.\n",
        "clear_data['eeg_datetime'] = pd.to_datetime(clear_data['eeg_date'] + ' ' + clear_data['eeg_time'],\n",
        "                                            errors='coerce', dayfirst=True)\n",
        "# Удаляем исходные столбцы с датой и временем, так как теперь они не нужны.\n",
        "clear_data = clear_data.drop(columns=['eeg_date', 'eeg_time'])\n",
        "\n",
        "# Приводим числовые признаки к числовому типу.\n",
        "# Определяем список признаков ЭКГ.\n",
        "numeric_columns = ['rr_interval', 'p_onset', 'p_end', 'qrs_onset',\n",
        "                   'qrs_end', 't_end', 'p_axis', 'qrs_axis', 't_axis']\n",
        "clear_data[numeric_columns] = clear_data[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Убираем аномальные значения: значения признаков больше 2000 считаем аномальными,\n",
        "# а также удаляем строки с логически неверными соотношениями (p_onset < p_end и qrs_onset < qrs_end).\n",
        "clear_data = clear_data[(clear_data[numeric_columns] < 2000).all(axis=1)]\n",
        "clear_data = clear_data[(clear_data['p_onset'] < clear_data['p_end']) & (clear_data['qrs_onset'] < clear_data['qrs_end'])]\n",
        "\n",
        "# Сортируем данные по идентификатору пациента (subject_id) и времени обследования.\n",
        "# Это важно для формирования корректных временных рядов.\n",
        "clear_data = clear_data.sort_values(by=['subject_id', 'eeg_datetime'])\n"
      ],
      "metadata": {
        "id": "b9MQ7vYIQQns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Формирование временных рядов и нормализация\n",
        "# -------------------------------\n",
        "\n",
        "# Для каждого пациента (subject_id) формируем последовательность обследований.\n",
        "# Каждая последовательность – это временной ряд, состоящий из строк с числовыми признаками ЭКГ.\n",
        "# В качестве целевой метки выбирается последний зафиксированный Healthy_Status (0 — здоров, 1 — болен).\n",
        "sequence_data = []\n",
        "sequence_labels = []\n",
        "features = numeric_columns  # Используем только числовые признаки ЭКГ.\n",
        "\n",
        "for subject_id, group in clear_data.groupby('subject_id'):\n",
        "    group_features = group[features].values  # Получаем данные в виде матрицы (seq_len, num_features)\n",
        "    label = group['Healthy_Status'].values[-1]  # Берём последнюю метку пациента.\n",
        "    sequence_data.append(group_features)\n",
        "    sequence_labels.append(label)\n",
        "\n",
        "# Нормализация данных:\n",
        "# Объединяем все последовательности для вычисления среднего и стандартного отклонения.\n",
        "all_data = np.vstack(sequence_data)\n",
        "scaler = StandardScaler().fit(all_data)\n",
        "\n",
        "# Применяем scaling к каждой последовательности индивидуально.\n",
        "sequence_data_scaled = [scaler.transform(seq) for seq in sequence_data]\n",
        "\n",
        "# Приводим все последовательности к одной длине с помощью паддинга.\n",
        "# Определяем максимальную длину последовательности.\n",
        "max_seq_length = max(len(seq) for seq in sequence_data_scaled)\n",
        "# Используем pad_sequences для дополнения коротких последовательностей нулями (padding='post').\n",
        "X = pad_sequences(sequence_data_scaled, maxlen=max_seq_length, dtype='float32', padding='post', truncating='post')\n",
        "y = np.array(sequence_labels)\n",
        "\n",
        "print(\"Форма входных данных:\", X.shape)   # (num_patients, max_seq_length, num_features)\n",
        "print(\"Форма меток:\", y.shape)              # (num_patients,)\n",
        "\n",
        "# Разбиваем данные на обучающую и тестовую выборки (90% на обучение, 10% на тест).\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Вычисляем веса классов для компенсации дисбаланса в данных.\n",
        "# Это помогает модели уделять больше внимания редкому классу.\n",
        "weights = class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                            classes=np.unique(y_train),\n",
        "                                            y=y_train)\n",
        "class_weights = {i: weights[i] for i in range(len(weights))}\n",
        "print(\"Классовые веса:\", class_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfOgAiUjQdZ7",
        "outputId": "ecef040c-faf6-489b-c121-9b4e0c38928f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Форма входных данных: (6575, 4, 9)\n",
            "Форма меток: (6575,)\n",
            "Классовые веса: {0: np.float64(0.6990784499054821), 1: np.float64(1.755786350148368)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Построение модели (Conv1D + Bidirectional LSTM + Глобальное объединение)\n",
        "# -------------------------------\n",
        "\n",
        "# Используем функциональный API для объединения нескольких глобальных пулов.\n",
        "inputs = Input(shape=(max_seq_length, len(features)))\n",
        "\n",
        "# Слой Masking – игнорирует паддинговые (нулевые) значения.\n",
        "x = Masking(mask_value=0.)(inputs)\n",
        "\n",
        "# Сверточный блок для выделения локальных особенностей.\n",
        "x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "# Первый слой Bidirectional LSTM – извлекает временные зависимости (возвращает последовательности).\n",
        "x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3))(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "# Второй слой Bidirectional LSTM – извлекает более глубокие зависимости.\n",
        "x = Bidirectional(LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.3))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "# Глобальное объединение: усреднение по временной оси.\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "\n",
        "# Полносвязный слой для дальнейшей обработки извлечённых признаков.\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "# Выходной слой для бинарной классификации.\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# Компилируем модель с дополнительными метриками.\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy',\n",
        "                       tf.keras.metrics.Precision(name='precision'),\n",
        "                       tf.keras.metrics.Recall(name='recall'),\n",
        "                       tf.keras.metrics.AUC(name='auc')])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "RFs9ZDMfQkvW",
        "outputId": "7318509e-e9f9-484b-a93b-da50be24d449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'conv1d_5' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m9\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ masking_5 (\u001b[38;5;33mMasking\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m9\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m1,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_14               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_10 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │         \u001b[38;5;34m197,632\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_15               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_11 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │         \u001b[38;5;34m164,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_16               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ masking_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_14               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_15               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_16               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m373,633\u001b[0m (1.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">373,633</span> (1.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m372,865\u001b[0m (1.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">372,865</span> (1.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Обучение модели\n",
        "# -------------------------------\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, min_lr=1e-6)\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    class_weight=class_weights,\n",
        "                    callbacks=[early_stop, reduce_lr],\n",
        "                    verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1vgs68DQoQQ",
        "outputId": "f966f6e8-77ae-495d-8116-625f927d731e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 62ms/step - accuracy: 0.6307 - auc: 0.7146 - loss: 0.8068 - precision: 0.4189 - recall: 0.7119 - val_accuracy: 0.7447 - val_auc: 0.7852 - val_loss: 0.6867 - val_precision: 0.5758 - val_recall: 0.3115 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.6876 - auc: 0.7798 - loss: 0.6551 - precision: 0.4720 - recall: 0.7875 - val_accuracy: 0.7021 - val_auc: 0.8213 - val_loss: 0.5912 - val_precision: 0.4796 - val_recall: 0.8361 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.7127 - auc: 0.8186 - loss: 0.5842 - precision: 0.4983 - recall: 0.8064 - val_accuracy: 0.7204 - val_auc: 0.8410 - val_loss: 0.5790 - val_precision: 0.4985 - val_recall: 0.8798 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.7357 - auc: 0.8365 - loss: 0.5544 - precision: 0.5346 - recall: 0.8566 - val_accuracy: 0.7340 - val_auc: 0.8427 - val_loss: 0.5533 - val_precision: 0.5136 - val_recall: 0.8251 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.7369 - auc: 0.8462 - loss: 0.5339 - precision: 0.5273 - recall: 0.8432 - val_accuracy: 0.7295 - val_auc: 0.8528 - val_loss: 0.5573 - val_precision: 0.5078 - val_recall: 0.8907 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - accuracy: 0.7349 - auc: 0.8437 - loss: 0.5232 - precision: 0.5165 - recall: 0.8655 - val_accuracy: 0.7371 - val_auc: 0.8507 - val_loss: 0.5498 - val_precision: 0.5161 - val_recall: 0.8743 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.7473 - auc: 0.8444 - loss: 0.5084 - precision: 0.5302 - recall: 0.8883 - val_accuracy: 0.7371 - val_auc: 0.8535 - val_loss: 0.5358 - val_precision: 0.5156 - val_recall: 0.9016 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.7504 - auc: 0.8525 - loss: 0.4957 - precision: 0.5405 - recall: 0.8873 - val_accuracy: 0.7447 - val_auc: 0.8499 - val_loss: 0.5397 - val_precision: 0.5240 - val_recall: 0.8962 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.7623 - auc: 0.8696 - loss: 0.4705 - precision: 0.5517 - recall: 0.8855 - val_accuracy: 0.7553 - val_auc: 0.8510 - val_loss: 0.5031 - val_precision: 0.5374 - val_recall: 0.8634 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.7575 - auc: 0.8691 - loss: 0.4654 - precision: 0.5396 - recall: 0.8958 - val_accuracy: 0.7295 - val_auc: 0.8524 - val_loss: 0.5519 - val_precision: 0.5078 - val_recall: 0.8852 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.7491 - auc: 0.8628 - loss: 0.4688 - precision: 0.5403 - recall: 0.8890 - val_accuracy: 0.7416 - val_auc: 0.8472 - val_loss: 0.5104 - val_precision: 0.5220 - val_recall: 0.8415 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.7581 - auc: 0.8652 - loss: 0.4600 - precision: 0.5490 - recall: 0.8970 - val_accuracy: 0.7477 - val_auc: 0.8493 - val_loss: 0.5166 - val_precision: 0.5275 - val_recall: 0.8907 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.7638 - auc: 0.8635 - loss: 0.4551 - precision: 0.5502 - recall: 0.8942 - val_accuracy: 0.7492 - val_auc: 0.8482 - val_loss: 0.5217 - val_precision: 0.5294 - val_recall: 0.8852 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7620 - auc: 0.8701 - loss: 0.4464 - precision: 0.5492 - recall: 0.9097\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.7620 - auc: 0.8701 - loss: 0.4464 - precision: 0.5492 - recall: 0.9097 - val_accuracy: 0.7553 - val_auc: 0.8571 - val_loss: 0.5050 - val_precision: 0.5377 - val_recall: 0.8579 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.7770 - auc: 0.8751 - loss: 0.4350 - precision: 0.5762 - recall: 0.8963 - val_accuracy: 0.7736 - val_auc: 0.8606 - val_loss: 0.4746 - val_precision: 0.5594 - val_recall: 0.8743 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.7730 - auc: 0.8770 - loss: 0.4267 - precision: 0.5602 - recall: 0.8903 - val_accuracy: 0.7568 - val_auc: 0.8596 - val_loss: 0.4891 - val_precision: 0.5377 - val_recall: 0.8962 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.7661 - auc: 0.8702 - loss: 0.4395 - precision: 0.5518 - recall: 0.9089 - val_accuracy: 0.7720 - val_auc: 0.8592 - val_loss: 0.4774 - val_precision: 0.5587 - val_recall: 0.8579 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.7816 - auc: 0.8793 - loss: 0.4185 - precision: 0.5625 - recall: 0.9096 - val_accuracy: 0.7644 - val_auc: 0.8551 - val_loss: 0.4963 - val_precision: 0.5461 - val_recall: 0.9071 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.7741 - auc: 0.8759 - loss: 0.4275 - precision: 0.5610 - recall: 0.8967 - val_accuracy: 0.7690 - val_auc: 0.8567 - val_loss: 0.4870 - val_precision: 0.5552 - val_recall: 0.8525 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m184/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7760 - auc: 0.8799 - loss: 0.4169 - precision: 0.5680 - recall: 0.9149\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.7760 - auc: 0.8799 - loss: 0.4169 - precision: 0.5680 - recall: 0.9149 - val_accuracy: 0.7614 - val_auc: 0.8592 - val_loss: 0.4887 - val_precision: 0.5433 - val_recall: 0.8907 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.7822 - auc: 0.8855 - loss: 0.4092 - precision: 0.5718 - recall: 0.9305 - val_accuracy: 0.7705 - val_auc: 0.8584 - val_loss: 0.4699 - val_precision: 0.5567 - val_recall: 0.8579 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.7786 - auc: 0.8805 - loss: 0.4060 - precision: 0.5541 - recall: 0.9169 - val_accuracy: 0.7720 - val_auc: 0.8585 - val_loss: 0.4764 - val_precision: 0.5583 - val_recall: 0.8634 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - accuracy: 0.7804 - auc: 0.8811 - loss: 0.4148 - precision: 0.5731 - recall: 0.9171 - val_accuracy: 0.7675 - val_auc: 0.8577 - val_loss: 0.4825 - val_precision: 0.5517 - val_recall: 0.8743 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.7953 - auc: 0.8836 - loss: 0.4042 - precision: 0.5930 - recall: 0.9210 - val_accuracy: 0.7644 - val_auc: 0.8571 - val_loss: 0.4888 - val_precision: 0.5476 - val_recall: 0.8798 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - accuracy: 0.7861 - auc: 0.8884 - loss: 0.3996 - precision: 0.5844 - recall: 0.9129 - val_accuracy: 0.7812 - val_auc: 0.8559 - val_loss: 0.4773 - val_precision: 0.5730 - val_recall: 0.8361 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m184/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7906 - auc: 0.8865 - loss: 0.4003 - precision: 0.5848 - recall: 0.8963\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.7906 - auc: 0.8865 - loss: 0.4003 - precision: 0.5848 - recall: 0.8965 - val_accuracy: 0.7644 - val_auc: 0.8566 - val_loss: 0.4778 - val_precision: 0.5490 - val_recall: 0.8579 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.7850 - auc: 0.8869 - loss: 0.4007 - precision: 0.5756 - recall: 0.9226 - val_accuracy: 0.7675 - val_auc: 0.8586 - val_loss: 0.4761 - val_precision: 0.5536 - val_recall: 0.8470 - learning_rate: 1.2500e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.7945 - auc: 0.8929 - loss: 0.3914 - precision: 0.5907 - recall: 0.9142 - val_accuracy: 0.7690 - val_auc: 0.8569 - val_loss: 0.4747 - val_precision: 0.5552 - val_recall: 0.8525 - learning_rate: 1.2500e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.7938 - auc: 0.8955 - loss: 0.3826 - precision: 0.5879 - recall: 0.9252 - val_accuracy: 0.7827 - val_auc: 0.8579 - val_loss: 0.4670 - val_precision: 0.5746 - val_recall: 0.8415 - learning_rate: 1.2500e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.7946 - auc: 0.8901 - loss: 0.3975 - precision: 0.5954 - recall: 0.8996 - val_accuracy: 0.7796 - val_auc: 0.8579 - val_loss: 0.4715 - val_precision: 0.5693 - val_recall: 0.8525 - learning_rate: 1.2500e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.7880 - auc: 0.8848 - loss: 0.4006 - precision: 0.5803 - recall: 0.9295 - val_accuracy: 0.7812 - val_auc: 0.8566 - val_loss: 0.4704 - val_precision: 0.5730 - val_recall: 0.8361 - learning_rate: 1.2500e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.7981 - auc: 0.8887 - loss: 0.3892 - precision: 0.5925 - recall: 0.9148 - val_accuracy: 0.7766 - val_auc: 0.8561 - val_loss: 0.4807 - val_precision: 0.5652 - val_recall: 0.8525 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.7994 - auc: 0.8973 - loss: 0.3808 - precision: 0.5988 - recall: 0.9186 - val_accuracy: 0.7766 - val_auc: 0.8571 - val_loss: 0.4734 - val_precision: 0.5657 - val_recall: 0.8470 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7870 - auc: 0.8864 - loss: 0.4076 - precision: 0.5770 - recall: 0.8935\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.7871 - auc: 0.8865 - loss: 0.4075 - precision: 0.5771 - recall: 0.8936 - val_accuracy: 0.7660 - val_auc: 0.8554 - val_loss: 0.4820 - val_precision: 0.5512 - val_recall: 0.8525 - learning_rate: 1.2500e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.7901 - auc: 0.8874 - loss: 0.3945 - precision: 0.5823 - recall: 0.9220 - val_accuracy: 0.7720 - val_auc: 0.8557 - val_loss: 0.4848 - val_precision: 0.5596 - val_recall: 0.8470 - learning_rate: 6.2500e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.7994 - auc: 0.8977 - loss: 0.3786 - precision: 0.5946 - recall: 0.9188 - val_accuracy: 0.7796 - val_auc: 0.8557 - val_loss: 0.4748 - val_precision: 0.5709 - val_recall: 0.8361 - learning_rate: 6.2500e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.7957 - auc: 0.8975 - loss: 0.3801 - precision: 0.5909 - recall: 0.9173 - val_accuracy: 0.7781 - val_auc: 0.8570 - val_loss: 0.4800 - val_precision: 0.5673 - val_recall: 0.8525 - learning_rate: 6.2500e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.8030 - auc: 0.8992 - loss: 0.3751 - precision: 0.5982 - recall: 0.9367 - val_accuracy: 0.7796 - val_auc: 0.8577 - val_loss: 0.4750 - val_precision: 0.5699 - val_recall: 0.8470 - learning_rate: 6.2500e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7987 - auc: 0.8962 - loss: 0.3901 - precision: 0.6066 - recall: 0.9164\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - accuracy: 0.7987 - auc: 0.8962 - loss: 0.3901 - precision: 0.6066 - recall: 0.9165 - val_accuracy: 0.7751 - val_auc: 0.8570 - val_loss: 0.4813 - val_precision: 0.5636 - val_recall: 0.8470 - learning_rate: 6.2500e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.7918 - auc: 0.8933 - loss: 0.3900 - precision: 0.5823 - recall: 0.9149 - val_accuracy: 0.7781 - val_auc: 0.8578 - val_loss: 0.4778 - val_precision: 0.5683 - val_recall: 0.8415 - learning_rate: 3.1250e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.8031 - auc: 0.8989 - loss: 0.3788 - precision: 0.6074 - recall: 0.9129 - val_accuracy: 0.7812 - val_auc: 0.8581 - val_loss: 0.4733 - val_precision: 0.5725 - val_recall: 0.8415 - learning_rate: 3.1250e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.8030 - auc: 0.8946 - loss: 0.3800 - precision: 0.6012 - recall: 0.9173 - val_accuracy: 0.7720 - val_auc: 0.8563 - val_loss: 0.4828 - val_precision: 0.5604 - val_recall: 0.8361 - learning_rate: 3.1250e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.8031 - auc: 0.9030 - loss: 0.3715 - precision: 0.6033 - recall: 0.9268 - val_accuracy: 0.7781 - val_auc: 0.8567 - val_loss: 0.4802 - val_precision: 0.5678 - val_recall: 0.8470 - learning_rate: 3.1250e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m184/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8001 - auc: 0.8988 - loss: 0.3773 - precision: 0.6004 - recall: 0.9217\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.8001 - auc: 0.8988 - loss: 0.3773 - precision: 0.6003 - recall: 0.9217 - val_accuracy: 0.7766 - val_auc: 0.8560 - val_loss: 0.4784 - val_precision: 0.5657 - val_recall: 0.8470 - learning_rate: 3.1250e-05\n",
            "Epoch 44: early stopping\n",
            "Restoring model weights from the end of the best epoch: 29.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Оценка модели и оптимизация порога отсечения\n",
        "# -------------------------------\n",
        "\n",
        "# Получаем предсказания вероятностей для тестовой выборки.\n",
        "y_pred_prob = model.predict(X_test).reshape(-1)\n",
        "\n",
        "# По умолчанию порог = 0.5. Найдём оптимальный порог, максимизирующий F1-score.\n",
        "best_threshold = 0.5\n",
        "best_f1 = 0\n",
        "for thresh in np.arange(0.3, 0.71, 0.01):\n",
        "    y_pred_temp = (y_pred_prob >= thresh).astype(int)\n",
        "    temp_f1 = f1_score(y_test, y_pred_temp)\n",
        "    if temp_f1 > best_f1:\n",
        "        best_f1 = temp_f1\n",
        "        best_threshold = thresh\n",
        "\n",
        "print(f\"Оптимальный порог: {best_threshold:.2f} с F1: {best_f1:.4f}\")\n",
        "\n",
        "# Вычисляем метрики с оптимальным порогом.\n",
        "y_pred = (y_pred_prob >= best_threshold).astype(int)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "test_f1 = f1_score(y_test, y_pred)\n",
        "test_precision = precision_score(y_test, y_pred)\n",
        "test_recall = recall_score(y_test, y_pred)\n",
        "test_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Test AUC-ROC: {test_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bc-wnX0Qs7X",
        "outputId": "a1bd8b27-91aa-44af-979b-fe9cfb5b09e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step\n",
            "Оптимальный порог: 0.52 с F1: 0.6890\n",
            "Test Accuracy: 0.7888\n",
            "Test Precision: 0.5833\n",
            "Test Recall: 0.8415\n",
            "Test F1 Score: 0.6890\n",
            "Test AUC-ROC: 0.8050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Пример предсказания для нового пациента\n",
        "# -------------------------------\n",
        "\n",
        "# Задаём данные нового пациента в виде двумерного массива (2 обследования, 9 признаков).\n",
        "new_patient_data = np.array([[700, 40, 120, 160, 240, 500, 80, 75, 78],\n",
        "                             [710, 40, 118, 165, 245, 510, 82, 76, 77]])  # форма: (2, num_features)\n",
        "\n",
        "# Применяем ту же нормализацию к новым данным.\n",
        "new_patient_data_scaled = scaler.transform(new_patient_data)\n",
        "# Приводим последовательность нового пациента к длине, используемой моделью, с помощью паддинга.\n",
        "new_patient_data_padded = pad_sequences([new_patient_data_scaled], maxlen=max_seq_length, dtype='float32',\n",
        "                                         padding='post', truncating='post')\n",
        "# Получаем предсказание: вероятность того, что пациент находится в критическом состоянии (1 - болен).\n",
        "prediction_prob = model.predict(new_patient_data_padded)[0][0]\n",
        "print(\"Вероятность критического состояния (1 - болен):\", prediction_prob)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "702f858a-0517-41e2-b642-bfaddcaef48f",
        "id": "21hvic0-O9wS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Вероятность критического состояния (1 - болен): 0.51075745\n"
          ]
        }
      ]
    }
  ]
}